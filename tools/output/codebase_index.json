[
  {
    "type": "file",
    "name": ".env",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\.env",
    "content": "OPENAI_API_KEY=PsCsoyu2KFQD4xvd8uXQbRXe3ZSpbZzJn8W3P5BQ\nJIRA_PARAM=ATATT3xFfGF0kNQ6mdntUjHIyk8XBc6X_4W4l1ZSMkzDBcNGu8ExuWy09KcP4m..."
  },
  {
    "type": "file",
    "name": "ARCHITECTURE_ANALYSIS.md",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\ARCHITECTURE_ANALYSIS.md",
    "content": "# MCP Server AWS Infrastructure - Architecture Analysis & Troubleshooting Guide\n\n## \ud83c\udfd7\ufe0f **Complete Architecture Flow Diagram**\n\n```mermaid\ngraph TB\n    subgraph \"Internet\"\n        Client[Client/Browser]\n        SSH[SSH Client]\n    end\n    \n    subgraph \"AWS Cloud (ap-south-1)\"\n        subgraph \"VPC (Default)\"\n            subgraph \"Public Subnet\"\n                EC2[EC2 Instance<br/>t2.micro<br/>Amazon Linux 2<br/>Public IP: 13.234.xxx.xxx]\n            end\n            \n            subgraph \"Security Groups\"\n                SG_EC2[EC2 Security Group<br/>Ports: 22, 8000]\n            end\n            \n            subgraph \"Storage & Services\"\n                S3[S3 Bucket<br/>minds-constructing-products-mcp-data]\n                ECR[ECR Repository<br/>minds-constructing-products/mcp-server]\n                CW[CloudWatch Logs<br/>/aws/mcp-server]\n            end\n        end\n    end\n    \n    subgraph \"EC2 Instance Components\"\n        subgraph \"System Services\"\n            Docker[Docker Engine]\n            PostgreSQL[PostgreSQL 12<br/>localhost:5432]\n            SystemD[SystemD Service<br/>mcp-server.service]\n        end\n        \n        subgraph \"Application Stack\"\n            MCP_App[MCP Server<br/>FastAPI<br/>Port 8000]\n            Redis[Redis 7<br/>Port 6379]\n            DockerCompose[Docker Compose<br/>Resource Limits]\n        end\n        \n        subgraph \"Data & Logs\"\n            AppLogs[Application Logs<br/>/opt/mcp-server/logs]\n            PGData[PostgreSQL Data<br/>/var/lib/pgsql/12]\n            RedisData[Redis Data<br/>/var/lib/redis]\n        end\n    end\n    \n    %% Connections\n    Client -->|HTTP/WebSocket| EC2\n    SSH -->|SSH Key| EC2\n    EC2 --> SG_EC2\n    EC2 --> S3\n    EC2 --> ECR\n    EC2 --> CW\n    \n    %% Internal connections\n    EC2 --> Docker\n    Docker --> MCP_App\n    Docker --> Redis\n    MCP_App --> PostgreSQL\n    MCP_App --> Redis\n    SystemD --> DockerCompose\n    \n    %% Data flows\n    MCP_App --> AppLogs\n    PostgreSQL --> PGData\n    Redis --> RedisData\n```\n\n## \ud83d\udcca **Infrastructure Components Checklist**\n\n### \u2705 **AWS Resources Deployed**\n- [x] **EC2 Instance** (t2.micro, Amazon Linux 2)\n- [x] **Security Groups** (Ports 22, 8000 open)\n- [x] **S3 Bucket** (minds-constructing-products-mcp-data)\n- [x] **ECR Repository** (minds-constructing-products/mcp-server)\n- [x] **CloudWatch Logs** (/aws/mcp-server)\n- [x] **Public IP** (for SSH access)\n\n### \u2705 **Application Stack**\n- [x] **Docker Engine** (for containerization)\n- [x] **Docker Compose** (for orchestration)\n- [x] **PostgreSQL 12** (local database)\n- [x] **Redis 7** (caching & sessions)\n- [x] **MCP Server** (FastAPI application)\n- [x] **SystemD Service** (auto-restart)\n\n### \u2705 **Security & Networking**\n- [x] **SSH Access** (port 22)\n- [x] **HTTP Access** (port 8000)\n- [x] **Public IP** (for external access)\n- [x] **Security Groups** (restricted access)\n\n## \ud83d\udd0d **Comprehensive Troubleshooting Guide**\n\n### **1. SSH Connectivity Check**\n\n```bash\n# Check if you can SSH to the instance\nssh -i \"Minds-Constructing-Products-key.pem\" ec2-user@<PUBLIC_IP>\n\n# If SSH fails, check:\n# - Key permissions: chmod 400 Minds-Constructing-Products-key.pem\n# - Security group allows port 22\n# - Instance is running\n```\n\n### **2. System Services Status**\n\n```bash\n# Check system services\nsudo systemctl status docker\nsudo systemctl status postgresql-12\nsudo systemctl status mcp-server.service\n\n# Check if services are enabled\nsudo systemctl is-enabled docker\nsudo systemctl is-enabled postgresql-12\nsudo systemctl is-enabled mcp-server.service\n```\n\n### **3. Docker & Application Status**\n\n```bash\n# Check Docker containers\ncd /opt/mcp-server\ndocker-compose ps\ndocker-compose logs mcp-server\ndocker-compose logs redis\n\n# Check if containers are running\ndocker ps -a\n\n# Check resource usage\ndocker stats\n```\n\n### **4. Database Connectivity**\n\n```bash\n# Test PostgreSQL connection\nsudo -u postgres psql -c \"SELECT version();\"\nsudo -u postgres psql -c \"SELECT current_database();\"\nsudo -u postgres psql -c \"SELECT * FROM pg_user;\"\n\n# Test database from application\nsudo -u postgres psql -d mcp_assistant -c \"SELECT 1;\"\n```\n\n### **5. Application Health Checks**\n\n```bash\n# Check if MCP server..."
  },
  {
    "type": "file",
    "name": "ARCHITECTURE_DIAGRAM.md",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\ARCHITECTURE_DIAGRAM.md",
    "content": "# MCP Server Architecture Diagrams\n## Technical Implementation Guide\n\n---\n\n## \ud83c\udfd7\ufe0f **System Architecture Overview**\n\n### **High-Level Architecture**\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              CLIENT LAYER                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Web Browser  \u2502  Mobile App  \u2502  API Client  \u2502  Third-party Integration   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           LOAD BALANCER LAYER                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                    AWS Application Load Balancer (Future)                  \u2502\n\u2502                              Port 80/443                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          APPLICATION LAYER                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                    MCP SERVER CONTAINER                            \u2502    \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502    \u2502\n\u2502  \u2502  \u2502   Flask App     \u2502  \u2502   LangChain     \u2502  \u2502   Tool Registry \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502   (Port 8000)   \u2502  \u2502   Integration   \u2502  \u2502   & Management  \u2502    \u2502    \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502\n\u2502  \u2502                                                                         \u2502    \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502    \u2502\n\u2502  \u2502  \u2502   REST API      \u2502  \u2502   Health Check  \u2502  \u2502   Multi-Agent   \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502   Endpoints     \u2502  \u2502   Monitoring    \u2502  \u2502   Coordinator   \u2502    \u2502    \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u25bc               \u25bc               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    POSTGRESQL LAYER     \u2502 \u2502      REDIS LAYER        \u2502 \u2502    MONITORING LAYER     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502 \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502 \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502   PostgreSQL    \u2502    \u2502 \u2502  \u2502     Redis       \u2502    \u2502 \u2502  Health Checks   \u2502    \u2502\n\u2502  \u2502   Database      \u2502    \u2502 \u2502  \u2502     Cache       \u2502    \u2502 \u2502  & Monitoring    \u2502    \u2502\n\u2502  \u2502   (Port 5432)   \u2502    \u2502 \u2502  \u2502   (Port 6379)   \u2502    \u2502 \u2502  & Logging       \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502 \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502 \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                         \u2502 \u2502                         \u2502 \u2502                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502 \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502 \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502   User Data     \u2502    \u2502 \u2502  \u2502   Session Data  \u2502    \u2502 \u2502  Performance     \u2502    \u2502\n\u2502  \u2502   & History     \u2502    \u2502 \u2502  \u2502   & Cache       \u2502    \u2502 \u2502  Metrics         \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502 \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502 \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n---\n\n## \ud83d\udd27 **Detailed Component Architecture**\n\n### **MCP Server Container Architecture**\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        MCP SERVER CONTAINER                               \u2502\n\u2502                           (Python 3.9)                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                        FLASK APPLICATION                           \u2502    \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502    \u2502\n\u2502  \u2502  \u2502   Main App      \u2502  \u2502   API Routes    \u2502  \u2502   Error Handler \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502   (server.py)   \u2502  \u2502   & Endpoints   \u2502  \u2502   & Middleware  \u2502    \u2502    \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                    \u2502                                      \u2502\n\u2502                                    \u25bc                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                      LANGCHAIN INTEGRATION                         \u2502    \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502    \u2502\n\u2502  \u2502  \u2502   LLM Models    \u2502  \u2502   Tool Registry \u2502  \u2502   Agent Manager \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502   & Providers   \u2502  \u2502   & Execution   \u2502  \u2502   & Coordination\u2502    \u2502    \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                    \u2502                                      \u2502\n\u2502                                    \u25bc                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                        DATA ACCESS LAYER                           \u2502    \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502    \u2502\n\u2502  \u2502  \u2502   PostgreSQL    \u2502  \u2502     Redis       \u2502  \u2502   File System   \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502   Connection    \u2502  \u2502   Connection    \u2502  \u2502   & Logs        \u2502    \u2502    \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n---\n\n## \ud83c\udf10 **Network Architecture**\n\n### **Docker Network Configuration**\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           DOCKER NETWORK                                  \u2502\n\u2502                           (mcp-network)                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                    MCP SERVER CONTAINER                            \u2502    \u2502\n\u2502  \u2502  IP: 172.21.0.2                                                    \u2502    \u2502\n\u2502  \u2502  Port: 8000 (exposed to host)                                      \u2502    \u2502\n\u2502  \u2502  Health Check: http://localhost:8000/health                        \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                    \u2502                                      \u2502\n\u2502                                    \u25bc                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                      REDIS CONTAINER                               \u2502    \u2502\n\u2502  \u2502  IP: 172.21.0.3                                                    \u2502    \u2502\n\u2502  \u2502  Port: 6379 (exposed to host)                                      \u2502    \u2502\n\u2502  \u2502  Health Check: redis-cli ping                                       \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                    \u2502                                      \u2502\n\u2502                                    \u25bc                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                    HOST SYSTEM                                     \u2502    \u2502\n\u2502  \u2502  IP: 172.31.5.251 (EC2 Private IP)                                \u2502    \u2502\n\u2502  \u2502  Public IP: 3.109.155.48                                          \u2502    \u2502\n\u2502  \u2502  PostgreSQL: 127.0.0.1:5432                                       \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n---\n\n## \ud83d\udd12 **Security Architecture**\n\n### **Security Group Configuration**\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           SECURITY GROUPS                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                    INBOUND RULES                                   \u2502    \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502    \u2502\n\u2502  \u2502  \u2502   SSH       \u2502 \u2502   HTTP      \u2502 \u2502   MCP API   \u2502 \u2502   Custom    \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502   Port 22   \u2502 \u2502   Port 80   \u2502 \u2502   Port 8000 \u2502 \u2502   Ports     \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502   (Restricted)\u2502 \u2502   (Public)   \u2502 \u2502   (Public)   \u2502 \u2502   (Internal) \u2502    \u2502    \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500..."
  },
  {
    "type": "file",
    "name": "bot.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\bot.py",
    "content": "from langchain_openai import ChatOpenAI\nfrom langchain.chains import ConversationalRetrievalChain\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_openai.embeddings import OpenAIEmbeddings\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.schema import AIMessage, HumanMessage, SystemMessage\nfrom dotenv import load_dotenv\nimport os\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Set your OpenAI API key\nos.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n\n# Load both FAISS indexes\nfaiss_index_path_1 = \"tools/output/jira_tickets_stories_faiss_index\"\nfaiss_index_path_2 = \"tools/output/codebase_faiss_index\"\nfaiss_index_path_3 = \"tools/output/git_history_faiss_index\"\nvectorstore1 = FAISS.load_local(faiss_index_path_1, OpenAIEmbeddings(), allow_dangerous_deserialization=True)\nvectorstore2 = FAISS.load_local(faiss_index_path_2, OpenAIEmbeddings(), allow_dangerous_deserialization=True)\nvectorstore3 = FAISS.load_local(faiss_index_path_3, OpenAIEmbeddings(), allow_dangerous_deserialization=True)\n\n# Merge the second index into the first\n    \nvectorstore1.merge_from(vectorstore2)\nvectorstore1.merge_from(vectorstore3)\nvectorstore = vectorstore1\n\n# Initialize conversation memory\nmemory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n\n# Custom system prompt\nsystem_prompt = \"\"\"\nYou are a highly intelligent and versatile assistant designed to support software development teams. You act as a combination of a Business Analyst, Product Manager, Product Owner, Senior Architect, and Developer. Your primary goal is to provide accurate, context-aware answers based on the knowledge base, which includes JIRA tickets (vectorstore1), codebase (vectorstore2), and git history (vectorstore3).\n\n### Role Identification:\n- Be smart enough to identify the user's role (Developer, Product Owner, Business Analyst, or Senior Architect) based on the type of question being asked.\n- If the question involves technical details (e.g., code, debugging, or implementation), assume the user is a Developer.\n- If the question involves estimations, task status, or high-level project details, assume the user is a Product Owner.\n- If the question involves requirements gathering or clarifying ambiguities, assume the user is a Business Analyst.\n- If the question involves system design, scalability, or architecture, assume the user is a Senior Architect.\n\n### General Capabilities:\n- Analyze the knowledge base to answer questions about JIRA tickets, codebase, and git history.\n- Provide detailed insights, such as:\n  - How many times a file was changed.\n  - Who made the most contributions to a file.\n  - The purpose of a specific function or module.\n  - Summaries of JIRA tickets and their statuses.\n  - Architectural recommendations for scaling the system.\n- If the requested information is not available, explicitly state what additional details are needed and ask clarifying questions.\n\n### Role-Specific Behaviors:\n- **Business Analyst**: Analyze requirements, clarify ambiguities, and ensure alignment with business goals.\n- **Product Manager/Product Owner**: Provide high-level summar..."
  },
  {
    "type": "function",
    "name": "chat_with_bot",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\bot.py"
  },
  {
    "type": "file",
    "name": "chatbot.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\chatbot.py",
    "content": "from llm_provider import LLMProvider\nimport os\nimport pathlib\nimport json\n\nfrom langchain_openai import ChatOpenAI\nfrom langchain.prompts import ChatPromptTemplate\nfrom chat_context_db import ChatContextDB\n\nclass Chatbot:\n    def __init__(self, model=\"gpt-4\"):\n        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n        if not openai_api_key:\n            # Try to read from settings.json\n            settings_path = pathlib.Path(__file__).parent / \"settings.json\"\n            if settings_path.exists():\n                with open(settings_path, \"r\", encoding=\"utf-8\") as f:\n                    try:\n                        settings = json.load(f)\n                        openai_api_key = settings.get(\"OPENAI_API_KEY\")\n                    except Exception:\n                        openai_api_key = None\n        if not openai_api_key:\n            openai_api_key = input(\"Enter your OpenAI API key: \").strip()\n        self.llm = ChatOpenAI(model=model, openai_api_key=openai_api_key)\n        self.prompt = ChatPromptTemplate.from_messages([\n            (\"system\", \"You are a helpful assistant. Here is the conversation so far: {context}\"),\n            (\"user\", \"{user_message}\")\n        ])\n        self.chain = self.prompt | self.llm\n        self.context_db = ChatContextDB()\n        self.context = self.context_db.load_context()\n\n\n    def _load_context(self):\n        self.context = self.context_db.load_context()\n\n\n    def _save_context(self):\n        self.context_db.save_context(self.context)\n\n    def add_to_context(self, user_message, bot_response):\n        self.context.append({\"role\": \"user\", \"content\": user_message})\n        # Always extract the string content for the assistant's response\n        content = None\n        if has..."
  },
  {
    "type": "class",
    "name": "Chatbot",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\chatbot.py"
  },
  {
    "type": "function",
    "name": "question_answering",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\chatbot.py"
  },
  {
    "type": "function",
    "name": "__init__",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\chatbot.py"
  },
  {
    "type": "function",
    "name": "_load_context",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\chatbot.py"
  },
  {
    "type": "function",
    "name": "_save_context",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\chatbot.py"
  },
  {
    "type": "function",
    "name": "add_to_context",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\chatbot.py"
  },
  {
    "type": "function",
    "name": "chat",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\chatbot.py"
  },
  {
    "type": "file",
    "name": "chat_context_db.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\chat_context_db.py",
    "content": "import sqlite3\nimport os\nimport json\n\nDB_PATH = os.path.join(os.path.dirname(__file__), 'chatbot_context.db')\n\nclass ChatContextDB:\n    def __init__(self, db_path=DB_PATH):\n        self.conn = sqlite3.connect(db_path, check_same_thread=False)\n        self._create_table()\n\n    def _create_table(self):\n        c = self.conn.cursor()\n        c.execute('''CREATE TABLE IF NOT EXISTS chat_context (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            context_json TEXT\n        )''')\n        self.conn.commit..."
  },
  {
    "type": "class",
    "name": "ChatContextDB",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\chat_context_db.py"
  },
  {
    "type": "function",
    "name": "__init__",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\chat_context_db.py"
  },
  {
    "type": "function",
    "name": "_create_table",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\chat_context_db.py"
  },
  {
    "type": "function",
    "name": "load_context",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\chat_context_db.py"
  },
  {
    "type": "function",
    "name": "save_context",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\chat_context_db.py"
  },
  {
    "type": "file",
    "name": "enhanced_context_manager.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\enhanced_context_manager.py",
    "content": "\"\"\"\nEnhanced Context Manager for Development Assistant\nHandles large codebases, JIRA data, and git history efficiently\n\"\"\"\nimport json\nimport sqlite3\nimport hashlib\nfrom pathlib import Path\nfrom typing import Dict, List, Any\nimport os\n\nclass DevelopmentContextManager:\n    def __init__(self, workspace_path: str):\n        self.workspace_path = Path(workspace_path)\n        self.db_path = self.workspace_path / \"dev_context.db\"\n        self.init_database()\n        \n    def init_database(self):\n        \"\"\"Initialize SQLite database for structured storage\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        # Code patterns table\n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS code_patterns (\n                id INTEGER PRIMARY KEY,\n                file_path TEXT,\n                language TEXT,\n                pattern_type TEXT,  -- class, function, variable, etc.\n                code_snippet TEXT,\n                metadata TEXT,  -- JSON string\n                hash TEXT UNIQUE\n            )\n        \"\"\")\n        \n        # JIRA tickets table\n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS jira_tickets (\n                id INTEGER PRIMARY KEY,\n                ticket_id TEXT UNIQUE,\n                title TEXT,\n                description TEXT,\n                status TEXT,\n                assignee TEXT,\n                created_date TEXT,\n                resolved_date TEXT,\n                metadata TEXT\n            )\n        \"\"\")\n        \n        # Git commits table\n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS git_commits (\n                id INTEGER PRIMARY KEY,\n                commit_hash TEXT UNIQUE,\n                author TEXT,\n                date TEXT,\n                message TEXT,\n                files_changed TEXT,  -- JSON array\n                diff_summary TEXT\n            )\n        \"\"\")\n        \n        conn.commit()\n        conn.close()\n    \n    def store_code_pattern(self, file_path: str, language: str, \n                          pattern_type: str, code_snippet: str, \n                          metadata: Dict[str, Any]):\n        \"\"\"Store code patterns with deduplication\"\"\"\n        code_hash = hashlib.md5(code_snippet.encode()).hexdigest()\n        \n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute(\"\"\"\n                INSERT OR REPLACE INTO code_patterns \n                (file_path, language, pattern_type, code_snippet, metadata, hash)\n                VALUES (?, ?, ?, ?, ?, ?)\n            \"\"\", (file_path, language, pattern_type, code_snippet, \n                  json.dumps(metadata), code_hash))\n            conn.commit()\n        except sqlite3.Error as e:\n            print(f\"Error storing code pattern: {e}\")\n        finally:\n            conn.close()\n    \n    def query_similar_patterns(self, query_type: str, language: str = None, \n                              limit: int = 10) -> List[Dict]:\n        \"\"\"Query similar code patterns\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        sql = \"\"\"\n            SELECT file_path, code_snippet, metadata \n            FROM code_patterns \n            WHERE pattern_type = ?\n        \"\"\"\n        params = [query_type]\n        \n        if language:\n            sql += \" AND language = ?\"\n            params.append(language)\n            \n        sql += f\" LIMIT {limit}\"\n        \n        cursor.execute(sql, params)\n        results = cursor.fetchall()\n        conn.close()\n        \n        return [{\"file_path\": r[0], \"code\": r[1], \"metadata\": json.loads(r[2])} \n                for r in results]\n    \n    def get_folder_structure_examples(self, language: str) -> Dict[str, List[str]]:\n        \"\"\"Get common folder structures for a language\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n            SELECT DISTINCT file_path FROM code_patterns \n            WHERE language = ?\n        \"\"\", (language,))\n        \n        file_paths = [row[0] for row in cursor.fetchall()]\n        conn.close()\n        \n        # Analyze folder patterns\n        folders = {}\n        for path in file_paths:\n            parts = Path(path).parts\n            if len(parts) > 1:\n                folder = parts[-2]  # Parent folder\n                if folder not in folders:\n                    folders[folder] = []\n                folders[folder].append(Path(path).name)\n        \n        return folders\n    \n    def get_naming_conventions(self, language: str, pattern_type: str) -> List[str]:\n        \"\"\"Extract naming conventions from existing code\"\"\"\n        patterns = self.query_similar_patterns(pattern_type, language)\n        names = []\n        \n        for pat..."
  },
  {
    "type": "class",
    "name": "DevelopmentContextManager",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\enhanced_context_manager.py"
  },
  {
    "type": "function",
    "name": "get_context_manager",
    "doc": "Get or create global context manager instance",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\enhanced_context_manager.py"
  },
  {
    "type": "function",
    "name": "scan_codebase",
    "doc": "Tool to scan and analyze codebase patterns",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\enhanced_context_manager.py"
  },
  {
    "type": "function",
    "name": "analyze_jira_history",
    "doc": "Tool to analyze JIRA ticket patterns",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\enhanced_context_manager.py"
  },
  {
    "type": "function",
    "name": "check_git_conventions",
    "doc": "Tool to check git commit conventions",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\enhanced_context_manager.py"
  },
  {
    "type": "function",
    "name": "__init__",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\enhanced_context_manager.py"
  },
  {
    "type": "function",
    "name": "init_database",
    "doc": "Initialize SQLite database for structured storage",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\enhanced_context_manager.py"
  },
  {
    "type": "function",
    "name": "store_code_pattern",
    "doc": "Store code patterns with deduplication",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\enhanced_context_manager.py"
  },
  {
    "type": "function",
    "name": "query_similar_patterns",
    "doc": "Query similar code patterns",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\enhanced_context_manager.py"
  },
  {
    "type": "function",
    "name": "get_folder_structure_examples",
    "doc": "Get common folder structures for a language",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\enhanced_context_manager.py"
  },
  {
    "type": "function",
    "name": "get_naming_conventions",
    "doc": "Extract naming conventions from existing code",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\enhanced_context_manager.py"
  },
  {
    "type": "file",
    "name": "llm_provider.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\llm_provider.py",
    "content": "import os\nimport json\nimport pathlib\n\nclass LLMProvider:\n    def __init__(self, provider=\"openai\"):\n        self.provider = provider\n        self.api_key = self._get_api_key()\n\n        if provider == \"openai\":\n            import openai\n            self.client = openai.OpenAI(api_key=self.api_key)\n        elif provider == \"mistral\":\n            from mistralai.client import MistralClient\n            self.client = MistralClient(api_key=self.api_key)\n        else:\n            raise ValueError(\"Unsupported provider\")\n\n    def _get_api_key(self):\n        env_key = os.environ.get(\"OPENAI_API_KEY\") if self.provider == \"openai\" else os.environ.get(\"MISTRAL_API_KEY\")\n        if env_key:\n            return env_key\n        root = pathlib.Path(__file__).parent\n        settings_path = root / \"settings.json\"\n        if settings_path.exists():\n            with open(settings_path, \"r\", encoding=\"utf-8\") as s:\n                cfg = json.load(s)\n                key_name = \"OPENAI_API_KEY\" if self.provider == \"openai\" else \"MISTRAL_API_KEY\"\n                return cfg.get(key_name)\n        raise RuntimeError(f\"{self.provider} API key not found.\")\n\n    def chat_completion(self, messages, model=\"gpt-4o\", temperature=0.2, max_tokens=2000, functions=None, function_call=None):\n        if self.provider == \"openai\":\n            kwargs = {\n                \"model\": model,\n                \"messages\": messages,\n                \"temperature\": temperature,\n      ..."
  },
  {
    "type": "class",
    "name": "LLMProvider",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\llm_provider.py"
  },
  {
    "type": "function",
    "name": "__init__",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\llm_provider.py"
  },
  {
    "type": "function",
    "name": "_get_api_key",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\llm_provider.py"
  },
  {
    "type": "function",
    "name": "chat_completion",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\llm_provider.py"
  },
  {
    "type": "file",
    "name": "LOCAL_ACCESS_GUIDE.md",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\LOCAL_ACCESS_GUIDE.md",
    "content": "# Local Access Guide\n\n## API Keys and Sensitive Files\n\n- Your `settings.json` file contains sensitive information such as your OpenAI API key.\n- This file is now included in `.gitignore` and will **not** be tracked by git. It will always remain in your local workspace.\n- Do **not** share or commit `settings.json` to any public or shared repository.\n\n## How to Use\n\n1. **Keep your `settings.json` file in the project root.**\n2. **Update your API key or m..."
  },
  {
    "type": "file",
    "name": "multi-agent.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\multi-agent.py",
    "content": "\"\"\"\nMulti-agent workflow using OpenAI Agentic SDK for autonomous tool selection and chaining.\nParses user prompt, selects tools from tools.json, and executes multi-step workflows.\nEnhanced with approval handling, context persistence, and intelligent data passing.\n\"\"\"\nimport json\nimport pathlib\nimport importlib\nimport sys\nfrom dotenv import load_dotenv\nimport os\n\n\n# Load environment variables from .env file\nload_dotenv()\n\nfrom langchain_openai import OpenAI\nsys.path.append(os.path.join(os.path.dirname(__file__), 'tools'))\n\nfrom llm_provider import LLMProvider\nfrom langchain.agents import Tool, AgentExecutor, create_openai_functions_agent\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.memory import ConversationBufferMemory\n\nsys.path.append(str(pathlib.Path(__file__).parent))\nTOOLS_PATH = pathlib.Path(__file__).parent / \"tools.json\"\nCONTEXT_PATH = pathlib.Path(__file__).parent / \"output\" / \"workflow_context.json\"\n\n# Load tool definitions\nwith open(TOOLS_PATH, \"r\", encoding=\"utf-8\") as f:\n    tools_config = json.load(f)\n\n# Build OpenAI function definitions from tools.json\nopenai_functions = []\nfor tool in tools_config:\n    openai_functions.append({\n        \"name\": tool[\"name\"],\n        \"description\": tool[\"description\"],\n        \"parameters\": tool[\"args_schema\"]\n    })\n\n# Initialize tool_map with tools from tools.json\ntool_map = {}\nfor tool in tools_config:\n    module_path = tool.get(\"module\")\n    func_name = tool[\"name\"]\n    \n    # Handle modules in main folder vs tools folder\n    if module_path.startswith(\"tools.\"):\n        import_path = module_path\n    else:\n        # For modules in main folder like chatbot\n        import_path = module_path\n    \n    mod = importlib.import_module(import_path)\n    tool_map[func_name] = getattr(mod, func_name)\n\n# Initialize tools\nfrom langchain.agents import Tool, AgentExecutor\nfrom tools.development.jira_tools import jira_ticket_summarizer\n\ntools = [\n    Tool(\n        name=\"jira_ticket_summarizer\",\n        func=jira_ticket_summarizer,\n        description=\"Fetch JIRA tickets, summarize them into a PRD, and save the context in JSON format.\"\n    )\n]\n\n# Initialize memory\nmemory = ConversationBufferMemory()\n\n# Initialize LLM\nopenai_api_key = os.getenv(\"OPENAI_API_KEY\")\nif not openai_api_key:\n    # Try to read from settings.json\n    settings_path = pathlib.Path(__file__).parent / \"settings.json\"\n    if settings_path.exists():\n        with open(settings_path, \"r\", encoding=\"utf-8\") as f:\n            try:\n                settings = json.load(f)\n                openai_api_key = settings.get(\"OPENAI_API_KEY\")\n            except Exception:\n                openai_api_key = None\n    if not openai_api_key:\n        openai_api_key = input(\"Enter your OpenAI API key: \").strip()\nllm = OpenAI(model=\"gpt-4\", openai_api_key=openai_api_key)\n\n# Create a prompt for the agent\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a helpful multi-agent assistant. Use tools as needed to solve the user's request. {agent_scratchpad}\"),\n    (\"user\", \"{input}\")\n])\nagent = create_openai_functions_agent(llm, tools, prompt)\nagent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory)\n\n# Helper: Save workflow context\ndef save_context(context):\n    CONTEXT_PATH.parent.mkdir(exist_ok=True)\n    with open(CONTEXT_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(context, f, indent=2)\n\n# Helper: Load workflow context\ndef load_context():\n    if CONTEXT_PATH.exists():\n        with open(CONTEXT_PATH, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    return {\"execution_history\": [], \"data_context\": {}}\n\n# Helper: Dynamically import and call a tool\ndef call_tool(tool_name, args):\n    tool = next((t for t in tools_config if t[\"name\"] == tool_name), None)\n    if not tool:\n        raise ValueError(f\"Tool {tool_name} not found ..."
  },
  {
    "type": "function",
    "name": "save_context",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\multi-agent.py"
  },
  {
    "type": "function",
    "name": "load_context",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\multi-agent.py"
  },
  {
    "type": "function",
    "name": "call_tool",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\multi-agent.py"
  },
  {
    "type": "class",
    "name": "MultiAgent",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\multi-agent.py"
  },
  {
    "type": "function",
    "name": "run_agent",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\multi-agent.py"
  },
  {
    "type": "function",
    "name": "__init__",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\multi-agent.py"
  },
  {
    "type": "function",
    "name": "run",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\multi-agent.py"
  },
  {
    "type": "file",
    "name": "PRESENTATION_ARCHITECTURE.md",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\PRESENTATION_ARCHITECTURE.md",
    "content": "# MCP Server Infrastructure Deployment\n## DevOps Engineer Presentation\n\n---\n\n## \ud83c\udfaf **Project Overview**\n\n### **What is MCP (Model Context Protocol)?**\n- **MCP** is a protocol that enables AI assistants to connect to external data sources and tools\n- Provides **real-time access** to databases, APIs, and external services\n- Enables **context-aware** AI responses with live data integration\n\n### **Our Implementation**\n- **Multi-Agent AI System** with PostgreSQL and Redis backend\n- **Dockerized microservices** architecture\n- **AWS EC2** deployment with automated infrastructure\n- **Health monitoring** and automated scaling capabilities\n\n---\n\n## \ud83c\udfd7\ufe0f **System Architecture**\n\n### **High-Level Architecture**\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Client Apps   \u2502    \u2502   Load Balancer \u2502    \u2502   MCP Server    \u2502\n\u2502   (Web/Mobile)  \u2502\u25c4\u2500\u2500\u25ba\u2502   (Future)      \u2502\u25c4\u2500\u2500\u25ba\u2502   (Port 8000)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                        \u2502\n                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                       \u2502   PostgreSQL    \u2502    \u2502     Redis       \u2502\n                       \u2502   (Port 5432)   \u2502    \u2502   (Port 6379)   \u2502\n                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### **Component Details**\n\n#### **1. MCP Server (Flask Application)**\n- **Technology**: Python Flask + LangChain\n- **Port**: 8000\n- **Features**:\n  - RESTful API endpoints\n  - AI model integration\n  - Tool registry and management\n  - Multi-agent coordination\n\n#### **2. PostgreSQL Database**\n- **Version**: 12.20\n- **Port**: 5432\n- **Purpose**: \n  - Persistent data storage\n  - User session management\n  - Conversation history\n  - Tool configurations\n\n#### **3. Redis Cache**\n- **Version**: 7-alpine\n- **Port**: 6379\n- **Purpose**:\n  - Session caching\n  - Real-time data storage\n  - Performance optimization\n  - Temporary context storage\n\n---\n\n## \ud83d\ude80 **Deployment Workflow**\n\n### **Phase 1: Infrastructure Setup**\n```bash\n# 1. EC2 Instance Creation\naws ec2 run-instances \\\n  --image-id ami-0c02fb55956c7d316 \\\n  --instance-type t3.medium \\\n  --key-name Minds-Constructing-Products-key \\\n  --security-group-ids sg-xxxxxxxxx\n\n# 2. Security Group Configuration\n- SSH (Port 22)\n- HTTP (Port 80)\n- HTTPS (Port 443)\n- Custom TCP (Port 8000) - MCP Server\n- Custom TCP (Port 5432) - PostgreSQL\n- Custom TCP (Port 6379) - Redis\n```\n\n### **Phase 2: Application Deployment**\n```bash\n# 1. System Updates\nsudo yum update -y\n\n# 2. Docker Installation\nsudo yum install -y docker\nsudo systemctl start docker\nsudo systemctl enable docker\n\n# 3. Docker Compose Installation\nsudo curl -L \"https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\nsudo chmod +x /usr/local/bin/docker-compose\n\n# 4. PostgreSQL Setup\nsudo yum install -y postgresql postgresql-server postgresql-contrib\nsudo /usr/bin/postgresql-setup initdb\nsudo systemctl enable postgresql\nsudo systemctl start postgresql\n\n# 5. Database Configuration\nsudo -u postgres psql -c \"CREATE USER mcp_admin WITH PASSWORD 'mcp_password_123';\"\nsudo -u postgres psql -c \"CREATE DATABASE mcp_assistant OWNER mcp_admin;\"\nsudo -u postgres psql -c \"GRANT ALL PRIVILEGES ON DATABASE mcp_assistant TO mcp_admin;\"\n```\n\n### **Phase 3: Application Containerization**\n```bash\n# 1. Application Setup\ncd /opt/mcp-server\ngit clone <repository>\ncd MCP-hackathon\n\n# 2. Docker Configuration\ncat > Dockerfile << 'EOF'\nFROM python:3.9-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\nCOPY . .\nEXPOSE 8000\nCMD [\"python\", \"server.py\"]\nEOF\n\n# 3. Docker Compose Configuration\ncat > docker-compose.yml << 'EOF'\nversion: '3.8'\nservices:\n  mcp-server:\n    build: .\n    ports:\n      - \"8000:8000\"\n    environment:\n      - DATABASE_URL=postgresql://mcp_admin:mcp_password_123@host.docker.internal:5432/mcp_assistant\n      - REDIS_URL=redis://redis:6379\n    depends_on:\n      - redis\n    networks:\n      - mcp-network\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  redis:\n    image: redis:7-alpine\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - redis_data:/data\n    networks:\n      - mcp-network\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\nvolumes:\n  redis_data:\n\nnetworks:\n  mcp-network:\n    driver: bridge\nEOF\n\n# 4. Application Deployment\ndocker-compose up -d --build\n```\n\n---\n\n## \ud83d\udd27 **Technical Implementation**\n\n### **Key Technologies Used**\n\n#### **Backend Stack**\n- **Python 3.9**: Core application language\n- **Flask**: Web framework for REST API\n- **LangChain**: AI/LLM integration framework\n- **PostgreSQL**: Primary database\n- **Redis**: Caching and session management\n\n#### **Infrastructure Stack**\n- **AWS EC2**: Cloud compute instance\n- **Docker**: Containerization platform\n- **Docker Compose**: Multi-container orchestration\n- **Terraform**: Infrastructure as Code (optional)\n\n#### **Monitoring & Health Checks**\n- **Docker Health Checks**: Container health monitoring\n- **Flask Health Endpoints**: Application status monitoring\n- **Systemd Services**: System-level service management\n\n### **Security Implementation**\n\n#### **Network Security**\n```bash\n# Security Group Rules\n- SSH (22): Restricted to specific IPs\n- HTTP (80): Public access for web interface\n- Custom TCP (8000): MCP Server API..."
  },
  {
    "type": "file",
    "name": "PRESENTATION_SLIDES.md",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\PRESENTATION_SLIDES.md",
    "content": "# MCP Server Infrastructure Deployment\n## DevOps Engineer Presentation Slides\n\n---\n\n## Slide 1: Title Slide\n# \ud83d\ude80 MCP Server Infrastructure Deployment\n### **Model Context Protocol Implementation**\n**Presented by: DevOps Engineering Team**  \n**Date: August 2025**\n\n---\n\n## Slide 2: Executive Summary\n# \ud83d\udcca **Project Overview**\n\n### **What We Built**\n- **Multi-Agent AI System** with real-time data integration\n- **Dockerized microservices** architecture on AWS\n- **Production-ready** infrastructure with monitoring\n\n### **Key Metrics**\n- \u2705 **100% Uptime** since deployment\n- \u2705 **< 100ms** response time\n- \u2705 **99.9%** system reliability\n- \u2705 **Zero** security incidents\n\n---\n\n## Slide 3: What is MCP?\n# \ud83e\udd16 **Model Context Protocol (MCP)**\n\n### **Definition**\nMCP enables AI assistants to connect to external data sources and tools in real-time\n\n### **Benefits**\n- **Real-time Data Access**: Live database connections\n- **Context-Aware Responses**: AI with current information\n- **Tool Integration**: External API and service connections\n- **Scalable Architecture**: Microservices design\n\n### **Use Cases**\n- Customer support automation\n- Data analysis and reporting\n- Real-time decision making\n- Multi-source information synthesis\n\n---\n\n## Slide 4: System Architecture\n# \ud83c\udfd7\ufe0f **Technical Architecture**\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Client Apps   \u2502    \u2502   Load Balancer \u2502    \u2502   MCP Server    \u2502\n\u2502   (Web/Mobile)  \u2502\u25c4\u2500\u2500\u25ba\u2502   (Future)      \u2502\u25c4\u2500\u2500\u25ba\u2502   (Port 8000)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                        \u2502\n                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                       \u2502   PostgreSQL    \u2502    \u2502     Redis       \u2502\n                       \u2502   (Port 5432)   \u2502    \u2502   (Port 6379)   \u2502\n                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### **Components**\n- **MCP Server**: Python Flask + LangChain\n- **PostgreSQL**: Persistent data storage\n- **Redis**: Caching and session management\n- **Docker**: Containerization platform\n\n---\n\n## Slide 5: Technology Stack\n# \ud83d\udee0\ufe0f **Technology Stack**\n\n### **Backend Technologies**\n- **Python 3.9**: Core application language\n- **Flask**: Web framework for REST API\n- **LangChain**: AI/LLM integration framework\n- **PostgreSQL 12.20**: Primary database\n- **Redis 7**: Caching and session management\n\n### **Infrastructure Technologies**\n- **AWS EC2**: Cloud compute instance (t3.medium)\n- **Docker**: Containerization platform\n- **Docker Compose**: Multi-container orchestration\n- **Terraform**: Infrastructure as Code\n\n### **Monitoring & Security**\n- **Health Checks**: Automated monitoring\n- **Security Groups**: Network-level security\n- **Container Security**: Non-root execution\n\n---\n\n## Slide 6: Deployment Workflow\n# \ud83d\udd04 **Deployment Process**\n\n### **Phase 1: Infrastructure Setup**\n1. **EC2 Instance Creation** (t3.medium)\n2. **Security Group Configuration**\n3. **Docker Installation & Configuration**\n\n### **Phase 2: Application Deployment**\n1. **PostgreSQL Setup & Configuration**\n2. **Redis Installation & Configuration**\n3. **Application Containerization**\n\n### **Phase 3: Production Deployment**\n1. **Docker Compose Deployment**\n2. **Health Check Validation**\n3. **Performance Testing**\n\n---\n\n## Slide 7: Security Implementation\n# \ud83d\udd12 **Security Architecture**\n\n### **Network Security**\n- **SSH (Port 22)**: Restricted access\n- **HTTP (Port 80)**: Public web interface\n- **Custom TCP (Port 8000)**: MCP Server API\n- **Custom TCP (Port 5432)**: PostgreSQL (internal)\n- **Custom TCP (Port 6379)**: Redis (internal)\n\n### **Application Security**\n- **Database Authentication**: Encrypted connections\n- **API Authentication**: JWT token-based access\n- **Container Security**: Non-root user execution\n- **Network Isolation**: Docker bridge networks\n\n### **Compliance**\n- **Data Encryption**: In-transit and at-rest\n- **Access Control**: Role-based permissions\n- **Audit Logging**: Comprehensive activity tracking\n\n---\n\n## Slide 8: Performance Metrics\n# \ud83d\udcc8 **Performance & Monitoring**\n\n### **Current Performance**\n- **Response Time**: < 100ms for health checks\n- **Uptime**: 99.9% since deployment\n- **CPU Usage**: 15% average\n- **Memory Usage**: 45% average\n- **Disk Usage**: 30% of allocated space\n\n### **Health Monitoring**\n```json\n{\n  \"status\": \"healthy\",\n  \"service\": \"mcp-server\",\n  \"postgresql\": \"connected\",\n  \"redis\": \"connected\",\n  \"timestamp\": \"2025-08-02T13:55:00Z\"\n}\n```\n\n### **Monitoring Tools**\n- **Docker Health Checks**: Container monitoring\n- **Flask Health Endpoints**: Application status\n- **Systemd Services**: System-level monitoring\n\n---\n\n## Slide 9: Deployment Status\n# \u2705 **Current Deployment Status**\n\n### **Infrastructure Status**\n- \u2705 **EC2 Instance**: Running (t3.medium)\n- \u2705 **Security Groups**: Configured and secured\n- \u2705 **Docker**: Installed and operational\n- \u2705 **PostgreSQL**: Running and configured\n- \u2705 **Redis**: Running and healthy\n- \u2705 **MCP Server**: Deployed and responding\n\n### **Application Status**\n- \u2705 **Health Endpoint**: `http://3.109.155.48:8000/health`\n- \u2705 **Main API**: `http://3.109.155.48:8000/`\n- \u2705 **Database**: Connected and operational\n- \u2705 **Cache**: Connected and operational\n\n### **Container Status**\n- \u2705 **mcp-server**: Healthy and running\n- \u2705 **redis**: Healthy and running\n- \u2705 **All containers**: Operational\n\n---\n\n## Slide 10: Benefits & ROI\n# \ud83d\udcb0 **Business Benefits**\n\n### **Operational Benefits**\n- **Reduced Response Time**: Real-time data access\n- **Improved Accuracy**: Context-aware AI responses\n- **Scalability**: Easy horizontal scaling\n- **Reliability**: 99.9% uptime guarantee\n\n### **Cost Benefits**\n- **Infrastructure Cost**: $50/month (t3.medium)\n- **Development Time**: 40% faster with containerization\n- **Maintenance Cost**: 60% reduction with automation\n- **Deployment Time**: 90% faster with Docker\n\n### **Technical Benefits**\n- **Microservices Architecture**: Independent scaling\n- **Container Orchestration**: Easy management\n- **Health Monitoring**: Proactive issue detection\n- **Security**: Enterprise-grade pro..."
  },
  {
    "type": "file",
    "name": "README.md",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\README.md",
    "content": "# MCP Server (LangChain Edition)\n\nThis project is a Multi-Agent Control Plane (MCP) server using [LangChain](https://github.com/langchain-ai/langchain), [FastAPI](https://fastapi.tiangolo.com/), and dynamic tool orchestration.\n\n## Features\n- **LangChain Tool Integration**: All tools are defined as LangChain-compatible Python functions and loaded dynamically from `tools.json`.\n- **REST API**: Exposes `/tools` (list tools) and `/tools/execute` (run a tool) endpoints.\n- **SQLite Logging**: Tool executions and errors are logged to SQLite.\n- **Agentic Workflows**: Ready for multi-agent and LLM-based orchestration.\n\n## Quickstart\n1. **Install dependencies**\n   ```sh\n   pip install -r requirements.txt\n   ```\n2. **Run the server**\n   ```sh\n   python -m uvicorn mcp_server.server:app --reload --port 8000\n   ```\n3. **List available tools**\n   ```sh\n   curl ..."
  },
  {
    "type": "file",
    "name": "README_PRESENTATION.md",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\README_PRESENTATION.md",
    "content": "# MCP Server Deployment Presentation Package\n## DevOps Engineer Guide\n\nThis package contains comprehensive presentation materials for showcasing the MCP (Model Context Protocol) server infrastructure deployment to stakeholders.\n\n---\n\n## \ud83d\udcc1 **Presentation Package Contents**\n\n### **Core Documents**\n1. **`PRESENTATION_ARCHITECTURE.md`** - Comprehensive technical documentation\n2. **`PRESENTATION_SLIDES.md`** - PowerPoint-style presentation slides\n3. **`ARCHITECTURE_DIAGRAM.md`** - Detailed architecture diagrams and technical specifications\n4. **`README_PRESENTATION.md`** - This guide for presenters\n\n### **Additional Resources**\n- **Working Infrastructure**: Live deployment at `http://3.109.155.48:8000`\n- **Health Endpoint**: `http://3.109.155.48:8000/health`\n- **API Documentation**: Available in the main project README\n\n---\n\n## \ud83c\udfaf **Presentation Objectives**\n\n### **Primary Goals**\n- Demonstrate successful infrastructure deployment\n- Showcase technical architecture and capabilities\n- Highlight business value and ROI\n- Secure stakeholder approval for production use\n\n### **Key Messages**\n1. **Technical Excellence**: Enterprise-grade infrastructure with 99.9% uptime\n2. **Business Value**: 40% cost reduction, 90% faster deployments\n3. **Security**: Comprehensive security implementation\n4. **Scalability**: Future-ready architecture for growth\n\n---\n\n## \ud83d\udcca **Current Deployment Status**\n\n### **\u2705 Infrastructure Status**\n- **EC2 Instance**: Running (t3.medium) - $37/month\n- **MCP Server**: Healthy on port 8000\n- **PostgreSQL**: Connected and operational on port 5432\n- **Redis**: Healthy and operational on port 6379\n- **Docker Containers**: All containers healthy\n\n### **\u2705 Performance Metrics**\n- **Response Time**: < 100ms for health checks\n- **Uptime**: 99.9% since deployment\n- **Error Rate**: < 0.1%\n- **Security Incidents**: 0\n\n### **\u2705 Health Check Response**\n```json\n{\n  \"status\": \"healthy\",\n  \"service\": \"mcp-server\",\n  \"postgresql\": \"connected\",\n  \"redis\": \"connected\",\n  \"timestamp\": \"2025-08-02T13:55:00Z\"\n}\n```\n\n---\n\n## \ud83c\udfa4 **Presentation Guidelines**\n\n### **Before the Presentation**\n1. **Test the Live Demo**\n   ```bash\n   # Test health endpoint\n   curl -f http://3.109.155.48:8000/health\n   \n   # Test main endpoint\n   curl http://3.109.155.48:8000/\n   ```\n\n2. **Prepare Your Environment**\n   - Have all presentation files ready\n   - Test screen sharing and video conferencing tools\n   - Prepare backup slides in case of technical issues\n\n3. **Know Your Audience**\n   - **Technical Stakeholders**: Focus on architecture and performance\n   - **Business Stakeholders**: Emphasize ROI and business value\n   - **Security Stakeholders**: Highlight security implementation\n\n### **During the Presentation**\n\n#### **Opening (5 minutes)**\n- Introduce the project and team\n- Explain what MCP is and why it's important\n- Show the current deployment status\n\n#### **Technical Deep Dive (15 minutes)**\n- Walk through the architecture diagrams\n- Explain the technology stack\n- Demonstrate the deployment process\n- Show live health checks\n\n#### **Business Value (10 minutes)**\n- Present cost analysis and ROI\n- Discuss performance metrics\n- Highlight scalability benefits\n- Address risk mitigation\n\n#### **Future Roadmap (5 minutes)**\n- Outline Phase 2 and 3 plans\n- Discuss enhancement opportunities\n- Present timeline and milestones\n\n#### **Q&A Session (10 minutes)**\n- Address technical questions\n- Discuss business concerns\n- Handle security inquiries\n- Provide next steps\n\n### **Presentation Tips**\n1. **Start with the Big Picture**: Explain MCP and its business value\n2. **Show Live Demos**: Demonstrate working endpoints\n3. **Use Visual Aids**: Reference architecture diagrams\n4. **Address Concerns**: Be prepared for security and cost questions\n5. **End with Action Items**: Clear next steps and timeline\n\n---\n\n## \ud83d\udd27 **Technical Demo Script**\n\n### **Demo 1: Health Check**\n```bash\n# Show the audience the health endpoint\ncurl -f http://3.109.155.48:8000/health\n\n# Expected response:\n{\n  \"status\": \"healthy\",\n  \"service\": \"mcp-server\",\n  \"postgresql\": \"connected\",\n  \"redis\": \"connected\",\n  \"timestamp\": \"2025-08-02T13:55:00Z\"\n}\n```\n\n### **Demo 2: Main API**\n```bash\n# Show the main API endpoint\ncurl http://3.109.155.48:8000/\n\n# Expected response:\n{\n  \"endpoints\": {\n    \"health\": \"/health\",\n    \"home\": \"/\"\n  },\n  \"message\": \"MCP Server is running!\",\n  \"version\": \"1.0.0\"\n}\n```\n\n### **Demo 3: Container Status**\n```bash\n# Show Docker container status\ndocker ps\n\n# Expected output:\n# CONTAINER ID   IMAGE                   COMMAND                  STATUS\n# 73be2f914793   mcp-server-mcp-server   \"python server.py\"       Up 5 minutes (healthy)\n# 1cd356f3b970   redis:7-alpine        ..."
  },
  {
    "type": "file",
    "name": "requirements.txt",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\requirements.txt",
    "content": "fastapi\nuvicorn\nstreamlit\nlangchain>=0.1.47\nlangchain-openai\nopenai\nrequests\nbeautifu..."
  },
  {
    "type": "file",
    "name": "streamlit_app.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py",
    "content": "#!/usr/bin/env python3\n\"\"\"\nProfessional MCP Tools Suite\nEnterprise-grade tool execution and management platform\n\"\"\"\n\nimport streamlit as st\nimport json\nimport os\nimport sys\nimport importlib\nimport traceback\nfrom datetime import datetime, timedelta\nfrom typing import List, Dict, Any\nimport uuid\nimport hashlib\n\n# Add tools directory to Python path\nsys.path.append('tools')\nsys.path.append(os.path.join(os.path.dirname(__file__), 'tools'))\n\n# Try to import chatbot components with graceful fallback\ntry:\n    from chatbot import Chatbot, question_answering\n    CHATBOT_AVAILABLE = True\nexcept ImportError as e:\n    CHATBOT_AVAILABLE = False\n    IMPORT_ERROR = str(e)\n\n# Try to import bot.py for chat functionality\ntry:\n    from bot import chat_with_bot\n    BOT_AVAILABLE = True\nexcept ImportError as e:\n    BOT_AVAILABLE = False\n    BOT_IMPORT_ERROR = str(e)\n    \n    # Fallback function\n    def chat_with_bot(user_input):\n        return \"Bot is not available. Please ensure bot.py is properly configured with OpenAI API key and FAISS index.\"\n    \n    # Fallback classes for demo mode\n    class Chatbot:\n        def __init__(self, **kwargs):\n            pass\n        def chat(self, message):\n            return \"System in demo mode. Install dependencies for full functionality: pip install langchain-openai langchain\"\n    \n    def question_answering(query):\n        return \"System in demo mode. Install dependencies for full functionality.\"\n\n# Configure Streamlit with professional settings\nst.set_page_config(\n    page_title=\"MCP AI Assistant Suite\",\n    page_icon=\"\ud83e\udd16\",\n    layout=\"wide\",\n    initial_sidebar_state=\"collapsed\"\n)\n\n# Professional CSS styling with business-standard design\nst.markdown(\"\"\"\n<style>\n    /* Professional color scheme */\n    :root {\n        --primary-navy: #1a365d;\n        --secondary-blue: #2b77d9;\n        --accent-teal: #319795;\n        --success-green: #38a169;\n        --warning-amber: #d69e2e;\n        --danger-red: #e53e3e;\n        --neutral-50: #f7fafc;\n        --neutral-100: #edf2f7;\n        --neutral-200: #e2e8f0;\n        --neutral-300: #cbd5e0;\n        --neutral-700: #4a5568;\n        --neutral-800: #2d3748;\n        --neutral-900: #1a202c;\n    }\n    \n    /* Hide Streamlit branding for professional appearance */\n    #MainMenu {visibility: hidden;}\n    footer {visibility: hidden;}\n    header {visibility: hidden;}\n    .css-1rs6os {visibility: hidden;}\n    .css-17ziqus {visibility: hidden;}\n    \n    /* Main application header */\n    .main-header {\n        background: linear-gradient(135deg, var(--primary-navy) 0%, var(--secondary-blue) 100%);\n        padding: 2rem 3rem 1.5rem 3rem;\n        margin: -1rem -1rem 2rem -1rem;\n        color: white;\n        border-radius: 0 0 16px 16px;\n        box-shadow: 0 8px 32px rgba(26, 54, 93, 0.15);\n    }\n    \n    .header-content {\n        display: flex;\n        align-items: center;\n        justify-content: space-between;\n        max-width: 1200px;\n        margin: 0 auto;\n    }\n    \n    .brand-section {\n        display: flex;\n        align-items: center;\n        gap: 1.5rem;\n    }\n    \n    .brand-icon {\n        width: 48px;\n        height: 48px;\n        background: rgba(255, 255, 255, 0.15);\n        border-radius: 12px;\n        display: flex;\n        align-items: center;\n        justify-content: center;\n        font-size: 1.5rem;\n        backdrop-filter: blur(10px);\n        border: 1px solid rgba(255, 255, 255, 0.2);\n    }\n    \n    .brand-text h1 {\n        font-size: 2rem;\n        font-weight: 700;\n        margin: 0 0 0.25rem 0;\n        letter-spacing: -0.025em;\n    }\n    \n    .brand-text .tagline {\n        font-size: 0.95rem;\n        opacity: 0.85;\n        font-weight: 400;\n        margin: 0;\n    }\n    \n    .system-status {\n        display: flex;\n        align-items: center;\n        background: rgba(56, 161, 105, 0.2);\n        color: white;\n        padding: 0.5rem 1rem;\n        border-radius: 8px;\n        font-size: 0.875rem;\n        font-weight: 600;\n        border: 1px solid rgba(255, 255, 255, 0.2);\n    }\n    \n    .status-indicator {\n        width: 8px;\n        height: 8px;\n        background: #38a169;\n        border-radius: 50%;\n        margin-right: 0.5rem;\n        animation: pulse 2s infinite;\n    }\n    \n    @keyframes pulse {\n        0% { opacity: 1; transform: scale(1); }\n        50% { opacity: 0.7; transform: scale(1.1); }\n        100% { opacity: 1; transform: scale(1); }\n    }\n    \n    /* Tool cards with professional styling */\n    .tool-card {\n        background: white;\n        border: 1px solid var(--neutral-200);\n        border-radius: 12px;\n        padding: 2rem;\n        margin: 1.5rem 0;\n        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.05);\n        transition: all 0.3s ease;\n        border-left: 4px solid var(--accent-teal);\n    }\n    \n    .tool-card:hover {\n        transform: translateY(-4px);\n        box-shadow: 0 12px 32px rgba(0, 0, 0, 0.12);\n        border-left-color: var(--secondary-blue);\n    }\n    \n    .tool-header {\n        display: flex;\n        align-items: center;\n        justify-content: space-between;\n        margin-bottom: 1rem;\n    }\n    \n    .tool-title {\n        font-size: 1.25rem;\n        font-weight: 600;\n        color: var(--neutral-800);\n        margin: 0;\n    }\n    \n    .tool-category {\n        background: var(--neutral-100);\n        color: var(--neutral-700);\n        padding: 0.25rem 0.75rem;\n        border-radius: 6px;\n        font-size: 0.75rem;\n        font-weight: 500;\n        text-transform: uppercase;\n        letter-spacing: 0.05em;\n    }\n    \n    .tool-description {\n        color: var(--neutral-700);\n        line-height: 1.6;\n        margin: 0 0 1.5rem 0;\n    }\n    \n    .tool-status {\n        display: inline-flex;\n        align-items: center;\n        padding: 0.375rem 0.875rem;\n        border-radius: 8px;\n        font-size: 0.875rem;\n        font-weight: 500;\n        margin-right: 0.5rem;\n    }\n    \n    .status-available {\n        background: rgba(56, 161, 105, 0.1);\n        color: var(--success-green);\n        border: 1px solid rgba(56, 161, 105, 0.2);\n    }\n    \n    .status-error {\n        background: rgba(229, 62, 62, 0.1);\n        color: var(--danger-red);\n        border: 1px solid rgba(229, 62, 62, 0.2);\n    }\n    \n    .status-warning {\n        background: rgba(214, 158, 46, 0.1);\n        color: var(--warning-amber);\n        border: 1px solid rgba(214, 158, 46, 0.2);\n    }\n    \n    /* Execution interface styling */\n    .execution-panel {\n        background: var(--neutral-50);\n        border: 1px solid var(--neutral-200);\n        border-radius: 12px;\n        padding: 2rem;\n        margin: 1.5rem 0;\n    }\n    \n    .execution-header {\n        font-size: 1.125rem;\n        font-weight: 600;\n        color: var(--neutral-800);\n        margin: 0 0 1.5rem 0;\n        padding-bottom: 0.75rem;\n        border-bottom: 2px solid var(--neutral-200);\n    }\n    \n    .parameter-group {\n        margin-bottom: 1.5rem;\n    }\n    \n    .parameter-label {\n        display: block;\n        font-weight: 600;\n        color: var(--neutral-700);\n        margin-bottom: 0.5rem;\n    }\n    \n    .required-indicator {\n        color: var(--danger-red);\n        margin-left: 0.25rem;\n    }\n    \n    /* Results display */\n    .result-container {\n        background: white;\n        border: 1px solid var(--neutral-200);\n        border-radius: 12px;\n        overflow: hidden;\n        margin: 1.5rem 0;\n        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n    }\n    \n    .result-header {\n        background: var(--neutral-100);\n        padding: 1rem 1.5rem;\n        border-bottom: 1px solid var(--neutral-200);\n        display: flex;\n        align-items: center;\n        justify-content: space-between;\n    }\n    \n    .result-title {\n        font-weight: 600;\n        color: var(--neutral-800);\n        margin: 0;\n    }\n    \n    .execution-time {\n        font-size: 0.875rem;\n        color: var(--neutral-700);\n        background: white;\n        padding: 0.25rem 0.75rem;\n        border-radius: 6px;\n        border: 1px solid var(--neutral-300);\n    }\n    \n    .result-content {\n        padding: 1.5rem;\n        max-height: 400px;\n        overflow-y: auto;\n    }\n    \n    /* Professional buttons */\n    .stButton > button {\n        background: linear-gradient(135deg, var(--primary-navy) 0%, var(--secondary-blue) 100%);\n        color: white;\n        border: none;\n        border-radius: 8px;\n        padding: 0.75rem 2rem;\n        font-weight: 600;\n        font-size: 0.875rem;\n        letter-spacing: 0.025em;\n        transition: all 0.3s ease;\n        box-shadow: 0 2px 8px rgba(43, 119, 217, 0.2);\n    }\n    \n    .stButton > button:hover {\n        transform: translateY(-2px);\n        box-shadow: 0 8px 24px rgba(43, 119, 217, 0.3);\n    }\n    \n    /* Navigation tabs */\n    .stTabs [data-baseweb=\"tab-list\"] {\n        gap: 12px;\n        background: var(--neutral-100);\n        padding: 0.5rem;\n        border-radius: 12px;\n        margin-bottom: 2rem;\n    }\n    \n    .stTabs [data-baseweb=\"tab\"] {\n        height: 48px;\n        background-color: transparent;\n        border-radius: 8px;\n        color: var(--neutral-700);\n        font-weight: 500;\n        border: none;\n        padding: 0 1.5rem;\n    }\n    \n    .stTabs [aria-selected=\"true\"] {\n        background-color: white;\n        color: var(--primary-navy);\n        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);\n    }\n    \n    /* Sidebar styling */\n    .css-1d391kg {\n        background-color: var(--neutral-50);\n    }\n    \n    /* Metrics and statistics */\n    .metric-card {\n        background: white;\n        padding: 1.5rem;\n        border-radius: 10px;\n        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n        text-align: center;\n        border-top: 3px solid var(--accent-teal);\n        margin: 0.75rem 0;\n    }\n    \n    .metric-value {\n        font-size: 1.75rem;\n        font-weight: 700;\n        color: var(--primary-navy);\n        margin: 0;\n    }\n    \n    .metric-label {\n        color: var(--neutral-700);\n        font-size: 0.875rem;\n        margin: 0.5rem 0 0 0;\n        font-weight: 500;\n    }\n    \n    /* ChatGPT-like interface styling */\n    .mode-info-card {\n        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n        color: white;\n        padding: 1.5rem;\n        border-radius: 12px;\n        margin: 1rem 0;\n        box-shadow: 0 4px 16px rgba(102, 126, 234, 0.2);\n    }\n    \n    .mode-header {\n        display: flex;\n        align-items: center;\n        gap: 0.75rem;\n        margin-bottom: 0.75rem;\n    }\n    \n    .mode-icon {\n        font-size: 1.5rem;\n        filter: drop-shadow(0 2px 4px rgba(0,0,0,0.2));\n    }\n    \n    .mode-title {\n        font-size: 1.25rem;\n        font-weight: 600;\n        margin: 0;\n    }\n    \n    .mode-description {\n        font-size: 0.95rem;\n        opacity: 0.9;\n        margin-bottom: 0.5rem;\n        line-height: 1.5;\n    }\n    \n    .mode-tools {\n        font-size: 0.85rem;\n        opacity: 0.8;\n        font-style: italic;\n    }\n    \n    .welcome-message {\n        background: linear-gradient(135deg, var(--neutral-50), var(--neutral-100));\n        border: 1px solid var(--neutral-200);\n        border-radius: 16px;\n        padding: 2rem;\n        margin: 2rem 0;\n        text-align: center;\n        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.05);\n    }\n    \n    .welcome-content {\n        font-size: 1.1rem;\n        color: var(--neutral-700);\n        line-height: 1.6;\n        max-width: 600px;\n        margin: 0 auto;\n    }\n    \n    /* Enhanced chat messages */\n    .chat-message {\n        margin: 1.5rem 0;\n        padding: 0;\n        border-radius: 16px;\n        max-width: 85%;\n        display: flex;\n        align-items: flex-start;\n        gap: 0.75rem;\n    }\n    \n    .user-message {\n        background: linear-gradient(135deg, #007bff, #0056b3);\n        color: white;\n        margin-left: auto;\n        border-radius: 16px 16px 4px 16px;\n        padding: 1.25rem 1.5rem;\n        box-shadow: 0 4px 12px rgba(0, 123, 255, 0.2);\n        max-width: 70%;\n    }\n    \n    .assistant-message {\n        background: white;\n        color: var(--neutral-800);\n        border: 1px solid var(--neutral-200);\n        border-radius: 16px 16px 16px 4px;\n        padding: 1.25rem 1.5rem;\n        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n        max-width: 80%;\n        margin-right: auto;\n    }\n    \n    .assistant-avatar {\n        width: 32px;\n        height: 32px;\n        background: linear-gradient(135deg, var(--accent-teal), var(--success-green));\n        border-radius: 50%;\n        display: flex;\n        align-items: center;\n        justify-content: center;\n        font-size: 1rem;\n        flex-shrink: 0;\n        margin-top: 0.25rem;\n        box-shadow: 0 2px 8px rgba(49, 151, 149, 0.3);\n    }\n    \n    .message-content {\n        flex: 1;\n        line-height: 1.6;\n        word-wrap: break-word;\n    }\n    \n    .user-message .message-content {\n        margin: 0;\n    }\n    \n    .assistant-message .message-content {\n        margin-left: 0.5rem;\n    }\n    \n    /* Quick actions styling */\n    .stButton > button {\n        background: linear-gradient(135deg, var(--primary-navy) 0%, var(--secondary-blue) 100%);\n        color: white;\n        border: none;\n        border-radius: 10px;\n        padding: 0.75rem 1.5rem;\n        font-weight: 500;\n        font-size: 0.875rem;\n        transition: all 0.3s ease;\n        box-shadow: 0 2px 8px rgba(43, 119, 217, 0.2);\n        border-left: 4px solid var(--accent-teal);\n    }\n    \n    .stButton > button:hover {\n        transform: translateY(-2px);\n        box-shadow: 0 6px 20px rgba(43, 119, 217, 0.3);\n        border-left-color: var(--success-green);\n    }\n    \n    .stButton > button:active {\n        transform: translateY(0);\n        box-shadow: 0 2px 8px rgba(43, 119, 217, 0.2);\n    }\n    \n    /* Chat input enhancement */\n    .stChatInput > div > div > div > div {\n        border-radius: 24px;\n        border: 2px solid var(--neutral-200);\n        background: white;\n        transition: all 0.3s ease;\n        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n    }\n    \n    .stChatInput > div > div > div > div:focus-within {\n        border-color: var(--secondary-blue);\n        box-shadow: 0 4px 16px rgba(43, 119, 217, 0.15);\n    }\n    \n    /* Selectbox styling */\n    .stSelectbox > div > div > div {\n        background: white;\n        border: 2px solid var(--neutral-200);\n        border-radius: 10px;\n        transition: all 0.3s ease;\n    }\n    \n    .stSelectbox > div > div > div:focus-within {\n        border-color: var(--secondary-blue);\n        box-shadow: 0 4px 16px rgba(43, 119, 217, 0.15);\n    }\n    \n    /* Conversation history styling */\n    .conversation-container {\n        max-height: 600px;\n        overflow-y: auto;\n        padding: 1rem;\n        background: var(--neutral-50);\n        border-radius: 12px;\n        margin: 1rem 0;\n    }\n    \n    /* Typing indicator */\n    .typing-indicator {\n        display: flex;\n        align-items: center;\n        gap: 0.5rem;\n        padding: 1rem;\n        background: var(--neutral-100);\n        border-radius: 12px;\n        margin: 1rem 0;\n        animation: pulse 1.5s infinite;\n    }\n    \n    @keyframes pulse {\n        0% { opacity: 0.6; }\n        50% { opacity: 1; }\n        100% { opacity: 0.6; }\n    }\n    \n    /* Session information */\n    .session-card {\n        background: white;\n        border: 1px solid var(--neutral-200);\n        border-radius: 10px;\n        padding: 1.25rem;\n        margin: 1rem 0;\n        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n    }\n    \n    .session-header {\n        font-weight: 600;\n        color: var(--neutral-800);\n        margin: 0 0 0.75rem 0;\n    }\n    \n    .session-detail {\n        display: flex;\n        justify-content: space-between;\n        margin: 0.5rem 0;\n        font-size: 0.875rem;\n    }\n    \n    .session-label {\n        color: var(--neutral-700);\n        font-weight: 500;\n    }\n    \n    .session-value {\n        color: var(--neutral-800);\n    }\n    \n    /* Alert messages */\n    .custom-alert {\n        padding: 1rem 1.5rem;\n        border-radius: 10px;\n        margin: 1.5rem 0;\n        border-left: 4px solid;\n        font-weight: 500;\n    }\n    \n    .alert-info {\n        background: rgba(43, 119, 217, 0.1);\n        border-color: var(--secondary-blue);\n        color: var(--secondary-blue);\n    }\n    \n    .alert-warning {\n        background: rgba(214, 158, 46, 0.1);\n        border-color: var(--warning-amber);\n        color: #9c4221;\n    }\n    \n    .alert-success {\n        background: rgba(56, 161, 105, 0.1);\n        border-color: var(--success-green);\n        color: var(--success-green);\n    }\n    \n    /* Loading states */\n    .loading-container {\n        display: flex;\n        align-items: center;\n        justify-content: center;\n        padding: 2rem;\n        background: var(--neutral-50);\n        border-radius: 12px;\n        margin: 1rem 0;\n    }\n    \n    /* Export functionality */\n    .export-section {\n        background: white;\n        border: 1px solid var(--neutral-200);\n        border-radius: 10px;\n        padding: 1.25rem;\n        margin: 1rem 0;\n    }\n    \n    .export-header {\n        font-weight: 600;\n        color: var(--neutral-800);\n        margin: 0 0 1rem 0;\n    }\n</style>\n\"\"\", unsafe_allow_html=True)\n\n# Load tools configuration\n@st.cache_data\ndef load_tools_config():\n    \"\"\"Load tools configuration from tools.json\"\"\"\n    try:\n        with open(\"tools.json\", \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except Exception as e:\n        st.error(f\"Error loading tools configuration: {e}\")\n        return []\n\nclass ProfessionalToolManager:\n    \"\"\"Enterprise-grade tool execution and management system\"\"\"\n    \n    def __init__(self):\n        self.tools_config = load_tools_config()\n        self.loaded_tools = {}\n        self.execution_log = []\n        self.session_stats = {\n            \"tools_executed\": 0,\n            \"successful_executions\": 0,\n            \"failed_executions\": 0,\n            \"total_execution_time\": 0\n        }\n        self._initialize_tools()\n    \n    def _initialize_tools(self):\n        \"\"\"Initialize and validate all available tools\"\"\"\n        for tool_config in self.tools_config:\n            try:\n                module_path = tool_config[\"module\"]\n                tool_name = tool_config[\"name\"]\n                \n                # Import the module\n                module = importlib.import_module(module_path)\n                \n                # Get the function\n                if hasattr(module, tool_name):\n                    tool_func = getattr(module, tool_name)\n                    self.loaded_tools[tool_name] = {\n                        \"function\": tool_func,\n                        \"config\": tool_config,\n                        \"status\": \"available\",\n                        \"executions\": 0,\n                        \"last_executed\": None\n                    }\n                else:\n                    self.loaded_tools[tool_na..."
  },
  {
    "type": "function",
    "name": "load_tools_config",
    "doc": "Load tools configuration from tools.json",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "class",
    "name": "ProfessionalToolManager",
    "doc": "Enterprise-grade tool execution and management system",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "init_session_state",
    "doc": "Initialize all session state variables",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "load_conversation_history",
    "doc": "Load conversation history from file",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "save_conversation_history",
    "doc": "Save conversation history to file",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "render_professional_header",
    "doc": "Render professional application header",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "render_chatgpt_interface",
    "doc": "Render ChatGPT-like interface with intelligent conversation",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "load_conversation_history",
    "doc": "Load conversation history from file",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "save_conversation_history",
    "doc": "Save conversation history to file",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "get_mode_specific_response",
    "doc": "Get mode-specific AI response",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "auto_execute_tool_if_applicable",
    "doc": "Auto-execute relevant tools based on mode and message content",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "main",
    "doc": "Main application entry point",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "__init__",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "_initialize_tools",
    "doc": "Initialize and validate all available tools",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "get_available_tools",
    "doc": "Get list of successfully loaded tools",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "get_all_tools",
    "doc": "Get all tools with their status",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "get_tool_config",
    "doc": "Get tool configuration",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "execute_tool",
    "doc": "Execute a tool with comprehensive error handling and logging",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "_create_error_result",
    "doc": "Create standardized error result",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "get_execution_statistics",
    "doc": "Get comprehensive execution statistics",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "chat_with_bot",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "class",
    "name": "Chatbot",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "question_answering",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "__init__",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "function",
    "name": "chat",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\streamlit_app.py"
  },
  {
    "type": "file",
    "name": "test_mcp_server.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\test_mcp_server.py",
    "content": "\"\"\"\nMCP Server Testing and Verification Script\nDemonstrates local access, monitoring, and tool call verification\n\"\"\"\nimport requests\nimport json\nimport time\nimport asyncio\nimport websockets\nfrom typing import Dict, Any\n\nclass MCPServerTester:\n    def __init__(self, base_url=\"http://localhost:8000\", api_key=\"dev-test-key\"):\n        self.base_url = base_url\n        self.api_key = api_key\n        self.headers = {\n            \"X-API-Key\": api_key,\n            \"Content-Type\": \"application/json\"\n        }\n    \n    def test_server_health(self):\n        \"\"\"Test server health and connectivity\"\"\"\n        print(\"Testing server health...\")\n        try:\n            response = requests.get(f\"{self.base_url}/\")\n            print(f\"Server Status: {response.json()}\")\n            \n            # Detailed health check\n            response = requests.get(f\"{self.base_url}/admin/health\")\n            health_data = response.json()\n            print(f\"Detailed Health: {json.dumps(health_data, indent=2)}\")\n            \n            return True\n        except Exception as e:\n            print(f\"Server connection failed: {e}\")\n            return False\n    \n    def test_tool_listing(self):\n        \"\"\"Test tool listing endpoint\"\"\"\n        print(\"\\nTesting tool listing...\")\n        try:\n            response = requests.get(f\"{self.base_url}/tools\", headers=self.headers)\n            tools = response.json()\n            print(f\"Available tools: {json.dumps(tools, indent=2)}\")\n            return tools.get(\"tools\", [])\n        except Exception as e:\n            print(f\"Tool listing failed: {e}\")\n            return []\n    \n    def test_tool_execution(self, tool_name=\"scan_codebase\", arguments=None):\n        \"\"\"Test tool execution with monitoring\"\"\"\n        if arguments is None:\n            arguments = {\"query\": \"python patterns\"}\n        print(f\"\\nTesting tool execution: {tool_name}\")\n        try:\n            payload = {\n                \"tool_name\": tool_name,\n                \"arguments\": arguments\n            }\n            \n            start_time = time.time()\n            response = requests.post(\n                f\"{self.base_url}/tools/execute\", \n                headers=self.headers, \n                json=payload\n            )\n            execution_time = time.time() - start_time\n            \n            if response.status_code == 200:\n                result = response.json()\n                print(f\"Tool executed successfully in {execution_time:.2f}s\")\n                print(f\"Result preview: {str(result.get('result', ''))[:200]}...\")\n                return result\n            else:\n                print(f\"Tool execution failed: {response.status_code} - {response.text}\")\n                return None\n        except Exception as e:\n            print(f\"Tool execution error: {e}\")\n            return None\n    \n    def test_verification_endpoint(self):\n        \"\"\"Test tool call verification\"\"\"\n        print(\"\\nTesting tool call verification...\")\n        try:\n            response = requests.get(f\"{self.base_url}/verify/tools\", headers=self.headers)\n            verification = response.json()\n            \n            print(f\"Verification Status: {verification.get('verification_status')}\")\n            print(f\"Total calls tracked: {verification.get('total_calls')}\")\n            print(f\"IDE breakdown: {verification.get('ide_breakdown')}\")\n            print(f\"Tool breakdown: {verification.get('tool_breakdown')}\")\n            \n            return verification\n        except Exception as e:\n            print(f\"Verification failed: {e}\")\n            return None\n    \n    def test_analytics(self):\n        \"\"\"Test analytics endpoints\"\"\"\n        print(\"\\nTesting analytics...\")\n        try:\n            # Get usage stats\n            response = requests.get(f\"{self.base_url}/admin/analytics/stats\", headers=self.headers)\n            stats = response.json()\n            print(f\"Usage Stats: {json.dumps(stats, indent=2)}\")\n            \n            # Get recent executions\n            response = requests.get(f\"{self.base_url}/admin/analytics/executions?limit=..."
  },
  {
    "type": "class",
    "name": "MCPServerTester",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\test_mcp_server.py"
  },
  {
    "type": "function",
    "name": "__init__",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\test_mcp_server.py"
  },
  {
    "type": "function",
    "name": "test_server_health",
    "doc": "Test server health and connectivity",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\test_mcp_server.py"
  },
  {
    "type": "function",
    "name": "test_tool_listing",
    "doc": "Test tool listing endpoint",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\test_mcp_server.py"
  },
  {
    "type": "function",
    "name": "test_tool_execution",
    "doc": "Test tool execution with monitoring",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\test_mcp_server.py"
  },
  {
    "type": "function",
    "name": "test_verification_endpoint",
    "doc": "Test tool call verification",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\test_mcp_server.py"
  },
  {
    "type": "function",
    "name": "test_analytics",
    "doc": "Test analytics endpoints",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\test_mcp_server.py"
  },
  {
    "type": "function",
    "name": "run_comprehensive_test",
    "doc": "Run all tests to verify MCP server functionality",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\test_mcp_server.py"
  },
  {
    "type": "file",
    "name": "tools.json",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools.json",
    "content": "[\n  {\n    \"name\": \"jira_ticket_summarizer\",\n    \"module\": \"tools.development.jira_tools\",\n    \"description\": \"Analyze JIRA ticket history for development patterns, requirements, and project insights.\",\n    \"args_schema\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"domainUrl\": { \"type\": \"string\", \"description\": \"The JIRA domain URL.\" },\n        \"userName\": { \"type\": \"string\", \"description\": \"The JIRA username.\" },\n        \"token\": { \"type\": \"string\", \"description\": \"The JIRA API token.\" },\n        \"query\": { \"type\": \"string\", \"description\": \"Query about JIRA patterns, ticket analysis, or project requirements.\" }\n      },\n      \"required\": [\"domainUrl\", \"userName\", \"token\", \"query\"]\n    },\n    \"output_format\": \"json\"\n  },\n  {\n    \"name\": \"fetch_remote_git_history\",..."
  },
  {
    "type": "file",
    "name": "tools_modular.json",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools_modular.json",
    "content": "[\n  {\n    \"name\": \"question_answering\",\n    \"module\": \"chatbot\",\n    \"description\": \"Answer questions by performing internet research and logical reasoning. Remembers context for follow-up questions.\",\n    \"args_schema\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"query\": { \"type\": \"string\", \"description\": \"The natural language question to answer.\" }\n      },\n      \"required\": [\"query\"]\n    },\n    \"output_format\": \"console\"\n  },\n  {\n    \"name\": \"custom_api\",\n    \"module\": \"tools.custom_api\",\n    \"description\": \"Execute an internal project function exposed over HTTP.\",\n    \"args_schema\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"query\": { \"type\": \"string\", \"description\": \"The natural language prompt or query for the tool.\" }\n      },\n      \"required\": [\"query\"]\n    },\n    \"output_format\": \"console\"\n  },\n  {\n    \"name\": \"scan_codebase\",\n    \"module\": \"tools.development.codebase_tools\",\n    \"description\": \"Scan and analyze codebase for patterns, conventions, folder structures, and naming patterns.\",\n    \"args_schema\": {\n      \"type\": \"object\",\n      ..."
  },
  {
    "type": "file",
    "name": "tool_registry.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\core\\tool_registry.py",
    "content": "import json\nimport importlib\nfrom pathlib import Path\nfrom langchain.tools import Tool\n\nTOOLS_PATH = Path(__file__).parent.parent / \"tools.json\"\n\nclass ToolRegistry:\n    def __init__(self):\n        with open(TOOLS_PATH, \"r\", encoding=\"utf-8\") as f:\n            self.tools_config = json.load(f)\n        self.tools = self._load_tools()\n\n    def _load_tools(self):\n        tools = []\n        for tool in self.tools_config:\n            module_path = tool[\"module\"]\n            func_name = tool[\"name\"]\n            mod = importlib.import_module(..."
  },
  {
    "type": "class",
    "name": "ToolRegistry",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\core\\tool_registry.py"
  },
  {
    "type": "function",
    "name": "get_tool_registry",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\core\\tool_registry.py"
  },
  {
    "type": "function",
    "name": "__init__",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\core\\tool_registry.py"
  },
  {
    "type": "function",
    "name": "_load_tools",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\core\\tool_registry.py"
  },
  {
    "type": "function",
    "name": "get_tool_list",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\core\\tool_registry.py"
  },
  {
    "type": "function",
    "name": "execute_tool",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\core\\tool_registry.py"
  },
  {
    "type": "file",
    "name": "codebandits_private_history.json",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\data\\codebandits_private_history.json",
    "content": "{\n  \"repository\": {\n    \"url\": \"https://github.com/Codebandits-tal/hackhathon-codebandits.git\",\n    \"cloned_branch\": \"master\",\n    \"requested_branch\": \"main\",\n    \"remote_url\": \"https://github.com/Codebandits-tal/hackhathon-codebandits.git\"\n  },\n  \"metadata\": {\n    \"total_commits_fetched\": 50,\n    \"max_commits_requested\": 50,\n    \"fetch_timestamp\": \"2025-08-02T14:54:43.328244\",\n    \"clone_method\": \"temporary\"\n  },\n  \"commits\": [\n    {\n      \"sha\": \"40421a3a982ff30c31d3d27810b560804904f866\",\n      \"short_sha\": \"40421a3\",\n      \"message\": \"Updated diagram path in readme file\",\n      \"author\": {\n        \"name\": \"Codebandits-tal\",\n        \"email\": \"140823987+Codebandits-tal@users.noreply.github.com\"\n      },\n      \"authored_date\": \"2023-07-30T10:37:00+05:30\",\n      \"committed_date\": \"2023-07-30T10:37:00+05:30\",\n      \"changed_files\": [\n        \"README.md\"\n      ]\n    },\n    {\n      \"sha\": \"1c2b351c0727515bb9c292d06232d9c790c29d80\",\n      \"short_sha\": \"1c2b351\",\n      \"message\": \"Update README.md for onion architecture diagram\",\n      \"author\": {\n        \"name\": \"Codebandits-tal\",\n        \"email\": \"140823987+Codebandits-tal@users.noreply.github.com\"\n      },\n      \"authored_date\": \"2023-07-30T10:34:21+05:30\",\n      \"committed_date\": \"2023-07-30T10:34:21+05:30\",\n      \"changed_files\": [\n        \"README.md\"\n      ]\n    },\n    {\n      \"sha\": \"3a9fe6f1ecea825781a85440459d7c48583d402b\",\n      \"short_sha\": \"3a9fe6f\",\n      \"message\": \"added onion architecture diagram\",\n      \"author\": {\n        \"name\": \"Giridhar Anand\",\n        \"email\": \"giridhar.anand@talentica.com\"\n      },\n      \"authored_date\": \"2023-07-30T10:33:27+05:30\",\n      \"committed_date\": \"2023-07-30T10:33:40+05:30\",\n      \"changed_files\": [\n        \"Hachathon-architecture.drawio.png\"\n      ]\n    },\n    {\n      \"sha\": \"60dac31bea290a0ae831b6fdce35485a3f473c1a\",\n      \"short_sha\": \"60dac31\",\n      \"message\": \"ai icon on app level\",\n      \"author\": {\n        \"name\": \"Ashok Patel\",\n        \"email\": \"ashok@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-30T10:23:59+05:30\",\n      \"committed_date\": \"2023-07-30T10:23:59+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/app.component.css\",\n        \"CB-UI/src/app/app.component.html\",\n        \"CB-UI/src/app/app.component.ts\",\n        \"CB-UI/src/app/landing-page/landing-page.component.html\"\n      ]\n    },\n    {\n      \"sha\": \"8685b87ad62a177b9478e78ea159f236207b1415\",\n      \"short_sha\": \"8685b87\",\n      \"message\": \"fixed editor resume builder\",\n      \"author\": {\n        \"name\": \"Rajesh Patra\",\n        \"email\": \"rajesh@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-30T09:39:44+05:30\",\n      \"committed_date\": \"2023-07-30T09:39:44+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/component/editor/editor.component.ts\",\n        \"CB-UI/src/app/service/login.service.ts\"\n      ]\n    },\n    {\n      \"sha\": \"df974d836a88b7a085dd6260c18597b9f76ed92d\",\n      \"short_sha\": \"df974d8\",\n      \"message\": \"fixed import error in app module, routing fix, search fix\",\n      \"author\": {\n        \"name\": \"Rajesh Patra\",\n        \"email\": \"rajesh@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-30T09:24:28+05:30\",\n      \"committed_date\": \"2023-07-30T09:24:28+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/app-routing.module.ts\",\n        \"CB-UI/src/app/app.module.ts\",\n        \"CB-UI/src/app/auth.guard.ts\",\n        \"CB-UI/src/app/component/editor/editor.component.ts\",\n        \"CB-UI/src/app/login/login.component.ts\",\n        \"CB-UI/src/app/service/login.service.ts\",\n        \"CB-UI/src/app/service/search.service.ts\",\n        \"CB-UI/src/app/service/userinfo.service.ts\"\n      ]\n    },\n    {\n      \"sha\": \"4c4a057cd322d05d63c422decd4d0944bd8e9a74\",\n      \"short_sha\": \"4c4a057\",\n      \"message\": \"Added Pipe for Gender\",\n      \"author\": {\n        \"name\": \"Vishal Raj\",\n        \"email\": \"Vishal@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-30T07:34:20+05:30\",\n      \"committed_date\": \"2023-07-30T07:34:20+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/app.module.ts\",\n        \"CB-UI/src/app/gender.pipe.spec.ts\",\n        \"CB-UI/src/app/gender.pipe.ts\",\n        \"CB-UI/src/app/view-search-result/view-search-result.component.html\"\n      ]\n    },\n    {\n      \"sha\": \"0335f51566f8f3440c3ea0c6f03875cf1486844b\",\n      \"short_sha\": \"0335f51\",\n      \"message\": \"App module and misc files\",\n      \"author\": {\n        \"name\": \"Ashok Patel\",\n        \"email\": \"ashok@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-30T04:25:00+05:30\",\n      \"committed_date\": \"2023-07-30T04:42:36+05:30\",\n      \"changed_files\": [\n        \"CB-UI/.prettierignore\",\n        \"CB-UI/.prettierrc.json\",\n        \"CB-UI/angular.json\",\n        \"CB-UI/package.json\",\n        \"CB-UI/proxy-base.json\",\n        \"CB-UI/proxy-config.js\",\n        \"CB-UI/src/app/app.module.ts\",\n        \"CB-UI/src/index.html\",\n        \"CB-UI/src/styles.css\",\n        \"CB-UI/src/web.config\"\n      ]\n    },\n    {\n      \"sha\": \"b7afab9718abce478964eeb6c95b01bcb5b1c13d\",\n      \"short_sha\": \"b7afab9\",\n      \"message\": \"Landing page work\",\n      \"author\": {\n        \"name\": \"Ashok Patel\",\n        \"email\": \"ashok@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-30T04:23:37+05:30\",\n      \"committed_date\": \"2023-07-30T04:41:36+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/landing-page/landing-page.component.css\",\n        \"CB-UI/src/app/landing-page/landing-page.component.html\",\n        \"CB-UI/src/app/landing-page/landing-page.component.ts\"\n      ]\n    },\n    {\n      \"sha\": \"222412f0c6e6c3daae121aa7dd734569b12058c8\",\n      \"short_sha\": \"222412f\",\n      \"message\": \"Shared module\",\n      \"author\": {\n        \"name\": \"Ashok Patel\",\n        \"email\": \"ashok@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-30T04:22:44+05:30\",\n      \"committed_date\": \"2023-07-30T04:39:23+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/core/common.css\",\n        \"CB-UI/src/app/core/shared/shared.module.ts\"\n      ]\n    },\n    {\n      \"sha\": \"87a86cf86e64e78c596252e1eea45bff5b31c5da\",\n      \"short_sha\": \"87a86cf\",\n      \"message\": \"AI Assistant module\",\n      \"author\": {\n        \"name\": \"Ashok Patel\",\n        \"email\": \"ashok@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-30T04:21:36+05:30\",\n      \"committed_date\": \"2023-07-30T04:39:23+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/ai-assistant/ai-assistant.module.ts\",\n        \"CB-UI/src/app/ai-assistant/ask-anything/ask-anything.component.css\",\n        \"CB-UI/src/app/ai-assistant/ask-anything/ask-anything.component.html\",\n        \"CB-UI/src/app/ai-assistant/ask-anything/ask-anything.component.ts\",\n        \"CB-UI/src/app/ai-assistant/assistant.service.ts\",\n        \"CB-UI/src/app/ai-assistant/core/ai-styles.css\",\n        \"CB-UI/src/app/ai-assistant/email-helper/email-helper.component.css\",\n        \"CB-UI/src/app/ai-assistant/email-helper/email-helper.component.html\",\n        \"CB-UI/src/app/ai-assistant/email-helper/email-helper.component.spec.ts\",\n        \"CB-UI/src/app/ai-assistant/email-helper/email-helper.component.ts\",\n        \"CB-UI/src/app/ai-assistant/grammar-helper/grammar-helper.component.css\",\n        \"CB-UI/src/app/ai-assistant/grammar-helper/grammar-helper.component.html\",\n        \"CB-UI/src/app/ai-assistant/grammar-helper/grammar-helper.component.spec.ts\",\n        \"CB-UI/src/app/ai-assistant/grammar-helper/grammar-helper.component.ts\",\n        \"CB-UI/src/app/ai-assistant/home/home.component.css\",\n        \"CB-UI/src/app/ai-assistant/home/home.component.html\",\n        \"CB-UI/src/app/ai-assistant/home/home.component.ts\",\n        \"CB-UI/src/app/ai-assistant/interview-helper/interview-helper.component.css\",\n        \"CB-UI/src/app/ai-assistant/interview-helper/interview-helper.component.html\",\n        \"CB-UI/src/app/ai-assistant/interview-helper/interview-helper.component.spec.ts\",\n        \"CB-UI/src/app/ai-assistant/interview-helper/interview-helper.component.ts\",\n        \"CB-UI/src/app/ai-assistant/resume-helper/resume-helper.component.css\",\n        \"CB-UI/src/app/ai-assistant/resume-helper/resume-helper.component.html\",\n        \"CB-UI/src/app/ai-assistant/resume-helper/resume-helper.component.spec.ts\",\n        \"CB-UI/src/app/ai-assistant/resume-helper/resume-helper.component.ts\",\n        \"CB-UI/src/app/ai-assistant/search-helper/search-helper.component.css\",\n        \"CB-UI/src/app/ai-assistant/search-helper/search-helper.component.html\",\n        \"CB-UI/src/app/ai-assistant/search-helper/search-helper.component.spec.ts\",\n        \"CB-UI/src/app/ai-assistant/search-helper/search-helper.component.ts\"\n      ]\n    },\n    {\n      \"sha\": \"06904bacfaa6c97a420f0c4b503b16486206de2f\",\n      \"short_sha\": \"06904ba\",\n      \"message\": \"Python code\",\n      \"author\": {\n        \"name\": \"Ashok Patel\",\n        \"email\": \"ashok@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-30T04:21:02+05:30\",\n      \"committed_date\": \"2023-07-30T04:39:22+05:30\",\n      \"changed_files\": [\n        \"CB-AI-Assistant/index.py\",\n        \"CB-AI-Assistant/web.config\"\n      ]\n    },\n    {\n      \"sha\": \"c2e3b3f7cddf29dec2e2c178ac8d5197cee425ea\",\n      \"short_sha\": \"c2e3b3f\",\n      \"message\": \"CB ai first work\",\n      \"author\": {\n        \"name\": \"Ashok Patel\",\n        \"email\": \"ashok@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-29T14:03:34+05:30\",\n      \"committed_date\": \"2023-07-30T04:39:22+05:30\",\n      \"changed_files\": [\n        \".gitignore\",\n        \"CB-AI-Assistant/.gitignore\",\n        \"CB-AI-Assistant/.vscode/launch.json\",\n        \"CB-AI-Assistant/.vscode/settings.json\",\n        \"CB-AI-Assistant/README.md\",\n        \"CB-AI-Assistant/Setup.md\",\n        \"CB-AI-Assistant/conf/config.ini\",\n        \"CB-AI-Assistant/index.py\",\n        \"CB-AI-Assistant/requirements.txt\",\n        \"CB-AI-Assistant/templates/index.html\",\n        \"CB-AI-Assistant/web.config\",\n        \"CB-UI/src/app/ai-assistant/ai-assistant-routing.module.ts\",\n        \"CB-UI/src/app/ai-assistant/ai-assistant.module.ts\",\n        \"CB-UI/src/app/ai-assistant/ask-anything/ask-anything.component.css\",\n        \"CB-UI/src/app/ai-assistant/ask-anything/ask-anything.component.html\",\n        \"CB-UI/src/app/ai-assistant/ask-anything/ask-anything.component.spec.ts\",\n        \"CB-UI/src/app/ai-assistant/ask-anything/ask-anything.component.ts\",\n        \"CB-UI/src/app/ai-assistant/assistant.service.spec.ts\",\n        \"CB-UI/src/app/ai-assistant/assistant.service.ts\",\n        \"CB-UI/src/app/ai-assistant/core/ai-assistant-request.model.ts\",\n        \"CB-UI/src/app/ai-assistant/core/ai-assistant-response.model.ts\",\n        \"CB-UI/src/app/ai-assistant/core/ai-styles.css\",\n        \"CB-UI/src/app/ai-assistant/core/toolbar-map.ts\",\n        \"CB-UI/src/app/ai-assistant/home/home.component.css\",\n        \"CB-UI/src/app/ai-assistant/home/home.component.html\",\n        \"CB-UI/src/app/ai-assistant/home/home.component.spec.ts\",\n        \"CB-UI/src/app/ai-assistant/home/home.component.ts\",\n        \"CB-UI/src/app/core/http.service.spec.ts\",\n        \"CB-UI/src/app/core/http.service.ts\",\n        \"CB-UI/src/app/landing-page/landing-page.component.ts\"\n      ]\n    },\n    {\n      \"sha\": \"a1b06e6e4bf456759ce78dd762edc830fdc49811\",\n      \"short_sha\": \"a1b06e6\",\n      \"message\": \"added Search integration -Vishal\",\n      \"author\": {\n        \"name\": \"Vishal Raj\",\n        \"email\": \"Vishal@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-30T03:39:06+05:30\",\n      \"committed_date\": \"2023-07-30T03:39:06+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/component/search/search.component.html\",\n        \"CB-UI/src/app/component/search/search.component.ts\",\n        \"CB-UI/src/app/header/header.component.css\",\n        \"CB-UI/src/app/header/header.component.html\",\n        \"CB-UI/src/app/landing-page/landing-page.component.html\",\n        \"CB-UI/src/app/profile/profile.component.html\",\n        \"CB-UI/src/app/service/search.service.spec.ts\",\n        \"CB-UI/src/app/service/search.service.ts\",\n        \"CB-UI/src/app/service/userinfo.service.ts\",\n        \"CB-UI/src/app/view-search-result/view-search-result.component.html\",\n        \"CB-UI/src/app/view-search-result/view-search-result.component.ts\"\n      ]\n    },\n    {\n      \"sha\": \"00b7d9deca5ef67e4f0f901be555fbe4be8c92ba\",\n      \"short_sha\": \"00b7d9d\",\n      \"message\": \"implemented get resume and save resume api\",\n      \"author\": {\n        \"name\": \"Giridhar Anand\",\n        \"email\": \"giridhar.anand@talentica.com\"\n      },\n      \"authored_date\": \"2023-07-30T03:01:47+05:30\",\n      \"committed_date\": \"2023-07-30T03:01:47+05:30\",\n      \"changed_files\": [\n        \"CB.Api/Controllers/ResumeController.cs\",\n        \"CB.Core/Models/Resume.cs\",\n        \"CB.Core/Repositories/IResumeRepository.cs\",\n        \"CB.Core/Services/IResumeService.cs\",\n        \"CB.Core/ServicesImpl/ResumeService.cs\",\n        \"CB.Extension/CBExtension.cs\",\n        \"CB.Repository/ResumeRepository.cs\",\n        \"CB.Repository/SQLDB/ReleaseScripts.sql/procs.sql\",\n        \"CB.Repository/SQLDB/ReleaseScripts.sql/tables.sql\",\n        \"CB.Repository/SQLDB/SProcs/get_resume.sql\",\n        \"CB.Repository/SQLDB/SProcs/save_resume.sql\"\n      ]\n    },\n    {\n      \"sha\": \"4abfa4fac765f913d9eb46adb89068a5de64ca8e\",\n      \"short_sha\": \"4abfa4f\",\n      \"message\": \"order by descending for search employee api\",\n      \"author\": {\n        \"name\": \"Giridhar Anand\",\n        \"email\": \"giridhar.anand@talentica.com\"\n      },\n      \"authored_date\": \"2023-07-30T01:34:31+05:30\",\n      \"committed_date\": \"2023-07-30T01:34:31+05:30\",\n      \"changed_files\": [\n        \"CB.Repository/SQLDB/ReleaseScripts.sql/procs.sql\",\n        \"CB.Repository/SQLDB/SProcs/search_employees.sql\"\n      ]\n    },\n    {\n      \"sha\": \"fcfd09f1871ee19fd848ca7b62a6d9b873c8829d\",\n      \"short_sha\": \"fcfd09f\",\n      \"message\": \"implemented search employee api\",\n      \"author\": {\n        \"name\": \"Giridhar Anand\",\n        \"email\": \"giridhar.anand@talentica.com\"\n      },\n      \"authored_date\": \"2023-07-30T01:25:35+05:30\",\n      \"committed_date\": \"2023-07-30T01:26:49+05:30\",\n      \"changed_files\": [\n        \"CB.Api/Controllers/EmployeeController.cs\",\n        \"CB.Api/Controllers/LoginController.cs\",\n        \"CB.Core/Commands/EmployeeSearchCommand.cs\",\n        \"CB.Api/Commands/LoginCommand.cs\",\n        \"CB.Core/Repositories/IEmployeeRepository.cs\",\n        \"CB.Core/Services/IEmployeeService.cs\",\n        \"CB.Core/ServicesImpl/EmployeeService.cs\",\n        \"CB.Repository/EmployeeRepository.cs\",\n        \"CB.Repository/SQLDB/ReleaseScripts.sql/procs.sql\",\n        \"CB.Repository/SQLDB/SProcs/get_employee_by_id.sql\",\n        \"CB.Repository/SQLDB/SProcs/search_employees.sql\"\n      ]\n    },\n    {\n      \"sha\": \"eab38cac1c7071eef158df24c9f96dd53f53266f\",\n      \"short_sha\": \"eab38ca\",\n      \"message\": \"YearOfExperience Bug Fixed\",\n      \"author\": {\n        \"name\": \"Vishal Raj\",\n        \"email\": \"Vishal@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-30T00:46:03+05:30\",\n      \"committed_date\": \"2023-07-30T00:46:03+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/profile/profile.component.html\",\n        \"CB-UI/src/app/profile/profile.component.ts\"\n      ]\n    },\n    {\n      \"sha\": \"12d02fa43c3b9fb83add1be3c0767d9c8dd12f5d\",\n      \"short_sha\": \"12d02fa\",\n      \"message\": \"forms autofill-rajesh\",\n      \"author\": {\n        \"name\": \"Rajesh Patra\",\n        \"email\": \"rajesh@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-30T00:24:57+05:30\",\n      \"committed_date\": \"2023-07-30T00:24:57+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/profile/profile.component.html\",\n        \"CB-UI/src/app/profile/profile.component.ts\"\n      ]\n    },\n    {\n      \"sha\": \"8b30ba4a082ba50bafb37b8ee854110ead087453\",\n      \"short_sha\": \"8b30ba4\",\n      \"message\": \"cors fix, issue tracker url update\",\n      \"author\": {\n        \"name\": \"Rajesh Patra\",\n        \"email\": \"rajesh@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-29T23:17:01+05:30\",\n      \"committed_date\": \"2023-07-29T23:17:01+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/app-routing.module.ts\",\n        \"CB-UI/src/app/header/header.component.html\",\n        \"CB-UI/src/app/issuetracker/issuetracker.component.ts\",\n        \"CB-UI/src/environments/environment.ts\",\n        \"CB.Api/Program.cs\",\n        \"CB.Repository/UnitOfWork.cs\"\n      ]\n    },\n    {\n      \"sha\": \"a1218c0ae44443ff8df24ea9c1e4d71c58c60611\",\n      \"short_sha\": \"a1218c0\",\n      \"message\": \"added cors policy, api in url\",\n      \"author\": {\n        \"name\": \"Giridhar Anand\",\n        \"email\": \"giridhar.anand@talentica.com\"\n      },\n      \"authored_date\": \"2023-07-29T23:00:03+05:30\",\n      \"committed_date\": \"2023-07-29T23:01:04+05:30\",\n      \"changed_files\": [\n        \"CB.Api/CB.Api.csproj\",\n        \"CB.Api/Controllers/LoginController.cs\",\n        \"CB.Api/Controllers/ProjectController.cs\",\n        \"CB.Api/Program.cs\"\n      ]\n    },\n    {\n      \"sha\": \"1670d81c42a2bd60f5eee83888d1620ac3bb7203\",\n      \"short_sha\": \"1670d81\",\n      \"message\": \"Added login html code -Vishal\",\n      \"author\": {\n        \"name\": \"Vishal Raj\",\n        \"email\": \"Vishal@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-29T21:12:58+05:30\",\n      \"committed_date\": \"2023-07-29T21:12:58+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/login/login.component.html\",\n        \"CB-UI/src/app/service/login.service.ts\",\n        \"CB-UI/src/environments/environment.ts\"\n      ]\n    },\n    {\n      \"sha\": \"0a29e4e3b004caacbb53081eac2b73e415833b2f\",\n      \"short_sha\": \"0a29e4e\",\n      \"message\": \"Added component to display users depending upon the search filter\",\n      \"author\": {\n        \"name\": \"Vishal Raj\",\n        \"email\": \"Vishal@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-29T20:32:54+05:30\",\n      \"committed_date\": \"2023-07-29T20:39:24+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/app-routing.module.ts\",\n        \"CB-UI/src/app/app.module.ts\",\n        \"CB-UI/src/app/profile/profile.component.css\",\n        \"CB-UI/src/app/view-search-result/view-search-result.component.css\",\n        \"CB-UI/src/app/view-search-result/view-search-result.component.html\",\n        \"CB-UI/src/app/view-search-result/view-search-result.component.spec.ts\",\n        \"CB-UI/src/app/view-search-result/view-search-result.component.ts\"\n      ]\n    },\n    {\n      \"sha\": \"76453991a9ae93a3a9df50c7f2391f7eb438bbc5\",\n      \"short_sha\": \"7645399\",\n      \"message\": \"implemented login service code\",\n      \"author\": {\n        \"name\": \"Vishal Raj\",\n        \"email\": \"Vishal@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-29T18:14:26+05:30\",\n      \"committed_date\": \"2023-07-29T20:28:38+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/app-routing.module.ts\",\n        \"CB-UI/src/app/login/login.component.ts\",\n        \"CB-UI/src/app/service/login.service.ts\",\n        \"CB-UI/src/app/service/userinfo.service.ts\",\n        \"CB-UI/src/environments/environment.ts\"\n      ]\n    },\n    {\n      \"sha\": \"3a014138598f6821dbbd87a47af1d78e57e56895\",\n      \"short_sha\": \"3a01413\",\n      \"message\": \"UI for login and employee search\",\n      \"author\": {\n        \"name\": \"Vishal Raj\",\n        \"email\": \"Vishal@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-29T17:29:04+05:30\",\n      \"committed_date\": \"2023-07-29T20:27:38+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/app-routing.module.ts\",\n        \"CB-UI/src/app/component/search/search.component.css\",\n        \"CB-UI/src/app/component/search/search.component.html\",\n        \"CB-UI/src/app/component/search/search.component.ts\",\n        \"CB-UI/src/app/header/header.component.css\",\n        \"CB-UI/src/app/header/header.component.html\",\n        \"CB-UI/src/app/landing-page/landing-page.component.css\",\n        \"CB-UI/src/app/login/login.component.css\",\n        \"CB-UI/src/app/login/login.component.ts\"\n      ]\n    },\n    {\n      \"sha\": \"95dde18ec0d8f28a67eea2ebe240d75a73d6afee\",\n      \"short_sha\": \"95dde18\",\n      \"message\": \"ai assist button added in resumebuilder\",\n      \"author\": {\n        \"name\": \"Rajesh Patra\",\n        \"email\": \"rajesh@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-29T18:21:28+05:30\",\n      \"committed_date\": \"2023-07-29T20:27:02+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/app.component.html\",\n        \"CB-UI/src/app/component/editor/editor.component.html\",\n        \"CB-UI/src/app/component/editor/editor.component.ts\"\n      ]\n    },\n    {\n      \"sha\": \"3d2b5db90d69e0611977cb08a04c6d5f3df68af2\",\n      \"short_sha\": \"3d2b5db\",\n      \"message\": \"issuetracker update\",\n      \"author\": {\n        \"name\": \"Rajesh Patra\",\n        \"email\": \"rajesh@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-29T16:50:57+05:30\",\n      \"committed_date\": \"2023-07-29T20:26:54+05:30\",\n      \"changed_files\": [\n        \"CB-UI/src/app/app.module.ts\",\n        \"CB-UI/src/app/issuetracker/issuetracker.component.css\",\n        \"CB-UI/src/app/issuetracker/issuetracker.component.html\",\n        \"CB-UI/src/app/issuetracker/issuetracker.component.ts\",\n        \"CB-UI/src/app/service/userinfo.service.ts\"\n      ]\n    },\n    {\n      \"sha\": \"79ded17afab556cbd0d52efdb96f89de2dbc7677\",\n      \"short_sha\": \"79ded17\",\n      \"message\": \"issue tracker started\",\n      \"author\": {\n        \"name\": \"Rajesh Patra\",\n        \"email\": \"rajesh@tailoredmail.com\"\n      },\n      \"authored_date\": \"2023-07-29T15:24:40+05:30\",\n      \"committed_date\": \"2023-07-29T20:26:0..."
  },
  {
    "type": "file",
    "name": "hello_world_remote.json",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\data\\hello_world_remote.json",
    "content": "{\n  \"repository\": {\n    \"url\": \"https://github.com/octocat/Hello-World.git\",\n    \"cloned_branch\": \"master\",\n    \"requested_branch\": \"main\",\n    \"remote_url\": \"https://github.com/octocat/Hello-World.git\"\n  },\n  \"metadata\": {\n    \"total_commits_fetched\": 3,\n    \"max_commits_requested\": 5,\n    \"fetch_timestamp\": \"2025-08-02T14:06:39.078365\",\n    \"clone_method\": \"temporary\"\n  },\n  \"commits\": [\n    {\n      \"sha\": \"7fd1a60b01f91b314f59955a4e4d4e80d8edf11d\",\n      \"short_sha\": \"7fd1a60\",\n      \"message\": \"Merge pull request #6 from Spaceghost/patch-1\\n\\nNew line at end of file.\",\n      \"author\": {\n        \"name\": \"The Octocat\",\n        \"email\": \"octocat@nowhere.com\"\n      },\n      \"authored_date\": \"2012-03-06T15:06:50-08:00\",\n      \"committed_date\": \"2012-03-06T15:06:50-08:00\",\n      \"changed_files\": [\n        \"README\"\n ..."
  },
  {
    "type": "file",
    "name": "mcp-server.log",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\logs\\mcp-server.log",
    "content": "2025-08-02 11:36:36,420 - mcp_server - ERROR - Error: {\"timestamp\": \"2025-08-02T06:06:36.419864\", \"event\": \"error\", \"error_type\": \"tool_execution_error\", \"error_message\": \"BaseTool.__call__() got an unexpected keyword argument 'query'\", \"user_id\": \"127.0.0.1\", \"client_ip\": \"127.0.0.1\", \"ide_type\": \"unknown\", \"additional_data\": \"{\\\"tool_name\\\": \\\"scan_codebase\\\", \\\"execution_time\\\": 0.0019974708557128906}\"}\n2025-08-02 11:36:36,420 - mcp_server - ERROR - Error: {\"timestamp\": \"2025-08-02T06:06:36.419864\", \"event\": \"error\", \"error_type\": \"tool_execution_error\", \"error_message\": \"BaseTool.__call__() got an unexpected keyword argument 'query'\", \"user_id\": \"127.0.0.1\", \"client_ip\": \"127.0.0.1\", \"ide_type\": \"unknown\", \"additional_data\": \"{\\\"tool_name\\\": \\\"scan_codebase\\\", \\\"execution_time\\\": 0.0019974708557128906}\"}\n2025-08-02 11:36:36,439 - mcp_server.server - ERROR - Tool 'scan_codebase' failed: BaseTool.__call__() got an unexpected keyword argument 'query'\n2025-08-02 11:36:36,439 - mcp_server.server - ERROR - Tool 'scan_codebase' failed: BaseTool.__call__() got an unexpected keyword argument 'query'\n2025-08-02 11:37:45,915 - mcp_server - INFO - Tool Executed: {\"timestamp\": \"2025-08-02T06:07:45.915899\", \"event\": \"tool_executed\", \"tool_name\": \"scan_codebase\", \"user_id\": \"127.0.0.1\", \"client_ip\": \"127.0.0.1\", \"ide_type\": \"unknown\", \"execution_time_ms\": 22819.079160690308, \"request_size\": 73, \"response_size\": 175, \"success\": true, \"arguments\": \"{\\\"query\\\": \\\"python patterns\\\"}\", \"response_preview\": \"Codebase scan completed. Found 433 patterns. Common folders: ['site-packages', 'annotated_types']. Use specific queries like 'python naming conventions' for detailed analysis.\"}\n2025-08-02 11:37:45,915 - mcp_server - INFO - Tool Executed: {\"timestamp\": \"2025-08-02T06:07:45.915899\", \"event\": \"tool_executed\", \"tool_name\": \"scan_codebase\", \"user_id\": \"127.0.0.1\", \"client_ip\": \"127.0.0.1\", \"ide_type\": \"unknown\", \"execution_time_ms\": 22819.079160690308, \"request_size\": 73, \"response_size\": 175, \"success\": true, \"arguments\": \"{\\\"query\\\": \\\"python patterns\\\"}\", \"response_preview\": \"Codebase scan completed. Found 433 patterns. Common folders: ['site-packages', 'annotated_types']. Use specific queries like 'python naming conventions' for detailed analysis.\"}\n2025-08-02 11:37:45,933 - mcp_server.server - INFO - Tool 'scan_codebase' executed successfully\n2025-08-02 11:37:45,933 - mcp_server.server - INFO - Tool 'scan_codebase' executed successfully\n2025-08-02 11:41:02,318 - mcp_server - INFO - Tool Executed: {\"timestamp\": \"2025-08-02T06:11:02.317179\", \"event\": \"tool_executed\", \"tool_name\": \"scan_codebase\", \"user_id\": \"127.0.0.1\", \"client_ip\": \"127.0.0.1\", \"ide_type\": \"unknown\", \"execution_time_ms\": 21206.46858215332, \"request_size\": 73, \"response_size\": 175, \"success\": true, \"arguments\": \"{\\\"query\\\": \\\"python patterns\\\"}\", \"response_preview\": \"Codebase scan completed. Found 433 patterns. Common folders: ['site-packages', 'annotated_types']. Use specific queries like 'python naming conventions' for detailed analysis.\"}\n2025-08-02 11:41:02,318 - mcp_server - INFO - Tool Executed: {\"timestamp\": \"2025-08-02T06:11:02.317179\", \"event\": \"tool_executed\", \"tool_name\": \"scan_codebase\", \"user_id\": \"127.0.0.1\", \"client_ip\": \"127.0.0.1\", \"ide_type\": \"unknown\", \"execution_time_ms\": 21206.46858215332, \"request_size\": 73, \"response_size\": 175, \"success\": true, \"arguments\": \"{\\\"query\\\": \\\"python patterns\\\"}\", \"response_preview\": \"Codebase scan completed. Found 433 patterns. Common folders: ['site-packages', 'annotated_types']. Use specific queries like 'python naming conventions' for detailed analysis.\"}\n2025-08-02 11:41:02,336 - mcp_server.server - INFO - Tool 'scan_codebase' executed successfully\n2025-08-02 11:41:02,336 - mcp_server.server - INFO - Tool 'scan_codebase' executed successfully\n2025-08-02 18:21:32,323 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:21:32,354 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:21:32,626 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:21:32,626 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:21:32,724 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:21:32,725 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:21:43,618 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:21:43,642 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:21:43,708 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:21:43,724 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:21:43,758 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:21:43,773 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:23:52,490 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:23:52,490 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:23:52,553 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:23:52,554 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:23:52,572 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:23:52,573 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:28:34,598 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:28:34,639 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:28:34,683 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:28:34,711 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:28:34,720 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:28:34,741 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:32:16,618 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:32:16,628 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:32:16,701 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:32:16,707 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:32:16,722 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:32:16,726 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:44:11,590 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:44:11,602 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:44:11,697 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:44:11,705 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:44:11,736 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:44:11,745 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:46:36,758 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:46:36,830 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:46:36,875 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:46:36,927 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:46:36,949 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:46:36,989 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:48:52,516 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:48:52,518 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:48:52,621 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:48:52,623 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:48:52,657 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:48:52,661 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:49:52,227 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:49:52,228 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:49:52,320 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:49:52,325 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:49:52,354 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:49:52,355 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:52:36,814 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:52:36,816 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:52:36,931 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:52:36,936 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:52:36,976 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:52:36,983 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:57:17,629 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:57:17,654 - faiss.loader - INFO - Loading faiss with AVX2 support.\n2025-08-02 18:57:17,759 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:57:17,774 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n2025-08-02 18:57:17,810 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n2025-08-02 18:57:17,817 - faiss ..."
  },
  {
    "type": "file",
    "name": ".env.example",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\.env.example",
    "content": "# Development Assistant MCP Server - Environment Configuration\n\n# Server Configuration\nSECRET_KEY=your-super-secret-key-change-this-in-production\nHOST=0.0.0.0\nPORT=8000\nDEBUG=false\n\n# Database Configuration\nREDIS_URL=redis://localhost:6379\nPOSTGRES_URL=postgresql://user:password@localhost:5432/devassistant\n\n# External API Keys\nOPENAI_API_KEY=your-openai-api-key-here\nSTRIPE_SECRET_KEY=sk_test_your-stripe-secret-key\nSTRIPE_WEBHOOK_SECRET=whsec_your-webhook-secret\n\n# Tool Configuration\nT..."
  },
  {
    "type": "file",
    "name": "docker-compose.yml",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\docker-compose.yml",
    "content": "version: '3.8'\n\nservices:\n  # MCP Server\n  mcp-server:\n    build: .\n    ports:\n      - \"8000:8000\"\n    environment:\n      - REDIS_URL=redis://redis:6379\n      - POSTGRES_URL=postgresql://postgres:password@postgres:5432/devassistant\n      - SECRET_KEY=your-production-secret-key-here\n    depends_on:\n      - redis\n      - postgres\n    volumes:\n      - ./logs:/app/logs\n      - ./data:/app/data\n    restart: unless-stopped\n\n  # Redis for caching and session management\n  redis:\n    image: redis:7-alpine\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - redis_data:/data\n    restart: unless-stopped\n    command: redis-server --appen..."
  },
  {
    "type": "file",
    "name": "Dockerfile",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\Dockerfile",
    "content": "FROM python:3.11-slim\n\n# Set working directory\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y \\\n    git \\\n    curl \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Copy requirements first for better caching\nCOPY requirements.txt .\n\n# Install Python dependencies\nRUN pip install --no-cache-dir -r requirements.txt\n\n# C..."
  },
  {
    "type": "file",
    "name": "langchain_mcp_server.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\langchain_mcp_server.py",
    "content": ""
  },
  {
    "type": "file",
    "name": "mcp_sqlite_logger.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\mcp_sqlite_logger.py",
    "content": "import logging\nimport json\nimport sqlite3\nfrom datetime import datetime\nfrom typing import Dict, Any, Optional\n\nclass MCPSQLiteLogger:\n    def __init__(self, db_path='logs/mcp-server.db', log_level=logging.INFO):\n        self.db_path = db_path\n        self.logger = logging.getLogger(\"mcp_server\")\n        self.setup_logging(log_level)\n        self._init_db()\n\n    def setup_logging(self, log_level):\n        formatter = logging.Formatter(\n            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n        )\n        console_handler = logging.StreamHandler()\n        console_handler.setFormatter(formatter)\n        file_handler = logging.FileHandler('logs/mcp-server.log')\n        file_handler.setFormatter(formatter)\n        self.logger.setLevel(log_level)\n        self.logger.addHandler(console_handler)\n        self.logger.addHandler(file_handler)\n\n    def _init_db(self):\n        conn = sqlite3.connect(self.db_path)\n        c = conn.cursor()\n        c.execute('''CREATE TABLE IF NOT EXISTS tool_executions (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            timestamp TEXT,\n            event TEXT,\n            tool_name TEXT,\n            user_id TEXT,\n            client_ip TEXT,\n            ide_type TEXT,\n            execution_time_ms REAL,\n            request_size INTEGER,\n            response_size INTEGER,\n            success INTEGER,\n            arguments TEXT,\n            response_preview TEXT\n        )''')\n        c.execute('''CREATE TABLE IF NOT EXISTS errors (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            timestamp TEXT,\n            event TEXT,\n            error_type TEXT,\n            error_message TEXT,\n            user_id TEXT,\n            client_ip TEXT,\n            ide_type TEXT,\n            additional_data TEXT\n        )''')\n        conn.commit()\n        conn.close()\n\n    def log_tool_execution(self, tool_name: str, user_id: str, request_data: Dict[str, Any], response_data: Any, execution_time: float, client_info: Dict[str, Any]):\n        execution_data = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"event\": \"tool_executed\",\n            \"tool_name\": tool_name,\n            \"user_id\": user_id,\n            \"client_ip\": client_info.get(\"client_ip\"),\n            \"ide_type\": self.detect_ide(client_info.get(\"user_agent\", \"\")),\n            \"execution_time_ms\": execution_time * 1000,\n            \"request_size\": len(str(request_data)),\n            \"response_size\": len(str(response_data)),\n            \"success\": True,\n            \"arguments\": json.dumps(request_data.get(\"arguments\", {})),\n            \"response_preview\": str(response_data)[:200] + \"...\" if len(str(response_data)) > 200 else str(response_data)\n        }\n        ..."
  },
  {
    "type": "class",
    "name": "MCPSQLiteLogger",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\mcp_sqlite_logger.py"
  },
  {
    "type": "function",
    "name": "__init__",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\mcp_sqlite_logger.py"
  },
  {
    "type": "function",
    "name": "setup_logging",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\mcp_sqlite_logger.py"
  },
  {
    "type": "function",
    "name": "_init_db",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\mcp_sqlite_logger.py"
  },
  {
    "type": "function",
    "name": "log_tool_execution",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\mcp_sqlite_logger.py"
  },
  {
    "type": "function",
    "name": "log_error",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\mcp_sqlite_logger.py"
  },
  {
    "type": "function",
    "name": "detect_ide",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\mcp_sqlite_logger.py"
  },
  {
    "type": "file",
    "name": "mcp_tools.http",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\mcp_tools.http",
    "content": "### List all tools\nGET http://localhost:8000/tools\n\n### Execute a tool (example: scan_codebase)\nPOST http://localhost:8000/tools..."
  },
  {
    "type": "file",
    "name": "monitoring.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py",
    "content": "\"\"\"\nEnhanced logging and monitoring for MCP server\nProvides detailed insights into tool usage, client connections, and performance\n\"\"\"\nimport logging\nimport json\nimport time\nfrom datetime import datetime\nfrom typing import Dict, Any, Optional, List\nfrom functools import wraps\nimport redis\nfrom fastapi import Request\nimport asyncio\n\nclass MCPLogger:\n    def __init__(self, redis_client, log_level=logging.INFO):\n        self.redis_client = redis_client\n        self.logger = logging.getLogger(\"mcp_server\")\n        self.setup_logging(log_level)\n        \n    def setup_logging(self, log_level):\n        \"\"\"Configure detailed logging\"\"\"\n        formatter = logging.Formatter(\n            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n        )\n        \n        # Console handler\n        console_handler = logging.StreamHandler()\n        console_handler.setFormatter(formatter)\n        \n        # File handler\n        file_handler = logging.FileHandler('logs/mcp-server.log')\n        file_handler.setFormatter(formatter)\n        \n        self.logger.setLevel(log_level)\n        self.logger.addHandler(console_handler)\n        self.logger.addHandler(file_handler)\n    \n    def log_connection(self, client_info: Dict[str, Any]):\n        \"\"\"Log client connection details\"\"\"\n        connection_data = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"event\": \"client_connected\",\n            \"client_ip\": client_info.get(\"client_ip\"),\n            \"user_agent\": client_info.get(\"user_agent\"),\n            \"ide_type\": self.detect_ide(client_info.get(\"user_agent\", \"\")),\n            \"user_id\": client_info.get(\"user_id\"),\n            \"connection_type\": client_info.get(\"connection_type\")  # websocket/rest\n        }\n        \n        # Log to file\n        self.logger.info(f\"Client Connected: {json.dumps(connection_data)}\")\n        \n        # Store in Redis for analytics\n        self.redis_client.lpush(\"mcp:connections\", json.dumps(connection_data))\n        self.redis_client.ltrim(\"mcp:connections\", 0, 1000)  # Keep last 1000 connections\n    \n    def log_tool_execution(self, tool_name: str, user_id: str, \n                          request_data: Dict[str, Any], \n                          response_data: Any, execution_time: float,\n                          client_info: Dict[str, Any]):\n        \"\"\"Log detailed tool execution\"\"\"\n        execution_data = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"event\": \"tool_executed\",\n            \"tool_name\": tool_name,\n            \"user_id\": user_id,\n            \"client_ip\": client_info.get(\"client_ip\"),\n            \"ide_type\": self.detect_ide(client_info.get(\"user_agent\", \"\")),\n            \"execution_time_ms\": execution_time * 1000,\n            \"request_size\": len(str(request_data)),\n            \"response_size\": len(str(response_data)),\n            \"success\": True,\n            \"arguments\": request_data.get(\"arguments\", {}),\n            \"response_preview\": str(response_data)[:200] + \"...\" if len(str(response_data)) > 200 else str(response_data)\n        }\n        \n        # Log to file\n        self.logger.info(f\"Tool Executed: {json.dumps(execution_data)}\")\n        \n        # Store in Redis for analytics\n        self.redis_client.lpush(\"mcp:executions\", json.dumps(execution_data))\n        self.redis_client.ltrim(\"mcp:executions\", 0, 10000)  # Keep last 10000 executions\n        \n        # Update tool usage statistics\n        today = datetime.utcnow().strftime(\"%Y-%m-%d\")\n        self.redis_client.hincrby(f\"mcp:stats:{today}\", f\"tool:{tool_name}\", 1)\n        self.redis_client.hincrby(f\"mcp:stats:{today}\", f\"user:{user_id}\", 1)\n        self.redis_client.hincrby(f\"mcp:stats:{today}\", \"total_executions\", 1)\n    \n    def log_error(self, error_type: str, error_message: str, \n                 user_id: str, client_info: Dict[str, Any], \n                 additional_data: Dict[str, Any] = None):\n        \"\"\"Log errors with context\"\"\"\n        error_data = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"event\": \"error\",\n            \"error_type\": error_type,\n            \"error_message\": error_message,\n            \"user_id\": user_id,\n            \"client_ip\": client_info.get(\"client_ip\"),\n      ..."
  },
  {
    "type": "class",
    "name": "MCPLogger",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "class",
    "name": "MCPAnalytics",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "function",
    "name": "track_execution",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "function",
    "name": "__init__",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "function",
    "name": "setup_logging",
    "doc": "Configure detailed logging",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "function",
    "name": "log_connection",
    "doc": "Log client connection details",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "function",
    "name": "log_tool_execution",
    "doc": "Log detailed tool execution",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "function",
    "name": "log_error",
    "doc": "Log errors with context",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "function",
    "name": "detect_ide",
    "doc": "Detect IDE type from user agent",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "function",
    "name": "__init__",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "function",
    "name": "get_usage_stats",
    "doc": "Get usage statistics for a specific date",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "function",
    "name": "get_active_connections",
    "doc": "Get recent active connections",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "function",
    "name": "get_recent_executions",
    "doc": "Get recent tool executions",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "function",
    "name": "get_error_summary",
    "doc": "Get recent errors",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "function",
    "name": "decorator",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\monitoring.py"
  },
  {
    "type": "file",
    "name": "README.md",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\README.md",
    "content": "# MCP Development Assistant Server\n\nA Model Context Protocol (MCP) server that provides development assistance tools for teams, including codebase analysis, git conventions, JIRA patterns, and team collaboration features.\n\n## \ud83d\ude80 Features\n\n- **Codebase Analysis**: Pattern recognition, naming conventions, folder structure analysis\n- **Git Integration**: Commit convention analysis, contributor patterns\n- **JIRA Integration**: Ticket pattern analysis, development insights\n- **Team Collaboration**: Centralized development intelligence\n- **Subscription Management**: Tiered access control with usage tracking\n- **MCP Protocol**: Native VS Code Copilot integration\n\n## \ud83d\udcc1 Architecture\n\n```\nmcp-server/\n\u251c\u2500\u2500 server.py              # FastAPI MCP server\n\u251c\u2500\u2500 auth/                  # Authentication & subscription management\n\u2502   \u2514\u2500\u2500 manager.py\n\u251c\u2500\u2500 core/                  # Tool registry and routing\n\u2502   \u2514\u2500\u2500 tool_registry.py\n\u251c\u2500\u2500 config/                # Configuration management\n\u2502   \u2514\u2500\u2500 settings.py\n\u251c\u2500\u2500 docker/                # Containerization files\n\u251c\u2500\u2500 deploy/                # Cloud deployment scripts\n\u2502   \u2514\u2500\u2500 deploy-aws.sh\n\u2514\u2500\u2500 .env.example          # Environment configuration template\n```\n\n## \ud83d\udd27 Local Development Setup\n\n### Prerequisites\n\n- Python 3.11+\n- Redis server\n- PostgreSQL (optional, SQLite used by default)\n- Git\n\n### Step 1: Clone and Setup\n\n```bash\ncd mcp-server\ncp .env.example .env\n```\n\n### Step 2: Configure Environment\n\nEdit `.env` file with your settings:\n\n```bash\n# Required\nSECRET_KEY=your-secret-key-here\nOPENAI_API_KEY=your-openai-api-key\n\n# Optional (uses defaults)\nREDIS_URL=redis://localhost:6379\nHOST=0.0.0.0\nPORT=8000\n```\n\n### Step 3: Install Dependencies\n\n```bash\npip install -r requirements.txt\n```\n\n### Step 4: Start Redis (Required)\n\n```bash\n# Using Docker\ndocker run -d -p 6379:6379 redis:alpine\n\n# Or install locally\n# Windows: Download from Redis website\n# macOS: brew install redis && brew services start redis\n# Linux: sudo apt install redis-server && sudo systemctl start redis\n```\n\n### Step 5: Run the Server\n\n```bash\npython server.py\n```\n\nServer will be available at:\n\n- **REST API**: <http://localhost:8000>\n- **MCP WebSocket**: ws://localhost:8000/mcp\n- **Health Check**: <http://localhost:8000/>\n\n## \ud83d\udc33 Docker Local Deployment\n\n### Single Container\n\n```bash\n# Build and run\ndocker build -t mcp-dev-assistant .\ndocker run -p 8000:8000 -e OPENAI_API_KEY=your-key mcp-dev-assistant\n```\n\n### Full Stack with Docker Compose\n\n```bash\n# Start all services (Redis, PostgreSQL, MCP Server)\ndocker-compose up -d\n\n# View logs\ndocker-compose logs -f mcp-server\n\n# Stop all services\ndocker-compose down\n```\n\nServices available:\n\n- **MCP Server**: <http://localhost:8000>\n- **Redis**: localhost:6379\n- **PostgreSQL**: localhost:5432\n\n## \u2601\ufe0f Cloud Deployment\n\n### AWS ECS/Fargate Deployment\n\n#### Prerequisites\n\n- AWS CLI configured\n- Docker installed\n- ECR repository access\n\n#### Automated Deployment\n\n```bash\n# Make script executable\nchmod +x deploy/deploy-aws.sh\n\n# Deploy to AWS\n./deploy/deploy-aws.sh\n```\n\n#### Manual AWS Setup\n\n1. **Create ECR Repository**:\n\n```bash\naws ecr create-repository --repository-name mcp-dev-assistant --region us-east-1\n```\n\n2. **Create ECS Cluster**:\n\n```bash\naws ecs create-cluster --cluster-name mcp-dev-assistant\n```\n\n3. **Deploy Infrastructure** (recommended: use CloudFormation):\n\n```bash\n# Create VPC, subnets, load balancer, RDS, ElastiCache\n# See deploy/cloudformation-template.yaml (create if needed)\n```\n\n4. **Deploy Application**:\n\n```bash\n./deploy/deploy-aws.sh\n```\n\n### Google Cloud Run Deployment\n\n```bash\n# Build and deploy\ngcloud run deploy mcp-dev-assistant \\\n  --image gcr.io/PROJECT-ID/mcp-dev-assistant \\\n  --platform managed \\\n  --region us-central1 \\\n  --allow-unauthenticated \\\n  --port 8000 \\\n  --set-env-vars OPENAI_API_KEY=your-key\n```\n\n### Azure Container Instances\n\n```bash\n# Create resource group\naz group create --name mcp-dev-assistant --location eastus\n\n# Deploy container\naz container create \\\n  --resource-group mcp-dev-assistant \\\n  --name mcp-server \\\n  --image your-registry/mcp-dev-assistant \\\n  --ports 8000 \\\n  --environment-variables OPENAI_API_KEY=your-key\n```\n\n## \ud83d\udd0c VS Code Integration\n\n### Method 1: MC..."
  },
  {
    "type": "file",
    "name": "requirements.txt",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\requirements.txt",
    "content": "fastapi>=0.104.1\nuvicorn>=0.24.0\nwebsockets>=12.0\npydantic>=2.5.0\nasyncio-mqtt>=0.16.1\npython-jose[cryptography]>=3.3.0\npasslib[bcrypt]>=1.7.4\nredis>=5.0.0\npsycopg2-binary>=2.9.9\n..."
  },
  {
    "type": "file",
    "name": "server.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\server.py",
    "content": "\"\"\"\nMain MCP Server implementation with Enhanced Monitoring\nHandles MCP protocol communication and routes requests to tools\nIncludes detailed logging, analytics, and verification features\n\"\"\"\nimport asyncio\nimport json\nimport logging\nimport time\nfrom datetime import datetime\nfrom typing import Dict, Any, List, Optional\nfrom fastapi import FastAPI, WebSocket, HTTPException, Depends, Header, Request\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel\nimport uvicorn\n# import redis\n\nfrom core.tool_registry import get_tool_registry\nfrom mcp_server.mcp_sqlite_logger import MCPSQLiteLogger\n# from monitoring import MCPLogger, MCPAnalytics, track_execution\n\n# Configure enhanced logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('logs/mcp-server.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(__name__)\n\n# Initialize FastAPI app\napp = FastAPI(title=\"Development Assistant MCP Server\", version=\"1.0.0\")\n\n# Add CORS middleware\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Initialize managers with monitoring\n# redis_client = redis.from_url(\"redis://localhost:6379\")\ntool_registry = get_tool_registry()\n\n# Initialize monitoring\nmcp_logger = MCPSQLiteLogger()\n# mcp_analytics = MCPAnalytics(redis_client)\n\n# Pydantic models\nclass MCPRequest(BaseModel):\n    method: str\n    params: Dict[str, Any]\n    id: Optional[str] = None\n\nclass MCPResponse(BaseModel):\n    result: Optional[Dict[str, Any]] = None\n    error: Optional[Dict[str, Any]] = None\n    id: Optional[str] = None\n\nclass ToolExecutionRequest(BaseModel):\n    tool_name: str\n    arguments: Dict[str, Any]\n\n# MCP Protocol handlers\nclass MCPHandler:\n    def __init__(self):\n        self.handlers = {\n            \"tools/list\": self.list_tools,\n            \"tools/call\": self.call_tool,\n            \"resources/list\": self.list_resources,\n            \"prompts/list\": self.list_prompts,\n        }\n    \n    async def handle_request(self, request: MCPRequest) -> MCPResponse:\n        \"\"\"Handle MCP request\"\"\"\n        try:\n            if request.method in self.handlers:\n                result = await self.handlers[request.method](request.params)\n                return MCPResponse(result=result, id=request.id)\n            else:\n                error = {\"code\": -32601, \"message\": f\"Method not found: {request.method}\"}\n                return MCPResponse(error=error, id=request.id)\n        \n        except Exception as e:\n            logger.error(f\"Error handling request: {e}\")\n            error = {\"code\": -32603, \"message\": f\"Internal error: {str(e)}\"}\n            return MCPResponse(error=error, id=request.id)\n    \n    async def list_tools(self, params: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"List available tools\"\"\"\n        tools = tool_registry.get_tool_list()\n        \n        return {\"tools\": tools}\n    \n    async def call_tool(self, params: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute a tool\"\"\"\n        tool_name = params.get(\"name\")\n        arguments = params.get(\"arguments\", {})\n        \n        if not tool_name:\n            raise ValueError(\"Tool name is required\")\n        \n        try:\n            result = tool_registry.execute_tool(tool_name, arguments)\n            \n            return {\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": str(result)\n                    }\n                ]\n            }\n        \n        except Exception as e:\n            logger.error(f\"Tool execution error: {e}\")\n            raise ValueError(f\"Tool execution failed: {str(e)}\")\n    \n    async def list_resources(self, params: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"List available resources\"\"\"\n        return {\"resources\": []}\n    \n    async def list_prompts(self, params: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"List available prompts\"\"\"\n        return {\"prompts\": []}\n\n# Initialize MCP handler\nmcp_handler = MCPHandler()\n\n# REST API endpoints\n@app.get(\"/\")\nasync def root():\n    \"\"\"Health check endpoint\"\"\"\n    return {\"status\": \"healthy\", \"service\": \"Development Assistant MCP Server\"}\n\n@app.get(\"/tools\")\nasync def list_tools_rest():\n    \"\"\"REST endpoint to list tools\"\"\"\n    tools = tool_registry.g..."
  },
  {
    "type": "class",
    "name": "MCPRequest",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\server.py"
  },
  {
    "type": "class",
    "name": "MCPResponse",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\server.py"
  },
  {
    "type": "class",
    "name": "ToolExecutionRequest",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\server.py"
  },
  {
    "type": "class",
    "name": "MCPHandler",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\server.py"
  },
  {
    "type": "function",
    "name": "__init__",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\server.py"
  },
  {
    "type": "file",
    "name": "start-server.bat",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\start-server.bat",
    "content": "@echo off\nREM Start MCP Server with Enhanced Monitoring (Windows version)\nREM This script starts the server and provides instructions for testing\n\necho \ud83d\ude80 Starting MCP Development Assistant Server with Enhanced Monitoring\necho ==============================================================\n\nREM Create necessary directories\nif not exist \"logs\" mkdir logs\nif not exist \"data\" mkdir data\n\nREM Check if Redis is running\ntasklist /FI \"IMAGENAME eq redis-server.exe\" 2>NUL | find /I /N \"redis-server.exe\">NUL\nif \"%ERRORLEVEL%\"==\"1\" (\n    echo \u26a0\ufe0f  Redis not detected. Please start Redis manually:\n    echo    - Install Redis for Windows\n    echo    - Or use Docker: docker run -d -p 6379:6379 redis:alpine\n    echo    - Or use WSL with Redis\n    pause\n    exit /b 1\n)\n\necho \u2705 Redis is running\n\nREM Activate virtual environment if it exists\nif exist \"venv\\Scripts\\activate.bat\" (\n    call venv\\Scripts\\activate.bat\n) else (\n    echo \ud83d\udce6 Setting up virtual environment...\n    python -m venv venv\n    call venv\\Scripts\\activate.bat\n    pip install -r requirements.txt\n)\n\necho \ud83d\udcca Starting MCP Server with monitoring...\necho    - REST API: http://localhost:8000..."
  },
  {
    "type": "file",
    "name": "start-server.sh",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\start-server.sh",
    "content": "#!/bin/bash\n# Start MCP Server with Enhanced Monitoring\n# This script starts the server and provides instructions for testing\n\necho \"\ud83d\ude80 Starting MCP Development Assistant Server with Enhanced Monitoring\"\necho \"==============================================================\"\n\n# Create necessary directories\nmkdir -p logs\nmkdir -p data\n\n# Check if Redis is running\nif ! pgrep -x \"redis-server\" > /dev/null; then\n    echo \"\u26a0\ufe0f  Redis not detected. Starting Redis...\"\n    # For Windows with Redis installed\n    if command -v redis-server &> /dev/null; then\n        redis-server &\n    else\n        echo \"\u274c Redis not found. Please install and start Redis first:\"\n        echo \"   - Windows: Download from https://redis.io/download\"\n        echo \"   - Or use Docker: docker run -d -p 6379:6379 redis:alpine\"\n        exit 1\n    fi\nfi\n\necho \"\u2705 Redis is running\"\n\n# Install dependencies if needed\nif [ ! -d \"venv\" ]; then\n    echo \"\ud83d\udce6 Setting up virtual environment...\"\n    python -m venv venv\n    source venv/bin/activate  # For Windows: venv\\Scripts\\activate\n    pip install -r requirements.txt\nelse\n    source venv/bin/activate  # For Windows: venv\\Scripts\\activate\nfi\n\necho \"\ud83d\udcca Starting MCP Server with monitoring...\"\necho \"   - REST API: http://localhost:8000\"\necho \"   - WebSocket: ws://localhost:8000/..."
  },
  {
    "type": "file",
    "name": "test_verification.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\test_verification.py",
    "content": "\"\"\"\nQuick verification that MCP server tools can be accessed locally\n\"\"\"\nimport requests\nimport json\n\ndef test_local_access():\n    base_url = \"http://localhost:8000\"\n    api_key = \"dev-test-key\"\n    headers = {\"X-API-Key\": api_key}\n    \n    print(\"\ud83d\udd0d Testing local MCP server access...\")\n    \n    # Test 1: Basic connectivity\n    try:\n        response = requests.get(f\"{base_url}/\")\n        print(f\"\u2705 Server reachable: {response.json()}\")\n    except Exception as e:\n        print(f\"\u274c Server not running. Start with: python server.py\")\n        return False\n    \n    # Test 2: List tools\n    try:\n        response = requests.get(f\"{base_url}/tools\", headers=headers)\n        tools_json = response..."
  },
  {
    "type": "function",
    "name": "test_local_access",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\test_verification.py"
  },
  {
    "type": "file",
    "name": "__init__.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\__init__.py",
    "content": "# Makes mcp_server..."
  },
  {
    "type": "file",
    "name": "tool_registry.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\core\\tool_registry.py",
    "content": "\"\"\"\nTool registry and routing for MCP server\nMaps tool names to implementations and handles tool discovery\n\"\"\"\nimport importlib\nimport json\nfrom typing import Dict, List, Any, Optional, Callable\nfrom pathlib import Path\n\n# Refactored ToolRegistry to dynamically load tools.json and transform its structure\nclass ToolRegistry:\n    def __init__(self, tools_config_path: str = None):\n        self.tools = {}\n        self.tool_functions = {}\n\n        if tools_config_path:\n            self.load_tools_from_config(tools_config_path)\n        else:\n            raise ValueError(\"tools.json configuration file is required\")\n\n    def load_tools_from_config(self, config_path: str):\n        \"\"\"Load tools from JSON configuration file\"\"\"\n        with open(config_path, 'r') as f:\n            tools_config = json.load(f)\n\n        for tool_config in tools_config:\n            self.register_tool_from_config(tool_config)\n\n    def register_tool_from_config(self, tool_config: Dict[str, Any]):\n        \"\"\"Register a tool from configuration\"\"\"\n        tool_name = tool_config[\"name\"]\n        module_path = tool_config[\"module\"]\n        description = tool_config.get(\"description\", \"\")\n        args_schema = tool_config.get(\"args_schema\", {})\n\n        # Import the module and get the function\n        try:\n            # Add parent directory to Python path for imports\n            import sys\n            parent_dir = str(Path(__file__).parent.parent.parent)\n            if parent_dir not in sys.path:\n                sys.path.insert(0, parent_dir)\n            \n            module = importlib.import_module(module_path)\n            tool_function = getattr(module, tool_name)\n            self.register_tool(tool..."
  },
  {
    "type": "class",
    "name": "ToolRegistry",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\core\\tool_registry.py"
  },
  {
    "type": "function",
    "name": "get_tool_registry",
    "doc": "Get global tool registry instance",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\core\\tool_registry.py"
  },
  {
    "type": "function",
    "name": "__init__",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\core\\tool_registry.py"
  },
  {
    "type": "function",
    "name": "load_tools_from_config",
    "doc": "Load tools from JSON configuration file",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\core\\tool_registry.py"
  },
  {
    "type": "function",
    "name": "register_tool_from_config",
    "doc": "Register a tool from configuration",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\core\\tool_registry.py"
  },
  {
    "type": "function",
    "name": "register_tool",
    "doc": "Register a tool with the registry",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\core\\tool_registry.py"
  },
  {
    "type": "function",
    "name": "get_tool_list",
    "doc": "Get list of available tools",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\core\\tool_registry.py"
  },
  {
    "type": "function",
    "name": "get_tool",
    "doc": "Get tool definition by name",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\core\\tool_registry.py"
  },
  {
    "type": "function",
    "name": "execute_tool",
    "doc": "Execute a tool with given arguments",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\core\\tool_registry.py"
  },
  {
    "type": "file",
    "name": "deploy-aws.sh",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\deploy\\deploy-aws.sh",
    "content": "#!/bin/bash\n\n# AWS ECS Deployment Script for MCP Development Assistant Server\n\nset -e\n\n# Configuration\nAWS_REGION=\"us-east-1\"\nCLUSTER_NAME=\"mcp-dev-assistant\"\nSERVICE_NAME=\"mcp-server\"\nTASK_FAMILY=\"mcp-dev-assistant-task\"\nECR_REPOSITORY=\"mcp-dev-assistant\"\nIMAGE_TAG=\"latest\"\n\necho \"Starting deployment of MCP Development Assistant Server...\"\n\n# Step 1: Build and push Docker image to ECR\necho \"Building Docker image...\"\ndocker build -t $ECR_REPOSITORY:$IMAGE_TAG .\n\n# Get ECR login token\necho \"Logging into ECR...\"\naws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $(aws sts get-caller-identity --query Account --output text).dkr.ecr.$AWS_REGION.amazonaws.com\n\n# Create ECR repository if it doesn't exist\naws ecr describe-repositories --repository-names $ECR_REPOSITORY --region $AWS_REGION 2>/dev/null || \\\naws ecr create-repository --repository-name $ECR_REPOSITORY --region $AWS_REGION\n\n# Tag and push image\nECR_URI=$(aws sts get-caller-identity --query Account --output text).dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPOSITORY:$IMAGE_TAG\ndocker tag $ECR_REPOSITORY:$IMAGE_TAG $ECR_URI\ndocker push $ECR_URI\n\n# Step 2: Update ECS task definition\necho \"Updating ECS task definition...\"\ncat > task-definition.json << EOF\n{\n  \"family\": \"$TASK_FAMILY\",\n  \"networkMode\": \"awsvpc\",\n  \"requiresCompatibilities\": [\"FARGATE\"],\n  \"cpu\": \"1024\",\n  \"memory\": \"2048\",\n  \"executionRoleArn\": \"arn:aws:iam::$(aws sts get-caller-identity --query Account --output text):role/ecsTaskExecutionRole\",\n  \"taskRoleArn\": \"arn:aws:iam::$(aws sts get-caller-identity --query Account --output text):role/ecsTaskRole\",\n  \"containerDefinitions\": [\n    {\n      \"name\": \"mcp-server\",\n      \"image\": \"$ECR_URI\",\n      \"portMappings\": [\n        {\n          \"containerPort\": 8000,\n          \"protocol\": \"tcp\"\n        }\n      ],\n      \"environment\": [\n        {\n          \"name\": \"REDIS_URL\",\n          \"value\": \"redis://mcp-redis.cache.amazonaws.com:6379\"\n        },\n        {\n          \"name\": \"POSTGRES_URL\",\n          \"value\": \"po..."
  },
  {
    "type": "file",
    "name": "mcp-server.log",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\mcp_server\\logs\\mcp-server.log",
    "content": "2025-08-02 01:01:02,739 - mcp_server - ERROR - Error: {\"timestamp\": \"2025-08-01T19:31:02.739187\", \"event\": \"error\", \"error_type\": \"tool_execution_error\", \"error_message\": \"Tool 'scan_codebase' not found\", \"user_id\": {\"client_ip\": \"127.0.0.1\", \"user_agent\": \"python-requests/2.32.3\", \"connection_type\": \"rest\"}, \"client_ip\": null, \"ide_type\": \"unknown\", \"additional_data\": {}}\n2025-08-02 01:01:02,739 - mcp_server - ERROR - Error: {\"timestamp\": \"2025-08-01T19:31:02.739187\", \"event\": \"error\", \"error_type\": \"tool_execution_error\", \"error_message\": \"Tool 'scan_codebase' not found\", \"user_id\": {\"client_ip\": \"127.0.0.1\", \"user_agent\": \"python-requests/2.32.3\", \"connection_type\": \"rest\"}, \"client_ip\": null, \"ide_type\": \"unknown\", \"additional_data\": {}}\n2025-08-02 01:01:02,739 - mcp_server - ERROR - Error: {\"timestamp\": \"2025-08-01T19:31:02.739187\", \"event\": \"error\", \"error_type\": \"tool_execution_error\", \"error_message\": \"Tool 'scan_codebase' not found\", \"user_id\": {\"client_ip\": \"127.0.0.1\", \"user_agent\": \"python-requests/2.32.3\", \"connection_type\": \"rest\"}, \"client_ip\": null, \"ide_type\": \"unknown\", \"additional_data\": {}}\n2025-08-02 01:09:20,818 - mcp_server - ERROR - Error: {\"timestamp\": \"2025-08-01T19:39:20.818130\", \"event\": \"error\", \"error_type\": \"tool_execution_error\", \"error_message\": \"Tool 'scan_codebase' not found\", \"user_id\": {\"client_ip\": \"127.0.0.1\", \"user_agent\": \"python-requests/2.32.3\", \"connection_type\": \"rest\"}, \"client_ip\": null, \"ide_type\": \"unknown\", \"additional_data\": {}}\n2025-08-02 01:09:20,818 - mcp_server - ERROR - Error: {\"timestamp\": \"2025-08-01T19:39:20.818130\", \"event\": \"error\", \"error_type\": \"tool_execution_error\", \"error_message\": \"Tool 'scan_codebase' not found\", \"user_id\": {\"client_ip\": \"127.0.0.1\", \"user_agent\": \"python-requests/2.32.3\", \"connection_type\": \"rest\"}, \"client_ip\": null, \"ide_type\": \"unknown\", \"additional_data\": {}}\n2025-08-02 01:09:20,818 - mcp_server - ERROR - Error: {\"timestamp\": \"2025-08-01T19:39:20.818130\", \"event\": \"error\", \"error_type\": \"tool_execution_error\", \"error_message\": \"Tool 'scan_codebase' not found\", \"user_id\": {\"client_ip\": \"127.0.0.1\", \"user_agent\": \"python-requests/2.32.3\", \"connection_type\": \"rest\"}, \"client_ip\": null, \"ide_type\": \"unknown\", \"additional_data\": {}}\n2025-08-02 01:24:32,819 - mcp_server - ERROR - Error: {\"timestamp\": \"2025-08-01T19:54:32.818256\", \"event\": \"error\", \"error_type\": \"tool_execution_error\", \"error_message\": \"MCPLogger.log_tool_execution() missing 1 required positional argument: 'user_id'\", \"user_id\": {\"client_ip\": \"127.0.0.1\", \"user_agent\": \"python-requests/2.32.3\", \"connection_type\": \"rest\"}, \"client_ip\": null, \"ide_type\": \"unknown\", \"additional_data\": {}}\n2025-08-02 01:24:32,819 - mcp_server - ERROR - Error: {\"timestamp\": \"2025-08-01T19:54:32.818256\", \"event\": \"error\", \"error_type\": \"tool_execution_error\", \"error_message\": \"MCPLogger.log_tool_execution() missing 1 required positional argument: 'user_id'\", \"user_id\": {\"client_ip\": \"127.0.0.1\", \"user_agent\": \"python-requests/2.32.3\", \"connection_type\": \"rest\"}, \"client_ip\": null, \"ide_type\": \"unknown\", \"additional_data\": {}}\n2025-08-02 01:24:32,819 - mcp_server - ERROR - Error: {\"timestamp\": \"2025-08-01T19:54:32.818256\", \"event\": \"error\", \"error_type\": \"tool_execution_error\", \"error_message\": \"MCPLogger.log_tool_execution() missing 1 required positional argument: 'user_id'\", \"user_id\": {\"client_ip\": \"127.0.0.1\", \"user_agent\": \"python-requests/2.32.3\", \"connection_type\": \"rest\"}, \"client_ip\": null, \"ide_type\": \"unknown\", \"additional_data\": {}}\n2025-08-02 01:38:27,964 - mcp_server - ERROR - Error: {\"timestamp\": \"2025-08-01T20:08:27.964511\", \"event\": \"error\", \"error_type\": \"tool_execution_error\", \"error_message\": \"MCPSQLiteLogger.log_tool_execution() missing 1 required positional argument: 'user_id'\", \"user_id\": {\"client_ip\": \"127.0.0.1\", \"user_agent\": \"python-requests/2.32.3\", \"connection_type\": \"rest\"}, \"client_ip\": null, \"ide_type\": \"unknown\", \"additional_data\": \"{}\"}\n2025-08-02 01:38:27,964 - mcp_server - ERROR - Error: {\"timestamp\": \"2025-08-01T20:08:27.964511\", \"event\": \"error\", \"error_type\": \"tool_execution_error\", \"error_message\": \"MCPSQLiteLogger.log_tool_execution() missing 1 required positional argument: 'user_id'\", \"user_id\": {\"client_ip\": \"127.0.0.1\", \"user_agent\": \"python-requests/2.32.3\", \"connection_type\": \"rest\"}, \"client_ip\": null, \"ide_type\": \"unknown\", \"additional_data\": \"{}\"}\n2025-08-02 01:38:27,964 - mcp_server - ERROR - Error: {\"timestamp\": \"2025-08-01T20:08:27.964511\", \"event\": \"error\", \"error_type\": \"tool_execution_error\", \"error_message\": \"MCPSQLiteLogger.log_tool_execution() missing 1 required positional argument: 'user_id'\", \"user_id\": {\"client_ip\": \"127.0.0.1\", \"user_agent\": \"python-requests/2.32.3\", \"connection_type\": \"rest\"}, \"client_ip\": null, \"ide_type\": \"unknown\", \"additional_data\": \"{}\"}\n2025-08-02 01:49:41,960 - mcp_server - INFO - Tool Executed: {\"timestamp\": \"2025-08-01T20:19:41.959074\", \"event\": \"tool_executed\", \"tool_name\": \"scan_codebase\", \"user_id\": \"127.0.0.1\", \"client_ip\":..."
  },
  {
    "type": "file",
    "name": "workflow_context.json",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\output\\workflow_context.json",
    "content": "{\n  \"execution_history\": [],\n  \"data_context\": {\n    \"https://github.com/atulpandey1695/MCP-hackathon.git\": \"https://github.com/atulpandey1695/MCP-hackathon.git\",\n    \"hi\": \"hi\",\n   ..."
  },
  {
    "type": "file",
    "name": ".terraform.lock.hcl",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\terraform\\.terraform.lock.hcl",
    "content": "# This file is maintained automatically by \"terraform init\".\n# Manual edits may be lost in future updates.\n\nprovider \"registry.terraform.io/hashicorp/aws\" {\n  version     = \"5.100.0\"\n  constraints = \"~> 5.0\"\n  hashes = [\n    \"h1:edXOJWE4ORX8Fm+dpVpICzMZJat4AX0VRCAy/xkcOc0=\",\n    \"zh:054b8dd49f0549c9a7cc27d159e45327b7b65cf404da5e5a20da154b90b8a644\",\n    \"zh:0b97bf8d5e03d15d83cc40b0530a1f84b459354939ba6f135a0086c20ebbe6b2\",\n    \"zh:1589a2266af699cbd5d80737a0fe02e54ec9cf2ca54e7e00ac51c7359056f274\",\n    \"zh:6330766f1d85f01ae6ea90d1b214b8b74cc8c1badc4696b165b36ddd4cc15f7b\",\n    \"zh:7c8c2e30d8e55291b86fcb64bdf6c25489d538688545eb48fd74ad622e5d3862\",\n    \"zh:99b1003bd9bd32ee323544da897148f46a527f622dc3971af63ea3e251596342\",\n    \"zh:9b12af85486a96aedd8d7984b0ff811a4b42e3d88dad1a3fb4c0b580d04fa425\",\n    \"zh:9f8b909d3ec50ade83c8062290378b1ec553edef6a447c56dadc01a99f4eaa93\",\n    \"zh:aaef921ff9aabaf8b1869a86d692ebd24fbd4e12c21205034bb679b9caf883a2\",\n    \"zh:ac882313207aba00dd5a76dbd572a0ddc818bb9cbf5c9d61b28fe30efaec951e\",\n    \"zh:bb64e8aff37becab373a1a0cc1080990785304141af42ed6aa3dd4913b000421\",\n    \"zh:dfe495f6621df5540d9c92ad40b8067376350b005c637ea6efac5dc15028add4\",\n    \"zh:f0ddf0eaf052766cfe09dea8200a946519f653c384ab4336e2a4a64fd..."
  },
  {
    "type": "file",
    "name": "deploy.sh",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\terraform\\deploy.sh",
    "content": "#!/bin/bash\n\n# MCP Server AWS Infrastructure Setup Guide\n# Team: Minds-Constructing-Products\n# Manual Terraform Deployment Guide\n\nset -e\n\necho \"\ud83d\ude80 MCP Server AWS Infrastructure Setup Guide\"\necho \"Team: Minds-Constructing-Products\"\necho \"Region: ap-south-1\"\necho \"\"\n\n# Check prerequisites\necho \"\ud83d\udccb Checking prerequisites...\"\n\nif ! command -v terraform &> /dev/null; then\n    echo \"\u274c Terraform is not installed. Please install Terraform first.\"\n    echo \"Installation guide: https://developer.hashicorp.com/terraform/downloads\"\n    exit 1\nfi\n\nif ! command -v aws &> /dev/null; then\n    echo \"\u274c AWS CLI is not installed. Please install AWS CLI first.\"\n    echo \"Installation guide: https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html\"\n    exit 1\nfi\n\n# Check AWS credentials\nif ! aws sts get-caller-identity &> /dev/null; then\n    echo \"\u274c AWS credentials not configured. Please run 'aws configure' first.\"\n    echo \"Configuration guide: https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html\"\n    exit 1\nfi\n\necho \"\u2705 Prerequisites check passed!\"\n\n# Check for manually created key pair\necho \"\ud83d\udd11 Checking for manually created key pair...\"\nif [ -f \"Minds-Constructing-Products-key.pem\" ]; then\n    echo \"\u2705 Key pair file found: Minds-Constructing-Products-key.pem\"\n    echo \"\u2705 Key pair already created manually\"\nelse\n    echo \"\u26a0\ufe0f  Key pair file not found!\"\n    echo \"Please create the key pair manually using:\"\n    echo \"aws ec2 create-key-pair \\\\\"\n    echo \"  --key-name Minds-Constructing-Products-key \\\\\"\n    echo \"  --query 'KeyMaterial' \\\\\"\n    echo \"  --output text \\\\\"\n    echo \"  --tag-specifications 'ResourceType=key-pair,Tags=[{Key=Team,Value=Minds-Constructing-Products},{Key=Name,Value=Minds-Constructing-Products}]' \\\\\"\n    echo \"  > Minds-Constructing-Products-key.pem\"\n    echo \"\"\n    echo \"Then set permissions:\"\n    echo \"chmod 400 Minds-Constructing-Products-key.pem\"\n    exit 1\nfi\n\necho \"\"\necho \"\ud83d\udd27 Manual Terraform Deployment Steps:\"\necho \"=====================================\"\necho \"\"\necho \"Step 1: Initialize Terraform\"\necho \"----------------------------\"\necho \"terraform..."
  },
  {
    "type": "file",
    "name": "main.tf",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\terraform\\main.tf",
    "content": "terraform {\n  required_version = \">= 1.0\"\n}\n\nprovider \"aws\" {\n  region = \"ap-south-1\"\n  \n  default_tags {\n    tags = {\n      Team = \"Minds-Constructing-Products\"\n      Name = \"Minds-Constructing-Products\"\n      Environment = \"production\"\n      Project = \"MCP-Server\"\n    }\n  }\n}\n\n# Data sources\ndata \"aws_vpc\" \"default\" {\n  default = true\n}\n\ndata \"aws_subnets\" \"public\" {\n  filter {\n    name   = \"vpc-id\"\n    values = [data.aws_vpc.default.id]\n  }\n  \n  filter {\n    name   = \"map-public-ip-on-launch\"\n    values = [\"true\"]\n  }\n}\n\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\ndata \"aws_ami\" \"amazon_linux_2\" {\n  most_recent = true\n  owners      = [\"amazon\"]\n\n  filter {\n    name   = \"name\"\n    values = [\"amzn2-ami-hvm-*-x86_64-gp2\"]\n  }\n\n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n}\n\n# Security Groups - CORRECTED\nresource \"aws_security_group\" \"mcp_server\" {\n  name_prefix = \"mcp-server-sg\"\n  vpc_id      = data.aws_vpc.default.id\n\n  # MCP Server API\n  ingress {\n    from_port   = 8000\n    to_port     = 8000\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n    description = \"MCP Server API\"\n  }\n\n  # SSH Access\n  ingress {\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n    description = \"SSH Access\"\n  }\n\n  # PostgreSQL - INTERNAL ONLY\n  ingress {\n    from_port   = 5432\n    to_port     = 5432\n    protocol    = \"tcp\"\n    cidr_blocks = [\"10.0.0.0/8\", \"172.16.0.0/12\", \"192.168.0.0/16\"]\n    description = \"PostgreSQL Database\"\n  }\n\n  # Redis - INTERNAL ONLY\n  ingress {\n    from_port   = 6379\n    to_port     = 6379\n    protocol    = \"tcp\"\n    cidr_blocks = [\"10.0.0.0/8\", \"172.16.0.0/12\", \"192.168.0.0/16\"]\n    description = \"Redis Cache\"\n  }\n\n  # HTTP for future load balancer\n  ingress {\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n    description = \"HTTP Access\"\n  }\n\n  # HTTPS for future load balancer\n  ingress {\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n    description = \"HTTPS Access\"\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    pr..."
  },
  {
    "type": "file",
    "name": "outputs.tf",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\terraform\\outputs.tf",
    "content": "output \"mcp_server_public_ip\" {\n  description = \"Public IP of the MCP server instance\"\n  value       = aws_instance.mcp_server.public_ip\n}\n\noutput \"mcp_server_private_ip\" {\n  description = \"Private IP of the MCP server instance\"\n  value       = aws_instance.mcp_server.private_ip\n}\n\noutput \"ecr_repository_url\" {\n  description = \"ECR repository URL\"\n  value       = aws_ecr_repository.mcp_server.repository_url\n}\n\noutput \"s3_bucket_name\" {\n  description = \"S3 bucket name for data storage\"\n  value       = aws_s3_bucket.mcp_data.bucket\n}\n\noutput \"application_urls\" {\n  description = \"Application access URLs\"\n  value = {\n    rest_api     = \"http://${aws_instance.mcp_server.public_ip}:8000\"\n    websocket    = \"ws://${aws_instan..."
  },
  {
    "type": "file",
    "name": "README.md",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\terraform\\README.md",
    "content": "# MCP Server AWS Infrastructure\n\nThis Terraform configuration deploys a cost-optimized, scalable AWS infrastructure for the MCP (Model Context Protocol) Development Assistant Server.\n\n## \ud83c\udfd7\ufe0f Architecture Overview\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Internet      \u2502    \u2502   ALB           \u2502    \u2502   EC2 Instance  \u2502\n\u2502                 \u2502\u2500\u2500\u2500\u2500\u2502   (Load         \u2502\u2500\u2500\u2500\u2500\u2502   (t2.micro)    \u2502\n\u2502                 \u2502    \u2502   Balancer)     \u2502    \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                       \u2502\n                                                       \u25bc\n                                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                              \u2502   RDS           \u2502\n                                              \u2502   PostgreSQL    \u2502\n                                              \u2502   (db.t2.micro) \u2502\n                                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n## \ud83d\udccb Infrastructure Components\n\n### Compute\n- **EC2 Instance**: `t2.micro` (1 vCPU, 1GB RAM, 20GB EBS)\n- **AMI**: Amazon Linux 2023 ARM64\n- **Auto-scaling**: Manual scaling capability\n\n### Database\n- **RDS PostgreSQL**: `db.t2.micro` (1 vCPU, 1GB RAM, 10GB storage)\n- **Backup**: 7-day retention\n- **Encryption**: Enabled\n\n### Storage\n- **S3 Bucket**: `minds-constructing-products-mcp-data`\n- **ECR Repository**: `minds-constructing-products/mcp-server`\n\n### Networking\n- **Load Balancer**: Application Load Balancer\n- **Security Groups**: Restricted access\n- **VPC**: Default VPC in ap-south-1\n\n### Monitoring\n- **CloudWatch Logs**: `/aws/mcp-server`\n- **Health Checks**: Application-level monitoring\n\n## \ud83d\ude80 Quick Start\n\n### Prerequisites\n1. AWS CLI configured\n2. Terraform installed\n3. SSH key pair (auto-generated)\n\n### Deployment Steps\n\n```bash\n# 1. Clone the repository\ngit clone <repository-url>\ncd MCP-hackathon/terraform\n\n# 2. Run deployment script\nchmod +x deploy.sh\n./deploy.sh\n```\n\n### Manual Deployment\n\n```bash\n# Initialize Terraform\nterraform init\n\n# Plan deployment\nterraform plan\n\n# Apply configuration\nterraform apply\n```\n\n## \ud83d\udd27 Configuration\n\n### Environment Variables\n- `AWS_REGION`: ap-south-1\n- `TEAM_NAME`: Minds-Constructing-Products\n- `INSTANCE_TYPE`: t2.micro\n- `RDS_INSTANCE_CLASS`: db.t2.micro\n\n### Customization\nEdit `variables.tf` to modify:\n- Instance types\n- Storage sizes\n- Region settings\n- Team name\n\n## \ud83d\udcca Monitoring & Logging\n\n### Application URLs\n- **REST API**: ..."
  },
  {
    "type": "file",
    "name": "user_data.sh",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\terraform\\user_data.sh",
    "content": "#!/bin/bash\n\n# MCP Server Deployment Script\n# CORRECTED based on manual workaround\n\nset -e  # Exit on any error\n\necho \"\ud83d\ude80 Starting MCP Server deployment...\"\n\n# Update system\necho \"\ud83d\udce6 Updating system packages...\"\nyum update -y\n\n# Install required packages\necho \"\ud83d\udce6 Installing required packages...\"\nyum install -y docker git curl wget\n\n# Start and enable Docker\necho \"\ud83d\udc33 Setting up Docker...\"\nsystemctl start docker\nsystemctl enable docker\n\n# Install Docker Compose\necho \"\ud83d\udce6 Installing Docker Compose...\"\ncurl -L \"https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose\n\n# Install PostgreSQL - CORRECTED\necho \"\ud83d\uddc4\ufe0f Installing PostgreSQL...\"\nyum install -y postgresql postgresql-server postgresql-contrib\n\n# Initialize PostgreSQL - CORRECTED\necho \"\ud83d\uddc4\ufe0f Initializing PostgreSQL...\"\n/usr/bin/postgresql-setup initdb\nsystemctl enable postgresql\nsystemctl start postgresql\n\n# Wait for PostgreSQL to be ready\necho \"\u23f3 Waiting for PostgreSQL to start...\"\nsleep 10\n\n# Create PostgreSQL user and database - CORRECTED\necho \"\ud83d\udc64 Creating database user and database...\"\nsudo -u postgres psql -c \"CREATE USER mcp_admin WITH PASSWORD 'mcp_password_123';\" 2>/dev/null || echo \"User might already exist\"\nsudo -u postgres psql -c \"CREATE DATABASE mcp_assistant OWNER mcp_admin;\" 2>/dev/null || echo \"Database might already exist\"\nsudo -u postgres psql -c \"GRANT ALL PRIVILEGES ON DATABASE mcp_assistant TO mcp_admin;\"\n\n# Configure PostgreSQL - CORRECTED\necho \"\ud83d\udd27 Configuring PostgreSQL...\"\nsed -i \"s/#listen_addresses = 'localhost'/listen_addresses = '*'/\" /var/lib/pgsql/data/postgresql.conf\nsed -i \"s/#port = 5432/port = 5432/\" /var/lib/pgsql/data/postgresql.conf\n\n# Configure PostgreSQL authentication - CORRECTED\necho \"host    mcp_assistant    mcp_admin    127.0.0.1/32            md5\" | sudo tee -a /var/lib/pgsql/data/pg_hba.conf\necho \"host    mcp_assistant    mcp_admin    ::1/128                 md5\" | sudo tee -a /var/lib/pgsql/data/pg_hba.conf\n\n# Add Docker network access - CORRECTED\necho \"host    mcp_assistant    mcp_admin    172.17.0.0/16           md5\" | sudo tee -a /var/lib/pgsql/data/pg_hba.conf\necho \"host    mcp_assistant    mcp_admin    172.18.0.0/16           md5\" | sudo tee -a /var/lib/pgsql/data/pg_hba.conf\necho \"host    mcp_assistant    mcp_admin    172.19.0.0/16           md5\" | sudo tee -a /var/lib/pgsql/data/pg_hba.conf\necho \"host    mcp_assistant    mcp_admin    172.20.0.0/16           md5\" | sudo tee -a /var/lib/pgsql/data/pg_hba.conf\necho \"host    mcp_assistant    mcp_admin    172.21.0.0/16           md5\" | sudo tee -a /var/lib/pgsql/data/pg_hba.conf\n\n# Restart PostgreSQL\nsystemctl restart postgresql\n\n# Stop system Redis to avoid conflicts\necho \"\ud83d\udd34 Stopping system Redis...\"\nsystemctl stop redis || true\nsystemctl disable redis || true\n\n# Create application directory\necho \"\ud83d\udcc1 Creating application directory...\"\nmkdir -p /opt/mcp-server\ncd /opt/mcp-server\n\n# Clone the repository\necho \"\ufffd\ufffd Cloning MCP server repository...\"\ngit clone https://github.com/atulpandey1695/MCP-hackathon.git .\n\n# Navigate to the correct directory\ncd MCP-hackathon\n\n# Create Dockerfile - CORRECTED\necho \"\ud83d\udc33 Creating Dockerfile...\"\ncat > Docke..."
  },
  {
    "type": "file",
    "name": "variables.tf",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\terraform\\variables.tf",
    "content": "variable \"aws_region\" {\n  description = \"AWS region\"\n  type        = string\n  default     = \"ap-south-1\"\n}\n\nvariable \"team_name\" {\n  description = \"Team name for resource tagging\"\n  type        = string\n  default     = \"Minds-Constructing-Products\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name\"\n  type        = string\n  default     = \"production\"\n}\n\nvariable \"instance_type\" {\n  description = \"EC2 instance type\"\n  type        = string\n  default     = \"t2.micro\"\n}\n\nvariable \"rds_instance_class\" {\n  description = \"RDS instance class\"\n  type        = string\n  default     = \"db.t2.micro\"\n}\n\nvariable \"rds_allocated_storag..."
  },
  {
    "type": "file",
    "name": "versions.tf",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\terraform\\versions.tf",
    "content": "terraform {\n  required_version = \">= 1.0\"\n  \n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n   ..."
  },
  {
    "type": "file",
    "name": "custom_api.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\custom_api.py",
    "content": "import json\nimport requests\nfrom langchain.tools import tool\n\n@tool\ndef custom_api(input: str) -> str:\n    \"\"\"\n    Calls your internal .NET microservice.\n    Example endpoint: http://localhost:5000/api/summarise\n    \"\"\"\n    endpoint = \"http://localhost:5000/api/summarise\"..."
  },
  {
    "type": "function",
    "name": "custom_api",
    "doc": "Calls your internal .NET microservice.\nExample endpoint: http://localhost:5000/api/summarise",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\custom_api.py"
  },
  {
    "type": "file",
    "name": "google_search.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\google_search.py",
    "content": "import json\nimport requests\nimport bs4\nfrom langchain.tools import tool\n\n@tool\ndef google_search(query: str) -> str:\n    \"\"\"\n    Scrapes DuckDuckGo (no API key) for the first 5 organic results.\n    \"\"\"\n    url = \"https://duckduckgo.com/html/\"\n    headers = {\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n    }\n    ..."
  },
  {
    "type": "function",
    "name": "google_search",
    "doc": "Scrapes DuckDuckGo (no API key) for the first 5 organic results.",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\google_search.py"
  },
  {
    "type": "file",
    "name": "question_answering_module.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\question_answering_module.py",
    "content": "\nfrom langchain.tools import tool\n\n@tool\ndef question_answering(query: str) -> str:\n    \"\"\"\n    Perform logical reason..."
  },
  {
    "type": "function",
    "name": "question_answering",
    "doc": "Perform logical reasoning and answer questions based on the query.",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\question_answering_module.py"
  },
  {
    "type": "file",
    "name": "__init__.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\__init__.py",
    "content": ""
  },
  {
    "type": "file",
    "name": "codebase_tools.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\codebase_tools.py",
    "content": "import tempfile\nimport shutil\nimport subprocess\nimport openai\nimport os\nimport json\nimport ast\ndef train_agent_on_github_repo(repo_url, output_path=None):\n    \"\"\"\n    Clones a GitHub repo, indexes its codebase, and updates the agent's knowledge base.\n    \"\"\"\n    target_dir = os.getcwd() + '/target'  # Use current working directory\n    repo_name = repo_url.rstrip('/').split('/')[-1].replace('.git', '')\n    clone_path = os.path.join(target_dir, repo_name)\n    # Ensure target_dir is empty before cloning\n    if os.path.exists(target_dir):\n        # Remove target_dir even if it contains read-only files\n        def onerror(func, path, exc_info):\n            import stat\n            os.chmod(path, stat.S_IWRITE)\n            func(path)\n        shutil.rmtree(target_dir, onerror=onerror)\n    try:\n        print(f\"Cloning repo {repo_url} to {target_dir}...\")\n        subprocess.run([\"git\", \"clone\", repo_url, target_dir], check=True)\n        print(\"Generating codebase index...\")\n        result = generate_codebase_index(codebase_path=target_dir, output_path=output_path)\n        print(result)\n        return result\n    except Exception as e:\n        return f\"[ERROR] Failed to train agent on repo: {e}\"\n   \ndef convert_codebase_index_to_faiss():\n    \"\"\"\n    Convert codebase_index.json to FAISS index for semantic search.\n    \"\"\"\n    from tools.utils.faiss_converter import codebase_json_to_faiss\n    json_file_path = os.path.join(os.path.dirname(__file__), '..', 'output', 'codebase_index.json')\n    faiss_index_path = os.path.join(os.path.dirname(__file__), '..', 'output', 'codebase_faiss_index')\n    \n    faiss_index = codebase_json_to_faiss(json_file_path, faiss_index_path)\n    print(f\"FAISS index created at {faiss_index_path}\")\n\ndef generate_codebase_index(codebase_path=None, output_path=None):\n    \"\"\"\n    Scans the codebase directory for Python and TypeScript/JavaScript files, extracts function/class names and docstrings/comments, and saves the index as JSON.\n    \"\"\"\n    if codebase_path is None:\n        codebase_path = os.path.join(os.path.dirname(__file__), '..', '..', 'codebase')\n    if output_path is None:\n        output_path = os.path.join(os.path.dirname(__file__), '..', 'output', 'codebase_index.json')\n    index = []\n    import re\n    function_regex = re.compile(r'(?:function\\s+|const\\s+|let\\s+|var\\s+)?([a-zA-Z0-9_]+)\\s*\\([^)]*\\)\\s*{')\n    class_regex = re.compile(r'class\\s+([a-zA-Z0-9_]+)')\n    for root, dirs, files in os.walk(codebase_path):\n        # Skip any directory containing '.git' in its path\n        if '.git' in root:\n            continue\n        dirs[:] = [d for d in dirs if '.git' not in d and d not in ['__pycache__', '.svn', '.hg']]\n        for file in files:\n            file_path = os.path.join(root, file)\n            # Skip any file containing '.git' in its path\n            if '.git' in file_path:\n                continue\n            # Read file content (truncate to first 1000 chars for large files)\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    file_content = f.read()\n            except Exception:\n                file_content = ''\n            half_length = len(file_content) // 2\n            half_content = file_content[:half_length] + ('...' if len(file_content) > half_length else '')\n            # Add file-level entry with half content\n            index.append({\n                'type': 'file',\n                'name': file,\n                'file': file_path,\n                'content': half_content\n            })\n            if file.endswith('.py'):\n                try:\n                    tree = ast.parse(file_content, filename=file_path)\n                    for node in ast.walk(tree):\n                        if isinstance(node, ast.FunctionDef):\n                            index.append({\n                                'type': 'function',\n                                'name': node.name,\n                                'doc': ast.get_docstring(node),\n                                'file': file_path\n                            })\n                        elif isinstance(node, ast.ClassDef):\n                            index.append({\n                                'type': 'class',\n                                'name': node.name,\n                                'doc': ast.get_docstring(node),\n                                'file': file_path\n                            })\n                except Exception:\n                    pass\n            elif file.endswith('.ts') or file.endswith('.js'):\n                # Extract comments\n                lines = file_content.splitlines()\n                comments = [line.strip() for line in li..."
  },
  {
    "type": "function",
    "name": "train_agent_on_github_repo",
    "doc": "Clones a GitHub repo, indexes its codebase, and updates the agent's knowledge base.",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\codebase_tools.py"
  },
  {
    "type": "function",
    "name": "convert_codebase_index_to_faiss",
    "doc": "Convert codebase_index.json to FAISS index for semantic search.",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\codebase_tools.py"
  },
  {
    "type": "function",
    "name": "generate_codebase_index",
    "doc": "Scans the codebase directory for Python and TypeScript/JavaScript files, extracts function/class names and docstrings/comments, and saves the index as JSON.",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\codebase_tools.py"
  },
  {
    "type": "function",
    "name": "search_codebase_index",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\codebase_tools.py"
  },
  {
    "type": "function",
    "name": "onerror",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\codebase_tools.py"
  },
  {
    "type": "file",
    "name": "git_tools.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\git_tools.py",
    "content": "import json\nimport os\nfrom datetime import datetime\nimport git\nimport shutil\nimport tempfile\nfrom langchain.tools import tool\n\n\n@tool\ndef fetch_remote_git_history(repo_url, branch='main', max_commits=50, output_file='tools/output/git_history_index.json', auth_token=None):\n    \"\"\"Fetch git history from a remote repository URL and write to file\n    \n    Args:\n        repo_url (str): Repository URL to clone\n        branch (str): Branch to fetch from (default: 'main')\n        max_commits (int): Maximum number of commits to fetch (default: 50)\n        output_file (str): Output file path (default: 'tools/output/git_history_index.json.json')\n        auth_token (str): Optional GitHub token for private repos\n        \n    Returns:\n        dict: Result dictionary with status, message, and metadata\n    \"\"\"\n    try:\n        if not repo_url:\n            return {'error': 'repo_url is required', 'status': 'error'}\n        \n        # Create temporary directory for cloning\n        temp_dir = tempfile.mkdtemp(prefix='git_clone_')\n        \n        try:\n            # Prepare authenticated URL if token provided\n            if auth_token and 'github.com' in repo_url:\n                if repo_url.startswith('https://'):\n                    authenticated_url = repo_url.replace('https://github.com/', f'https://{auth_token}@github.com/')\n                else:\n                    authenticated_url = repo_url\n            else:\n                authenticated_url = repo_url\n            \n            # Clone the repository\n            print(f\"Cloning repository: {repo_url}\")\n            repo = git.Repo.clone_from(authenticated_url, temp_dir, depth=max_commits + 10)\n            \n            # Get the current branch name safely\n            try:\n                current_branch = repo.active_branch.name\n            except:\n                current_branch = \"HEAD\"\n            \n            # Switch to specified branch if not default\n            try:\n                if branch != 'main' and branch != current_branch:\n                    repo.git.checkout(branch)\n                    current_branch = branch\n            except:\n                # If branch switch fails, continue with current branch\n                pass\n            \n            # Get commits from the repository\n            try:\n                commits = list(repo.iter_commits(max_count=max_commits))\n            except Exception as e:\n                return {'error': f'Failed to get commits: {str(e)}', 'status': 'error'}\n            \n            # Extract commit information\n            git_history = []\n            for commit in commits:\n                # Get changed files\n                changed_files = []\n                if commit.parents:  # Not the initial commit\n                    try:\n                        diff = commit.parents[0].diff(commit)\n                        changed_files = [item.a_path or item.b_path for item in diff]\n                    except:\n                        changed_files = []\n                commit_info = {\n                    \"sha\": commit.hexsha,\n                    \"short_sha\": commi..."
  },
  {
    "type": "function",
    "name": "fetch_remote_git_history",
    "doc": "Fetch git history from a remote repository URL and write to file\n\nArgs:\n    repo_url (str): Repository URL to clone\n    branch (str): Branch to fetch from (default: 'main')\n    max_commits (int): Maximum number of commits to fetch (default: 50)\n    output_file (str): Output file path (default: 'tools/output/git_history_index.json.json')\n    auth_token (str): Optional GitHub token for private repos\n    \nReturns:\n    dict: Result dictionary with status, message, and metadata",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\git_tools.py"
  },
  {
    "type": "function",
    "name": "convert_remote_git_history_index_to_faiss",
    "doc": "Convert remote_git_history_index.json to FAISS index for semantic search.",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\git_tools.py"
  },
  {
    "type": "file",
    "name": "jira_tools.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\jira_tools.py",
    "content": "\"\"\"\nJIRA integration tools\n\"\"\"\nimport json\nimport requests\nfrom enhanced_context_manager import get_context_manager\nfrom langchain.tools import tool\nfrom tools.utils.faiss_converter import json_to_faiss\n\n@tool\ndef jira_ticket_summarizer(domainUrl: str, userName: str, token: str, query: str) -> str:\n    \"\"\"\n    Fetch JIRA tickets, summarize them into a PRD, and save the context in JSON format.\n    \"\"\"\n    # Validate input parameters\n    if not all([domainUrl, userName, token, query]):\n        return \"Missing required parameters. Please provide domainUrl, userName, token, and query.\"\n\n    # Construct JIRA API URL and credentials dynamically\n    jira_api_url = f\"{domainUrl}/rest/api/latest/search\"\n    auth = (userName, token)\n\n    # Step 1: Fetch JIRA tickets\n    tickets = fetch_jira_tickets(jira_api_url, auth, query)\n\n    print(f\"Fetched {len(tickets)} JIRA tickets.\")\n    \n    # Step 2: Summarize tickets into a PRD\n    prd = summarize_tickets(tickets)\n    \n    # Step 3: Save the PRD to a JSON file\n    save_prd_to_json(prd)\n\n    convert_to_faiss()\n    \n    return \"JIRA tickets summarized and saved to jira_tickets_stories_context.json.\"\n\ndef fetch_jira_tickets(jira_api_url: str, auth: tuple, query: str):\n    \"\"\"Fetch JIRA tickets using the JIRA API.\"\"\"\n    headers = {\n        \"Content-Type\": \"application/json\"\n    }\n    params = {\n        \"jql\": query,\n        \"fields\": \"*all\"\n    }\n    response = requests.get(jira_api_url, headers=headers, auth=auth, params=params)\n    if response.status_code != 200:\n        raise Exception(f\"Failed to fetch JIRA tickets: {response.status_code} - {response..."
  },
  {
    "type": "function",
    "name": "jira_ticket_summarizer",
    "doc": "Fetch JIRA tickets, summarize them into a PRD, and save the context in JSON format.",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\jira_tools.py"
  },
  {
    "type": "function",
    "name": "fetch_jira_tickets",
    "doc": "Fetch JIRA tickets using the JIRA API.",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\jira_tools.py"
  },
  {
    "type": "function",
    "name": "summarize_tickets",
    "doc": "Summarize JIRA tickets into a PRD format.",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\jira_tools.py"
  },
  {
    "type": "function",
    "name": "save_prd_to_json",
    "doc": "Save the PRD to a JSON file.",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\jira_tools.py"
  },
  {
    "type": "function",
    "name": "convert_to_faiss",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\development\\jira_tools.py"
  },
  {
    "type": "file",
    "name": "codebase_index.json",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\output\\codebase_index.json",
    "content": "[\n  {\n    \"type\": \"file\",\n    \"name\": \".env\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\.env\",\n    \"content\": \"OPENAI_API_KEY=PsCsoyu2KFQD4xvd8uXQbRXe3ZSpbZzJn8W3P5BQ\\nJIRA_PARAM=ATATT3xFfGF0kNQ6mdntUjHIyk8XBc6X_4W4l1ZSMkzDBcNGu8ExuWy09KcP4m...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"ARCHITECTURE_ANALYSIS.md\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\ARCHITECTURE_ANALYSIS.md\",\n    \"content\": \"# MCP Server AWS Infrastructure - Architecture Analysis & Troubleshooting Guide\\n\\n## \\ud83c\\udfd7\\ufe0f **Complete Architecture Flow Diagram**\\n\\n```mermaid\\ngraph TB\\n    subgraph \\\"Internet\\\"\\n        Client[Client/Browser]\\n        SSH[SSH Client]\\n    end\\n    \\n    subgraph \\\"AWS Cloud (ap-south-1)\\\"\\n        subgraph \\\"VPC (Default)\\\"\\n            subgraph \\\"Public Subnet\\\"\\n                EC2[EC2 Instance<br/>t2.micro<br/>Amazon Linux 2<br/>Public IP: 13.234.xxx.xxx]\\n            end\\n            \\n            subgraph \\\"Security Groups\\\"\\n                SG_EC2[EC2 Security Group<br/>Ports: 22, 8000]\\n            end\\n            \\n            subgraph \\\"Storage & Services\\\"\\n                S3[S3 Bucket<br/>minds-constructing-products-mcp-data]\\n                ECR[ECR Repository<br/>minds-constructing-products/mcp-server]\\n                CW[CloudWatch Logs<br/>/aws/mcp-server]\\n            end\\n        end\\n    end\\n    \\n    subgraph \\\"EC2 Instance Components\\\"\\n        subgraph \\\"System Services\\\"\\n            Docker[Docker Engine]\\n            PostgreSQL[PostgreSQL 12<br/>localhost:5432]\\n            SystemD[SystemD Service<br/>mcp-server.service]\\n        end\\n        \\n        subgraph \\\"Application Stack\\\"\\n            MCP_App[MCP Server<br/>FastAPI<br/>Port 8000]\\n            Redis[Redis 7<br/>Port 6379]\\n            DockerCompose[Docker Compose<br/>Resource Limits]\\n        end\\n        \\n        subgraph \\\"Data & Logs\\\"\\n            AppLogs[Application Logs<br/>/opt/mcp-server/logs]\\n            PGData[PostgreSQL Data<br/>/var/lib/pgsql/12]\\n            RedisData[Redis Data<br/>/var/lib/redis]\\n        end\\n    end\\n    \\n    %% Connections\\n    Client -->|HTTP/WebSocket| EC2\\n    SSH -->|SSH Key| EC2\\n    EC2 --> SG_EC2\\n    EC2 --> S3\\n    EC2 --> ECR\\n    EC2 --> CW\\n    \\n    %% Internal connections\\n    EC2 --> Docker\\n    Docker --> MCP_App\\n    Docker --> Redis\\n    MCP_App --> PostgreSQL\\n    MCP_App --> Redis\\n    SystemD --> DockerCompose\\n    \\n    %% Data flows\\n    MCP_App --> AppLogs\\n    PostgreSQL --> PGData\\n    Redis --> RedisData\\n```\\n\\n## \\ud83d\\udcca **Infrastructure Components Checklist**\\n\\n### \\u2705 **AWS Resources Deployed**\\n- [x] **EC2 Instance** (t2.micro, Amazon Linux 2)\\n- [x] **Security Groups** (Ports 22, 8000 open)\\n- [x] **S3 Bucket** (minds-constructing-products-mcp-data)\\n- [x] **ECR Repository** (minds-constructing-products/mcp-server)\\n- [x] **CloudWatch Logs** (/aws/mcp-server)\\n- [x] **Public IP** (for SSH access)\\n\\n### \\u2705 **Application Stack**\\n- [x] **Docker Engine** (for containerization)\\n- [x] **Docker Compose** (for orchestration)\\n- [x] **PostgreSQL 12** (local database)\\n- [x] **Redis 7** (caching & sessions)\\n- [x] **MCP Server** (FastAPI application)\\n- [x] **SystemD Service** (auto-restart)\\n\\n### \\u2705 **Security & Networking**\\n- [x] **SSH Access** (port 22)\\n- [x] **HTTP Access** (port 8000)\\n- [x] **Public IP** (for external access)\\n- [x] **Security Groups** (restricted access)\\n\\n## \\ud83d\\udd0d **Comprehensive Troubleshooting Guide**\\n\\n### **1. SSH Connectivity Check**\\n\\n```bash\\n# Check if you can SSH to the instance\\nssh -i \\\"Minds-Constructing-Products-key.pem\\\" ec2-user@<PUBLIC_IP>\\n\\n# If SSH fails, check:\\n# - Key permissions: chmod 400 Minds-Constructing-Products-key.pem\\n# - Security group allows port 22\\n# - Instance is running\\n```\\n\\n### **2. System Services Status**\\n\\n```bash\\n# Check system services\\nsudo systemctl status docker\\nsudo systemctl status postgresql-12\\nsudo systemctl status mcp-server.service\\n\\n# Check if services are enabled\\nsudo systemctl is-enabled docker\\nsudo systemctl is-enabled postgresql-12\\nsudo systemctl is-enabled mcp-server.service\\n```\\n\\n### **3. Docker & Application Status**\\n\\n```bash\\n# Check Docker containers\\ncd /opt/mcp-server\\ndocker-compose ps\\ndocker-compose logs mcp-server\\ndocker-compose logs redis\\n\\n# Check if containers are running\\ndocker ps -a\\n\\n# Check resource usage\\ndocker stats\\n```\\n\\n### **4. Database Connectivity**\\n\\n```bash\\n# Test PostgreSQL connection\\nsudo -u postgres psql -c \\\"SELECT version();\\\"\\nsudo -u postgres psql -c \\\"SELECT current_database();\\\"\\nsudo -u postgres psql -c \\\"SELECT * FROM pg_user;\\\"\\n\\n# Test database from application\\nsudo -u postgres psql -d mcp_assistant -c \\\"SELECT 1;\\\"\\n```\\n\\n### **5. Application Health Checks**\\n\\n```bash\\n# Check if MCP server...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"ARCHITECTURE_DIAGRAM.md\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\ARCHITECTURE_DIAGRAM.md\",\n    \"content\": \"# MCP Server Architecture Diagrams\\n## Technical Implementation Guide\\n\\n---\\n\\n## \\ud83c\\udfd7\\ufe0f **System Architecture Overview**\\n\\n### **High-Level Architecture**\\n```\\n\\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n\\u2502                              CLIENT LAYER                                  \\u2502\\n\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\\n\\u2502  Web Browser  \\u2502  Mobile App  \\u2502  API Client  \\u2502  Third-party Integration   \\u2502\\n\\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n                                    \\u2502\\n                                    \\u25bc\\n\\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n\\u2502                           LOAD BALANCER LAYER                             \\u2502\\n\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\\n\\u2502                    AWS Application Load Balancer (Future)                  \\u2502\\n\\u2502                              Port 80/443                                  \\u2502\\n\\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n                                    \\u2502\\n                                    \\u25bc\\n\\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n\\u2502                          APPLICATION LAYER                                \\u2502\\n\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\\n\\u2502                                                                             \\u2502\\n\\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502\\n\\u2502  \\u2502                    MCP SERVER CONTAINER                            \\u2502    \\u2502\\n\\u2502  \\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2502   Flask App     \\u2502  \\u2502   LangChain     \\u2502  \\u2502   Tool Registry \\u2502    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2502   (Port 8000)   \\u2502  \\u2502   Integration   \\u2502  \\u2502   & Management  \\u2502    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502    \\u2502\\n\\u2502  \\u2502                                                                         \\u2502    \\u2502\\n\\u2502  \\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2502   REST API      \\u2502  \\u2502   Health Check  \\u2502  \\u2502   Multi-Agent   \\u2502    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2502   Endpoints     \\u2502  \\u2502   Monitoring    \\u2502  \\u2502   Coordinator   \\u2502    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502    \\u2502\\n\\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502\\n\\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n                                    \\u2502\\n                    \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n                    \\u25bc               \\u25bc               \\u25bc\\n\\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n\\u2502    POSTGRESQL LAYER     \\u2502 \\u2502      REDIS LAYER        \\u2502 \\u2502    MONITORING LAYER     \\u2502\\n\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524 \\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524 \\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\\n\\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502 \\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502 \\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502\\n\\u2502  \\u2502   PostgreSQL    \\u2502    \\u2502 \\u2502  \\u2502     Redis       \\u2502    \\u2502 \\u2502  Health Checks   \\u2502    \\u2502\\n\\u2502  \\u2502   Database      \\u2502    \\u2502 \\u2502  \\u2502     Cache       \\u2502    \\u2502 \\u2502  & Monitoring    \\u2502    \\u2502\\n\\u2502  \\u2502   (Port 5432)   \\u2502    \\u2502 \\u2502  \\u2502   (Port 6379)   \\u2502    \\u2502 \\u2502  & Logging       \\u2502    \\u2502\\n\\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502 \\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502 \\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502\\n\\u2502                         \\u2502 \\u2502                         \\u2502 \\u2502                         \\u2502\\n\\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502 \\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502 \\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502\\n\\u2502  \\u2502   User Data     \\u2502    \\u2502 \\u2502  \\u2502   Session Data  \\u2502    \\u2502 \\u2502  Performance     \\u2502    \\u2502\\n\\u2502  \\u2502   & History     \\u2502    \\u2502 \\u2502  \\u2502   & Cache       \\u2502    \\u2502 \\u2502  Metrics         \\u2502    \\u2502\\n\\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502 \\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502 \\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502\\n\\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n```\\n\\n---\\n\\n## \\ud83d\\udd27 **Detailed Component Architecture**\\n\\n### **MCP Server Container Architecture**\\n```\\n\\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n\\u2502                        MCP SERVER CONTAINER                               \\u2502\\n\\u2502                           (Python 3.9)                                    \\u2502\\n\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\\n\\u2502                                                                             \\u2502\\n\\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502\\n\\u2502  \\u2502                        FLASK APPLICATION                           \\u2502    \\u2502\\n\\u2502  \\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2502   Main App      \\u2502  \\u2502   API Routes    \\u2502  \\u2502   Error Handler \\u2502    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2502   (server.py)   \\u2502  \\u2502   & Endpoints   \\u2502  \\u2502   & Middleware  \\u2502    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502    \\u2502\\n\\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502\\n\\u2502                                    \\u2502                                      \\u2502\\n\\u2502                                    \\u25bc                                      \\u2502\\n\\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502\\n\\u2502  \\u2502                      LANGCHAIN INTEGRATION                         \\u2502    \\u2502\\n\\u2502  \\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2502   LLM Models    \\u2502  \\u2502   Tool Registry \\u2502  \\u2502   Agent Manager \\u2502    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2502   & Providers   \\u2502  \\u2502   & Execution   \\u2502  \\u2502   & Coordination\\u2502    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502    \\u2502\\n\\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502\\n\\u2502                                    \\u2502                                      \\u2502\\n\\u2502                                    \\u25bc                                      \\u2502\\n\\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502\\n\\u2502  \\u2502                        DATA ACCESS LAYER                           \\u2502    \\u2502\\n\\u2502  \\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2502   PostgreSQL    \\u2502  \\u2502     Redis       \\u2502  \\u2502   File System   \\u2502    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2502   Connection    \\u2502  \\u2502   Connection    \\u2502  \\u2502   & Logs        \\u2502    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502    \\u2502\\n\\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502\\n\\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n```\\n\\n---\\n\\n## \\ud83c\\udf10 **Network Architecture**\\n\\n### **Docker Network Configuration**\\n```\\n\\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n\\u2502                           DOCKER NETWORK                                  \\u2502\\n\\u2502                           (mcp-network)                                   \\u2502\\n\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\\n\\u2502                                                                             \\u2502\\n\\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502\\n\\u2502  \\u2502                    MCP SERVER CONTAINER                            \\u2502    \\u2502\\n\\u2502  \\u2502  IP: 172.21.0.2                                                    \\u2502    \\u2502\\n\\u2502  \\u2502  Port: 8000 (exposed to host)                                      \\u2502    \\u2502\\n\\u2502  \\u2502  Health Check: http://localhost:8000/health                        \\u2502    \\u2502\\n\\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502\\n\\u2502                                    \\u2502                                      \\u2502\\n\\u2502                                    \\u25bc                                      \\u2502\\n\\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502\\n\\u2502  \\u2502                      REDIS CONTAINER                               \\u2502    \\u2502\\n\\u2502  \\u2502  IP: 172.21.0.3                                                    \\u2502    \\u2502\\n\\u2502  \\u2502  Port: 6379 (exposed to host)                                      \\u2502    \\u2502\\n\\u2502  \\u2502  Health Check: redis-cli ping                                       \\u2502    \\u2502\\n\\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502\\n\\u2502                                    \\u2502                                      \\u2502\\n\\u2502                                    \\u25bc                                      \\u2502\\n\\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502\\n\\u2502  \\u2502                    HOST SYSTEM                                     \\u2502    \\u2502\\n\\u2502  \\u2502  IP: 172.31.5.251 (EC2 Private IP)                                \\u2502    \\u2502\\n\\u2502  \\u2502  Public IP: 3.109.155.48                                          \\u2502    \\u2502\\n\\u2502  \\u2502  PostgreSQL: 127.0.0.1:5432                                       \\u2502    \\u2502\\n\\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502\\n\\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n```\\n\\n---\\n\\n## \\ud83d\\udd12 **Security Architecture**\\n\\n### **Security Group Configuration**\\n```\\n\\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n\\u2502                           SECURITY GROUPS                                 \\u2502\\n\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\\n\\u2502                                                                             \\u2502\\n\\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502\\n\\u2502  \\u2502                    INBOUND RULES                                   \\u2502    \\u2502\\n\\u2502  \\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2502   SSH       \\u2502 \\u2502   HTTP      \\u2502 \\u2502   MCP API   \\u2502 \\u2502   Custom    \\u2502    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2502   Port 22   \\u2502 \\u2502   Port 80   \\u2502 \\u2502   Port 8000 \\u2502 \\u2502   Ports     \\u2502    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2502   (Restricted)\\u2502 \\u2502   (Public)   \\u2502 \\u2502   (Public)   \\u2502 \\u2502   (Internal) \\u2502    \\u2502    \\u2502\\n\\u2502  \\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502    \\u2502\\n\\u2502  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2502\\n\\u2502                                                                             \\u2502\\n\\u2502  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"bot.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\bot.py\",\n    \"content\": \"from langchain_openai import ChatOpenAI\\nfrom langchain.chains import ConversationalRetrievalChain\\nfrom langchain_community.vectorstores import FAISS\\nfrom langchain_openai.embeddings import OpenAIEmbeddings\\nfrom langchain.memory import ConversationBufferMemory\\nfrom langchain.schema import AIMessage, HumanMessage, SystemMessage\\nfrom dotenv import load_dotenv\\nimport os\\n\\n# Load environment variables from .env file\\nload_dotenv()\\n\\n# Set your OpenAI API key\\nos.environ[\\\"OPENAI_API_KEY\\\"] = os.getenv(\\\"OPENAI_API_KEY\\\")\\n\\n# Load both FAISS indexes\\nfaiss_index_path_1 = \\\"tools/output/jira_tickets_stories_faiss_index\\\"\\nfaiss_index_path_2 = \\\"tools/output/codebase_faiss_index\\\"\\nfaiss_index_path_3 = \\\"tools/output/git_history_faiss_index\\\"\\nvectorstore1 = FAISS.load_local(faiss_index_path_1, OpenAIEmbeddings(), allow_dangerous_deserialization=True)\\nvectorstore2 = FAISS.load_local(faiss_index_path_2, OpenAIEmbeddings(), allow_dangerous_deserialization=True)\\nvectorstore3 = FAISS.load_local(faiss_index_path_3, OpenAIEmbeddings(), allow_dangerous_deserialization=True)\\n\\n# Merge the second index into the first\\n    \\nvectorstore1.merge_from(vectorstore2)\\nvectorstore1.merge_from(vectorstore3)\\nvectorstore = vectorstore1\\n\\n# Initialize conversation memory\\nmemory = ConversationBuffe...\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"chat_with_bot\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\bot.py\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"chatbot.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\chatbot.py\",\n    \"content\": \"from llm_provider import LLMProvider\\nimport os\\nimport pathlib\\nimport json\\n\\nfrom langchain_openai import ChatOpenAI\\nfrom langchain.prompts import ChatPromptTemplate\\nfrom chat_context_db import ChatContextDB\\n\\nclass Chatbot:\\n    def __init__(self, model=\\\"gpt-4\\\"):\\n        openai_api_key = os.getenv(\\\"OPENAI_API_KEY\\\")\\n        if not openai_api_key:\\n            # Try to read from settings.json\\n            settings_path = pathlib.Path(__file__).parent / \\\"settings.json\\\"\\n            if settings_path.exists():\\n                with open(settings_path, \\\"r\\\", encoding=\\\"utf-8\\\") as f:\\n                    try:\\n                        settings = json.load(f)\\n                        openai_api_key = settings.get(\\\"OPENAI_API_KEY\\\")\\n                    except Exception:\\n                        openai_api_key = None\\n        if not openai_api_key:\\n            openai_api_key = input(\\\"Enter your OpenAI API key: \\\").strip()\\n        self.llm = ChatOpenAI(model=model, openai_api_key=openai_api_key)\\n        self.prompt = ChatPromptTemplate.from_messages([\\n            (\\\"system\\\", \\\"You are a helpful assistant. Here is the conversation so far: {context}\\\"),\\n            (\\\"user\\\", \\\"{user_message}\\\")\\n        ])\\n        self.chain = self.prompt | self.llm\\n        self.context_db = ChatContextDB()\\n        self.context = self.context_db.load_context()\\n\\n\\n    def _load_context(self):\\n        self.context = self.context_db.load_context()\\n\\n\\n    def _save_context(self):\\n        self.context_db.save_context(self.context)\\n\\n    def add_to_context(self, user_message, bot_response):\\n        self.context.append({\\\"role\\\": \\\"user\\\", \\\"content\\\": user_message})\\n        # Always extract the string content for the assistant's response\\n        content = None\\n        if has...\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"Chatbot\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\chatbot.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"question_answering\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\chatbot.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"__init__\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\chatbot.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"_load_context\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\chatbot.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"_save_context\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\chatbot.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"add_to_context\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\chatbot.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"chat\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\chatbot.py\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"chat_context_db.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\chat_context_db.py\",\n    \"content\": \"import sqlite3\\nimport os\\nimport json\\n\\nDB_PATH = os.path.join(os.path.dirname(__file__), 'chatbot_context.db')\\n\\nclass ChatContextDB:\\n    def __init__(self, db_path=DB_PATH):\\n        self.conn = sqlite3.connect(db_path, check_same_thread=False)\\n        self._create_table()\\n\\n    def _create_table(self):\\n        c = self.conn.cursor()\\n        c.execute('''CREATE TABLE IF NOT EXISTS chat_context (\\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\\n            context_json TEXT\\n        )''')\\n        self.conn.commit...\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"ChatContextDB\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\chat_context_db.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"__init__\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\chat_context_db.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"_create_table\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\chat_context_db.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"load_context\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\chat_context_db.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"save_context\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\chat_context_db.py\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"enhanced_context_manager.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\enhanced_context_manager.py\",\n    \"content\": \"\\\"\\\"\\\"\\nEnhanced Context Manager for Development Assistant\\nHandles large codebases, JIRA data, and git history efficiently\\n\\\"\\\"\\\"\\nimport json\\nimport sqlite3\\nimport hashlib\\nfrom pathlib import Path\\nfrom typing import Dict, List, Any\\nimport os\\n\\nclass DevelopmentContextManager:\\n    def __init__(self, workspace_path: str):\\n        self.workspace_path = Path(workspace_path)\\n        self.db_path = self.workspace_path / \\\"dev_context.db\\\"\\n        self.init_database()\\n        \\n    def init_database(self):\\n        \\\"\\\"\\\"Initialize SQLite database for structured storage\\\"\\\"\\\"\\n        conn = sqlite3.connect(self.db_path)\\n        cursor = conn.cursor()\\n        \\n        # Code patterns table\\n        cursor.execute(\\\"\\\"\\\"\\n            CREATE TABLE IF NOT EXISTS code_patterns (\\n                id INTEGER PRIMARY KEY,\\n                file_path TEXT,\\n                language TEXT,\\n                pattern_type TEXT,  -- class, function, variable, etc.\\n                code_snippet TEXT,\\n                metadata TEXT,  -- JSON string\\n                hash TEXT UNIQUE\\n            )\\n        \\\"\\\"\\\")\\n        \\n        # JIRA tickets table\\n        cursor.execute(\\\"\\\"\\\"\\n            CREATE TABLE IF NOT EXISTS jira_tickets (\\n                id INTEGER PRIMARY KEY,\\n                ticket_id TEXT UNIQUE,\\n                title TEXT,\\n                description TEXT,\\n                status TEXT,\\n                assignee TEXT,\\n                created_date TEXT,\\n                resolved_date TEXT,\\n                metadata TEXT\\n            )\\n        \\\"\\\"\\\")\\n        \\n        # Git commits table\\n        cursor.execute(\\\"\\\"\\\"\\n            CREATE TABLE IF NOT EXISTS git_commits (\\n                id INTEGER PRIMARY KEY,\\n                commit_hash TEXT UNIQUE,\\n                author TEXT,\\n                date TEXT,\\n                message TEXT,\\n                files_changed TEXT,  -- JSON array\\n                diff_summary TEXT\\n            )\\n        \\\"\\\"\\\")\\n        \\n        conn.commit()\\n        conn.close()\\n    \\n    def store_code_pattern(self, file_path: str, language: str, \\n                          pattern_type: str, code_snippet: str, \\n                          metadata: Dict[str, Any]):\\n        \\\"\\\"\\\"Store code patterns with deduplication\\\"\\\"\\\"\\n        code_hash = hashlib.md5(code_snippet.encode()).hexdigest()\\n        \\n        conn = sqlite3.connect(self.db_path)\\n        cursor = conn.cursor()\\n        \\n        try:\\n            cursor.execute(\\\"\\\"\\\"\\n                INSERT OR REPLACE INTO code_patterns \\n                (file_path, language, pattern_type, code_snippet, metadata, hash)\\n                VALUES (?, ?, ?, ?, ?, ?)\\n            \\\"\\\"\\\", (file_path, language, pattern_type, code_snippet, \\n                  json.dumps(metadata), code_hash))\\n            conn.commit()\\n        except sqlite3.Error as e:\\n            print(f\\\"Error storing code pattern: {e}\\\")\\n        finally:\\n            conn.close()\\n    \\n    def query_similar_patterns(self, query_type: str, language: str = None, \\n                              limit: int = 10) -> List[Dict]:\\n        \\\"\\\"\\\"Query similar code patterns\\\"\\\"\\\"\\n        conn = sqlite3.connect(self.db_path)\\n        cursor = conn.cursor()\\n        \\n        sql = \\\"\\\"\\\"\\n            SELECT file_path, code_snippet, metadata \\n            FROM code_patterns \\n            WHERE pattern_type = ?\\n        \\\"\\\"\\\"\\n        params = [query_type]\\n        \\n        if language:\\n            sql += \\\" AND language = ?\\\"\\n            params.append(language)\\n            \\n        sql += f\\\" LIMIT {limit}\\\"\\n        \\n        cursor.execute(sql, params)\\n        results = cursor.fetchall()\\n        conn.close()\\n        \\n        return [{\\\"file_path\\\": r[0], \\\"code\\\": r[1], \\\"metadata\\\": json.loads(r[2])} \\n                for r in results]\\n    \\n    def get_folder_structure_examples(self, language: str) -> Dict[str, List[str]]:\\n        \\\"\\\"\\\"Get common folder structures for a language\\\"\\\"\\\"\\n        conn = sqlite3.connect(self.db_path)\\n        cursor = conn.cursor()\\n        \\n        cursor.execute(\\\"\\\"\\\"\\n            SELECT DISTINCT file_path FROM code_patterns \\n            WHERE language = ?\\n        \\\"\\\"\\\", (language,))\\n        \\n        file_paths = [row[0] for row in cursor.fetchall()]\\n        conn.close()\\n        \\n        # Analyze folder patterns\\n        folders = {}\\n        for path in file_paths:\\n            parts = Path(path).parts\\n            if len(parts) > 1:\\n                folder = parts[-2]  # Parent folder\\n                if folder not in folders:\\n                    folders[folder] = []\\n                folders[folder].append(Path(path).name)\\n        \\n        return folders\\n    \\n    def get_naming_conventions(self, language: str, pattern_type: str) -> List[str]:\\n        \\\"\\\"\\\"Extract naming conventions from existing code\\\"\\\"\\\"\\n        patterns = self.query_similar_patterns(pattern_type, language)\\n        names = []\\n        \\n        for pat...\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"DevelopmentContextManager\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\enhanced_context_manager.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_context_manager\",\n    \"doc\": \"Get or create global context manager instance\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\enhanced_context_manager.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"scan_codebase\",\n    \"doc\": \"Tool to scan and analyze codebase patterns\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\enhanced_context_manager.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"analyze_jira_history\",\n    \"doc\": \"Tool to analyze JIRA ticket patterns\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\enhanced_context_manager.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"check_git_conventions\",\n    \"doc\": \"Tool to check git commit conventions\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\enhanced_context_manager.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"__init__\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\enhanced_context_manager.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"init_database\",\n    \"doc\": \"Initialize SQLite database for structured storage\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\enhanced_context_manager.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"store_code_pattern\",\n    \"doc\": \"Store code patterns with deduplication\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\enhanced_context_manager.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"query_similar_patterns\",\n    \"doc\": \"Query similar code patterns\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\enhanced_context_manager.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_folder_structure_examples\",\n    \"doc\": \"Get common folder structures for a language\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\enhanced_context_manager.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_naming_conventions\",\n    \"doc\": \"Extract naming conventions from existing code\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\enhanced_context_manager.py\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"llm_provider.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\llm_provider.py\",\n    \"content\": \"import os\\nimport json\\nimport pathlib\\n\\nclass LLMProvider:\\n    def __init__(self, provider=\\\"openai\\\"):\\n        self.provider = provider\\n        self.api_key = self._get_api_key()\\n\\n        if provider == \\\"openai\\\":\\n            import openai\\n            self.client = openai.OpenAI(api_key=self.api_key)\\n        elif provider == \\\"mistral\\\":\\n            from mistralai.client import MistralClient\\n            self.client = MistralClient(api_key=self.api_key)\\n        else:\\n            raise ValueError(\\\"Unsupported provider\\\")\\n\\n    def _get_api_key(self):\\n        env_key = os.environ.get(\\\"OPENAI_API_KEY\\\") if self.provider == \\\"openai\\\" else os.environ.get(\\\"MISTRAL_API_KEY\\\")\\n        if env_key:\\n            return env_key\\n        root = pathlib.Path(__file__).parent\\n        settings_path = root / \\\"settings.json\\\"\\n        if settings_path.exists():\\n            with open(settings_path, \\\"r\\\", encoding=\\\"utf-8\\\") as s:\\n                cfg = json.load(s)\\n                key_name = \\\"OPENAI_API_KEY\\\" if self.provider == \\\"openai\\\" else \\\"MISTRAL_API_KEY\\\"\\n                return cfg.get(key_name)\\n        raise RuntimeError(f\\\"{self.provider} API key not found.\\\")\\n\\n    def chat_completion(self, messages, model=\\\"gpt-4o\\\", temperature=0.2, max_tokens=2000, functions=None, function_call=None):\\n        if self.provider == \\\"openai\\\":\\n            kwargs = {\\n                \\\"model\\\": model,\\n                \\\"messages\\\": messages,\\n                \\\"temperature\\\": temperature,\\n      ...\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"LLMProvider\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\llm_provider.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"__init__\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\llm_provider.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"_get_api_key\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\llm_provider.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"chat_completion\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\llm_provider.py\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"LOCAL_ACCESS_GUIDE.md\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\LOCAL_ACCESS_GUIDE.md\",\n    \"content\": \"# Local Access Guide\\n\\n## API Keys and Sensitive Files\\n\\n- Your `settings.json` file contains sensitive information such as your OpenAI API key.\\n- This file is now included in `.gitignore` and will **not** be tracked by git. It will always remain in your local workspace.\\n- Do **not** share or commit `settings.json` to any public or shared repository.\\n\\n## How to Use\\n\\n1. **Keep your `settings.json` file in the project root.**\\n2. **Update your API key or m...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"multi-agent.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\multi-agent.py\",\n    \"content\": \"\\\"\\\"\\\"\\nMulti-agent workflow using OpenAI Agentic SDK for autonomous tool selection and chaining.\\nParses user prompt, selects tools from tools.json, and executes multi-step workflows.\\nEnhanced with approval handling, context persistence, and intelligent data passing.\\n\\\"\\\"\\\"\\nimport json\\nimport pathlib\\nimport importlib\\nimport sys\\nimport os\\n\\nfrom langchain_openai import OpenAI\\nsys.path.append(os.path.join(os.path.dirname(__file__), 'tools'))\\n\\nfrom llm_provider import LLMProvider\\nfrom langchain.agents import Tool, AgentExecutor, create_openai_functions_agent\\nfrom langchain.prompts import ChatPromptTemplate\\nfrom langchain.memory import ConversationBufferMemory\\n\\nsys.path.append(str(pathlib.Path(__file__).parent))\\nTOOLS_PATH = pathlib.Path(__file__).parent / \\\"tools.json\\\"\\nCONTEXT_PATH = pathlib.Path(__file__).parent / \\\"output\\\" / \\\"workflow_context.json\\\"\\n\\n# Load tool definitions\\nwith open(TOOLS_PATH, \\\"r\\\", encoding=\\\"utf-8\\\") as f:\\n    tools_config = json.load(f)\\n\\n# Build OpenAI function definitions from tools.json\\nopenai_functions = []\\nfor tool in tools_config:\\n    openai_functions.append({\\n        \\\"name\\\": tool[\\\"name\\\"],\\n        \\\"description\\\": tool[\\\"description\\\"],\\n        \\\"parameters\\\": tool[\\\"args_schema\\\"]\\n    })\\n\\n# Initialize tool_map with tools from tools.json\\ntool_map = {}\\nfor tool in tools_config:\\n    module_path = tool.get(\\\"module\\\")\\n    func_name = tool[\\\"name\\\"]\\n    \\n    # Handle modules in main folder vs tools folder\\n    if module_path.startswith(\\\"tools.\\\"):\\n        import_path = module_path\\n    else:\\n        # For modules in main folder like chatbot\\n        import_path = module_path\\n    \\n    mod = importlib.import_module(import_path)\\n    tool_map[func_name] = getattr(mod, func_name)\\n\\n# Initialize tools\\nfrom langchain.agents import Tool, AgentExecutor\\nfrom tools.development.jira_tools import jira_ticket_summarizer\\n\\ntools = [\\n    Tool(\\n        name=\\\"jira_ticket_summarizer\\\",\\n        func=jira_ticket_summarizer,\\n        description=\\\"Fetch JIRA tickets, summarize them into a PRD, and save the context in JSON format.\\\"\\n    )\\n]\\n\\n# Initialize memory\\nmemory = ConversationBufferMemory()\\n\\n# Initialize LLM\\nopenai_api_key = os.getenv(\\\"OPENAI_API_KEY\\\")\\nif not openai_api_key:\\n    # Try to read from settings.json\\n    settings_path = pathlib.Path(__file__).parent / \\\"settings.json\\\"\\n    if settings_path.exists():\\n        with open(settings_path, \\\"r\\\", encoding=\\\"utf-8\\\") as f:\\n            try:\\n                settings = json.load(f)\\n                openai_api_key = settings.get(\\\"OPENAI_API_KEY\\\")\\n            except Exception:\\n                openai_api_key = None\\n    if not openai_api_key:\\n        openai_api_key = input(\\\"Enter your OpenAI API key: \\\").strip()\\nllm = OpenAI(model=\\\"gpt-4\\\", openai_api_key=openai_api_key)\\n\\n# Create a prompt for the agent\\nprompt = ChatPromptTemplate.from_messages([\\n    (\\\"system\\\", \\\"You are a helpful multi-agent assistant. Use tools as needed to solve the user's request. {agent_scratchpad}\\\"),\\n    (\\\"user\\\", \\\"{input}\\\")\\n])\\nagent = create_openai_functions_agent(llm, tools, prompt)\\nagent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory)\\n\\n# Helper: Save workflow context\\ndef save_context(context):\\n    CONTEXT_PATH.parent.mkdir(exist_ok=True)\\n    with open(CONTEXT_PATH, \\\"w\\\", encoding=\\\"utf-8\\\") as f:\\n        json.dump(context, f, indent=2)\\n\\n# Helper: Load workflow context\\ndef load_context():\\n    if CONTEXT_PATH.exists():\\n        with open(CONTEXT_PATH, \\\"r\\\", encoding=\\\"utf-8\\\") as f:\\n            return json.load(f)\\n    return {\\\"execution_history\\\": [], \\\"data_context\\\": {}}\\n\\n# Helper: Dynamically import and call a tool\\ndef call_tool(tool_name, args):\\n    tool = next((t for t in tools_config if t[\\\"name\\\"] ==...\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"save_context\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\multi-agent.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"load_context\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\multi-agent.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"call_tool\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\multi-agent.py\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"MultiAgent\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\multi-agent.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"run_agent\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\multi-agent.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"__init__\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\multi-agent.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"run\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\multi-agent.py\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"PRESENTATION_ARCHITECTURE.md\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\PRESENTATION_ARCHITECTURE.md\",\n    \"content\": \"# MCP Server Infrastructure Deployment\\n## DevOps Engineer Presentation\\n\\n---\\n\\n## \\ud83c\\udfaf **Project Overview**\\n\\n### **What is MCP (Model Context Protocol)?**\\n- **MCP** is a protocol that enables AI assistants to connect to external data sources and tools\\n- Provides **real-time access** to databases, APIs, and external services\\n- Enables **context-aware** AI responses with live data integration\\n\\n### **Our Implementation**\\n- **Multi-Agent AI System** with PostgreSQL and Redis backend\\n- **Dockerized microservices** architecture\\n- **AWS EC2** deployment with automated infrastructure\\n- **Health monitoring** and automated scaling capabilities\\n\\n---\\n\\n## \\ud83c\\udfd7\\ufe0f **System Architecture**\\n\\n### **High-Level Architecture**\\n```\\n\\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n\\u2502   Client Apps   \\u2502    \\u2502   Load Balancer \\u2502    \\u2502   MCP Server    \\u2502\\n\\u2502   (Web/Mobile)  \\u2502\\u25c4\\u2500\\u2500\\u25ba\\u2502   (Future)      \\u2502\\u25c4\\u2500\\u2500\\u25ba\\u2502   (Port 8000)   \\u2502\\n\\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n                                                        \\u2502\\n                       \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n                       \\u2502   PostgreSQL    \\u2502    \\u2502     Redis       \\u2502\\n                       \\u2502   (Port 5432)   \\u2502    \\u2502   (Port 6379)   \\u2502\\n                       \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n```\\n\\n### **Component Details**\\n\\n#### **1. MCP Server (Flask Application)**\\n- **Technology**: Python Flask + LangChain\\n- **Port**: 8000\\n- **Features**:\\n  - RESTful API endpoints\\n  - AI model integration\\n  - Tool registry and management\\n  - Multi-agent coordination\\n\\n#### **2. PostgreSQL Database**\\n- **Version**: 12.20\\n- **Port**: 5432\\n- **Purpose**: \\n  - Persistent data storage\\n  - User session management\\n  - Conversation history\\n  - Tool configurations\\n\\n#### **3. Redis Cache**\\n- **Version**: 7-alpine\\n- **Port**: 6379\\n- **Purpose**:\\n  - Session caching\\n  - Real-time data storage\\n  - Performance optimization\\n  - Temporary context storage\\n\\n---\\n\\n## \\ud83d\\ude80 **Deployment Workflow**\\n\\n### **Phase 1: Infrastructure Setup**\\n```bash\\n# 1. EC2 Instance Creation\\naws ec2 run-instances \\\\\\n  --image-id ami-0c02fb55956c7d316 \\\\\\n  --instance-type t3.medium \\\\\\n  --key-name Minds-Constructing-Products-key \\\\\\n  --security-group-ids sg-xxxxxxxxx\\n\\n# 2. Security Group Configuration\\n- SSH (Port 22)\\n- HTTP (Port 80)\\n- HTTPS (Port 443)\\n- Custom TCP (Port 8000) - MCP Server\\n- Custom TCP (Port 5432) - PostgreSQL\\n- Custom TCP (Port 6379) - Redis\\n```\\n\\n### **Phase 2: Application Deployment**\\n```bash\\n# 1. System Updates\\nsudo yum update -y\\n\\n# 2. Docker Installation\\nsudo yum install -y docker\\nsudo systemctl start docker\\nsudo systemctl enable docker\\n\\n# 3. Docker Compose Installation\\nsudo curl -L \\\"https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)\\\" -o /usr/local/bin/docker-compose\\nsudo chmod +x /usr/local/bin/docker-compose\\n\\n# 4. PostgreSQL Setup\\nsudo yum install -y postgresql postgresql-server postgresql-contrib\\nsudo /usr/bin/postgresql-setup initdb\\nsudo systemctl enable postgresql\\nsudo systemctl start postgresql\\n\\n# 5. Database Configuration\\nsudo -u postgres psql -c \\\"CREATE USER mcp_admin WITH PASSWORD 'mcp_password_123';\\\"\\nsudo -u postgres psql -c \\\"CREATE DATABASE mcp_assistant OWNER mcp_admin;\\\"\\nsudo -u postgres psql -c \\\"GRANT ALL PRIVILEGES ON DATABASE mcp_assistant TO mcp_admin;\\\"\\n```\\n\\n### **Phase 3: Application Containerization**\\n```bash\\n# 1. Application Setup\\ncd /opt/mcp-server\\ngit clone <repository>\\ncd MCP-hackathon\\n\\n# 2. Docker Configuration\\ncat > Dockerfile << 'EOF'\\nFROM python:3.9-slim\\nWORKDIR /app\\nCOPY requirements.txt .\\nRUN pip install --no-cache-dir -r requirements.txt\\nCOPY . .\\nEXPOSE 8000\\nCMD [\\\"python\\\", \\\"server.py\\\"]\\nEOF\\n\\n# 3. Docker Compose Configuration\\ncat > docker-compose.yml << 'EOF'\\nversion: '3.8'\\nservices:\\n  mcp-server:\\n    build: .\\n    ports:\\n      - \\\"8000:8000\\\"\\n    environment:\\n      - DATABASE_URL=postgresql://mcp_admin:mcp_password_123@host.docker.internal:5432/mcp_assistant\\n      - REDIS_URL=redis://redis:6379\\n    depends_on:\\n      - redis\\n    networks:\\n      - mcp-network\\n    healthcheck:\\n      test: [\\\"CMD\\\", \\\"curl\\\", \\\"-f\\\", \\\"http://localhost:8000/health\\\"]\\n      interval: 30s\\n      timeout: 10s\\n      retries: 3\\n\\n  redis:\\n    image: redis:7-alpine\\n    ports:\\n      - \\\"6379:6379\\\"\\n    volumes:\\n      - redis_data:/data\\n    networks:\\n      - mcp-network\\n    healthcheck:\\n      test: [\\\"CMD\\\", \\\"redis-cli\\\", \\\"ping\\\"]\\n      interval: 30s\\n      timeout: 10s\\n      retries: 3\\n\\nvolumes:\\n  redis_data:\\n\\nnetworks:\\n  mcp-network:\\n    driver: bridge\\nEOF\\n\\n# 4. Application Deployment\\ndocker-compose up -d --build\\n```\\n\\n---\\n\\n## \\ud83d\\udd27 **Technical Implementation**\\n\\n### **Key Technologies Used**\\n\\n#### **Backend Stack**\\n- **Python 3.9**: Core application language\\n- **Flask**: Web framework for REST API\\n- **LangChain**: AI/LLM integration framework\\n- **PostgreSQL**: Primary database\\n- **Redis**: Caching and session management\\n\\n#### **Infrastructure Stack**\\n- **AWS EC2**: Cloud compute instance\\n- **Docker**: Containerization platform\\n- **Docker Compose**: Multi-container orchestration\\n- **Terraform**: Infrastructure as Code (optional)\\n\\n#### **Monitoring & Health Checks**\\n- **Docker Health Checks**: Container health monitoring\\n- **Flask Health Endpoints**: Application status monitoring\\n- **Systemd Services**: System-level service management\\n\\n### **Security Implementation**\\n\\n#### **Network Security**\\n```bash\\n# Security Group Rules\\n- SSH (22): Restricted to specific IPs\\n- HTTP (80): Public access for web interface\\n- Custom TCP (8000): MCP Server API...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"PRESENTATION_SLIDES.md\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\PRESENTATION_SLIDES.md\",\n    \"content\": \"# MCP Server Infrastructure Deployment\\n## DevOps Engineer Presentation Slides\\n\\n---\\n\\n## Slide 1: Title Slide\\n# \\ud83d\\ude80 MCP Server Infrastructure Deployment\\n### **Model Context Protocol Implementation**\\n**Presented by: DevOps Engineering Team**  \\n**Date: August 2025**\\n\\n---\\n\\n## Slide 2: Executive Summary\\n# \\ud83d\\udcca **Project Overview**\\n\\n### **What We Built**\\n- **Multi-Agent AI System** with real-time data integration\\n- **Dockerized microservices** architecture on AWS\\n- **Production-ready** infrastructure with monitoring\\n\\n### **Key Metrics**\\n- \\u2705 **100% Uptime** since deployment\\n- \\u2705 **< 100ms** response time\\n- \\u2705 **99.9%** system reliability\\n- \\u2705 **Zero** security incidents\\n\\n---\\n\\n## Slide 3: What is MCP?\\n# \\ud83e\\udd16 **Model Context Protocol (MCP)**\\n\\n### **Definition**\\nMCP enables AI assistants to connect to external data sources and tools in real-time\\n\\n### **Benefits**\\n- **Real-time Data Access**: Live database connections\\n- **Context-Aware Responses**: AI with current information\\n- **Tool Integration**: External API and service connections\\n- **Scalable Architecture**: Microservices design\\n\\n### **Use Cases**\\n- Customer support automation\\n- Data analysis and reporting\\n- Real-time decision making\\n- Multi-source information synthesis\\n\\n---\\n\\n## Slide 4: System Architecture\\n# \\ud83c\\udfd7\\ufe0f **Technical Architecture**\\n\\n```\\n\\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n\\u2502   Client Apps   \\u2502    \\u2502   Load Balancer \\u2502    \\u2502   MCP Server    \\u2502\\n\\u2502   (Web/Mobile)  \\u2502\\u25c4\\u2500\\u2500\\u25ba\\u2502   (Future)      \\u2502\\u25c4\\u2500\\u2500\\u25ba\\u2502   (Port 8000)   \\u2502\\n\\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n                                                        \\u2502\\n                       \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510    \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n                       \\u2502   PostgreSQL    \\u2502    \\u2502     Redis       \\u2502\\n                       \\u2502   (Port 5432)   \\u2502    \\u2502   (Port 6379)   \\u2502\\n                       \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518    \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n```\\n\\n### **Components**\\n- **MCP Server**: Python Flask + LangChain\\n- **PostgreSQL**: Persistent data storage\\n- **Redis**: Caching and session management\\n- **Docker**: Containerization platform\\n\\n---\\n\\n## Slide 5: Technology Stack\\n# \\ud83d\\udee0\\ufe0f **Technology Stack**\\n\\n### **Backend Technologies**\\n- **Python 3.9**: Core application language\\n- **Flask**: Web framework for REST API\\n- **LangChain**: AI/LLM integration framework\\n- **PostgreSQL 12.20**: Primary database\\n- **Redis 7**: Caching and session management\\n\\n### **Infrastructure Technologies**\\n- **AWS EC2**: Cloud compute instance (t3.medium)\\n- **Docker**: Containerization platform\\n- **Docker Compose**: Multi-container orchestration\\n- **Terraform**: Infrastructure as Code\\n\\n### **Monitoring & Security**\\n- **Health Checks**: Automated monitoring\\n- **Security Groups**: Network-level security\\n- **Container Security**: Non-root execution\\n\\n---\\n\\n## Slide 6: Deployment Workflow\\n# \\ud83d\\udd04 **Deployment Process**\\n\\n### **Phase 1: Infrastructure Setup**\\n1. **EC2 Instance Creation** (t3.medium)\\n2. **Security Group Configuration**\\n3. **Docker Installation & Configuration**\\n\\n### **Phase 2: Application Deployment**\\n1. **PostgreSQL Setup & Configuration**\\n2. **Redis Installation & Configuration**\\n3. **Application Containerization**\\n\\n### **Phase 3: Production Deployment**\\n1. **Docker Compose Deployment**\\n2. **Health Check Validation**\\n3. **Performance Testing**\\n\\n---\\n\\n## Slide 7: Security Implementation\\n# \\ud83d\\udd12 **Security Architecture**\\n\\n### **Network Security**\\n- **SSH (Port 22)**: Restricted access\\n- **HTTP (Port 80)**: Public web interface\\n- **Custom TCP (Port 8000)**: MCP Server API\\n- **Custom TCP (Port 5432)**: PostgreSQL (internal)\\n- **Custom TCP (Port 6379)**: Redis (internal)\\n\\n### **Application Security**\\n- **Database Authentication**: Encrypted connections\\n- **API Authentication**: JWT token-based access\\n- **Container Security**: Non-root user execution\\n- **Network Isolation**: Docker bridge networks\\n\\n### **Compliance**\\n- **Data Encryption**: In-transit and at-rest\\n- **Access Control**: Role-based permissions\\n- **Audit Logging**: Comprehensive activity tracking\\n\\n---\\n\\n## Slide 8: Performance Metrics\\n# \\ud83d\\udcc8 **Performance & Monitoring**\\n\\n### **Current Performance**\\n- **Response Time**: < 100ms for health checks\\n- **Uptime**: 99.9% since deployment\\n- **CPU Usage**: 15% average\\n- **Memory Usage**: 45% average\\n- **Disk Usage**: 30% of allocated space\\n\\n### **Health Monitoring**\\n```json\\n{\\n  \\\"status\\\": \\\"healthy\\\",\\n  \\\"service\\\": \\\"mcp-server\\\",\\n  \\\"postgresql\\\": \\\"connected\\\",\\n  \\\"redis\\\": \\\"connected\\\",\\n  \\\"timestamp\\\": \\\"2025-08-02T13:55:00Z\\\"\\n}\\n```\\n\\n### **Monitoring Tools**\\n- **Docker Health Checks**: Container monitoring\\n- **Flask Health Endpoints**: Application status\\n- **Systemd Services**: System-level monitoring\\n\\n---\\n\\n## Slide 9: Deployment Status\\n# \\u2705 **Current Deployment Status**\\n\\n### **Infrastructure Status**\\n- \\u2705 **EC2 Instance**: Running (t3.medium)\\n- \\u2705 **Security Groups**: Configured and secured\\n- \\u2705 **Docker**: Installed and operational\\n- \\u2705 **PostgreSQL**: Running and configured\\n- \\u2705 **Redis**: Running and healthy\\n- \\u2705 **MCP Server**: Deployed and responding\\n\\n### **Application Status**\\n- \\u2705 **Health Endpoint**: `http://3.109.155.48:8000/health`\\n- \\u2705 **Main API**: `http://3.109.155.48:8000/`\\n- \\u2705 **Database**: Connected and operational\\n- \\u2705 **Cache**: Connected and operational\\n\\n### **Container Status**\\n- \\u2705 **mcp-server**: Healthy and running\\n- \\u2705 **redis**: Healthy and running\\n- \\u2705 **All containers**: Operational\\n\\n---\\n\\n## Slide 10: Benefits & ROI\\n# \\ud83d\\udcb0 **Business Benefits**\\n\\n### **Operational Benefits**\\n- **Reduced Response Time**: Real-time data access\\n- **Improved Accuracy**: Context-aware AI responses\\n- **Scalability**: Easy horizontal scaling\\n- **Reliability**: 99.9% uptime guarantee\\n\\n### **Cost Benefits**\\n- **Infrastructure Cost**: $50/month (t3.medium)\\n- **Development Time**: 40% faster with containerization\\n- **Maintenance Cost**: 60% reduction with automation\\n- **Deployment Time**: 90% faster with Docker\\n\\n### **Technical Benefits**\\n- **Microservices Architecture**: Independent scaling\\n- **Container Orchestration**: Easy management\\n- **Health Monitoring**: Proactive issue detection\\n- **Security**: Enterprise-grade pro...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"README.md\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\README.md\",\n    \"content\": \"# MCP Server (LangChain Edition)\\n\\nThis project is a Multi-Agent Control Plane (MCP) server using [LangChain](https://github.com/langchain-ai/langchain), [FastAPI](https://fastapi.tiangolo.com/), and dynamic tool orchestration.\\n\\n## Features\\n- **LangChain Tool Integration**: All tools are defined as LangChain-compatible Python functions and loaded dynamically from `tools.json`.\\n- **REST API**: Exposes `/tools` (list tools) and `/tools/execute` (run a tool) endpoints.\\n- **SQLite Logging**: Tool executions and errors are logged to SQLite.\\n- **Agentic Workflows**: Ready for multi-agent and LLM-based orchestration.\\n\\n## Quickstart\\n1. **Install dependencies**\\n   ```sh\\n   pip install -r requirements.txt\\n   ```\\n2. **Run the server**\\n   ```sh\\n   python -m uvicorn mcp_server.server:app --reload --port 8000\\n   ```\\n3. **List available tools**\\n   ```sh\\n   curl ...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"README_PRESENTATION.md\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\README_PRESENTATION.md\",\n    \"content\": \"# MCP Server Deployment Presentation Package\\n## DevOps Engineer Guide\\n\\nThis package contains comprehensive presentation materials for showcasing the MCP (Model Context Protocol) server infrastructure deployment to stakeholders.\\n\\n---\\n\\n## \\ud83d\\udcc1 **Presentation Package Contents**\\n\\n### **Core Documents**\\n1. **`PRESENTATION_ARCHITECTURE.md`** - Comprehensive technical documentation\\n2. **`PRESENTATION_SLIDES.md`** - PowerPoint-style presentation slides\\n3. **`ARCHITECTURE_DIAGRAM.md`** - Detailed architecture diagrams and technical specifications\\n4. **`README_PRESENTATION.md`** - This guide for presenters\\n\\n### **Additional Resources**\\n- **Working Infrastructure**: Live deployment at `http://3.109.155.48:8000`\\n- **Health Endpoint**: `http://3.109.155.48:8000/health`\\n- **API Documentation**: Available in the main project README\\n\\n---\\n\\n## \\ud83c\\udfaf **Presentation Objectives**\\n\\n### **Primary Goals**\\n- Demonstrate successful infrastructure deployment\\n- Showcase technical architecture and capabilities\\n- Highlight business value and ROI\\n- Secure stakeholder approval for production use\\n\\n### **Key Messages**\\n1. **Technical Excellence**: Enterprise-grade infrastructure with 99.9% uptime\\n2. **Business Value**: 40% cost reduction, 90% faster deployments\\n3. **Security**: Comprehensive security implementation\\n4. **Scalability**: Future-ready architecture for growth\\n\\n---\\n\\n## \\ud83d\\udcca **Current Deployment Status**\\n\\n### **\\u2705 Infrastructure Status**\\n- **EC2 Instance**: Running (t3.medium) - $37/month\\n- **MCP Server**: Healthy on port 8000\\n- **PostgreSQL**: Connected and operational on port 5432\\n- **Redis**: Healthy and operational on port 6379\\n- **Docker Containers**: All containers healthy\\n\\n### **\\u2705 Performance Metrics**\\n- **Response Time**: < 100ms for health checks\\n- **Uptime**: 99.9% since deployment\\n- **Error Rate**: < 0.1%\\n- **Security Incidents**: 0\\n\\n### **\\u2705 Health Check Response**\\n```json\\n{\\n  \\\"status\\\": \\\"healthy\\\",\\n  \\\"service\\\": \\\"mcp-server\\\",\\n  \\\"postgresql\\\": \\\"connected\\\",\\n  \\\"redis\\\": \\\"connected\\\",\\n  \\\"timestamp\\\": \\\"2025-08-02T13:55:00Z\\\"\\n}\\n```\\n\\n---\\n\\n## \\ud83c\\udfa4 **Presentation Guidelines**\\n\\n### **Before the Presentation**\\n1. **Test the Live Demo**\\n   ```bash\\n   # Test health endpoint\\n   curl -f http://3.109.155.48:8000/health\\n   \\n   # Test main endpoint\\n   curl http://3.109.155.48:8000/\\n   ```\\n\\n2. **Prepare Your Environment**\\n   - Have all presentation files ready\\n   - Test screen sharing and video conferencing tools\\n   - Prepare backup slides in case of technical issues\\n\\n3. **Know Your Audience**\\n   - **Technical Stakeholders**: Focus on architecture and performance\\n   - **Business Stakeholders**: Emphasize ROI and business value\\n   - **Security Stakeholders**: Highlight security implementation\\n\\n### **During the Presentation**\\n\\n#### **Opening (5 minutes)**\\n- Introduce the project and team\\n- Explain what MCP is and why it's important\\n- Show the current deployment status\\n\\n#### **Technical Deep Dive (15 minutes)**\\n- Walk through the architecture diagrams\\n- Explain the technology stack\\n- Demonstrate the deployment process\\n- Show live health checks\\n\\n#### **Business Value (10 minutes)**\\n- Present cost analysis and ROI\\n- Discuss performance metrics\\n- Highlight scalability benefits\\n- Address risk mitigation\\n\\n#### **Future Roadmap (5 minutes)**\\n- Outline Phase 2 and 3 plans\\n- Discuss enhancement opportunities\\n- Present timeline and milestones\\n\\n#### **Q&A Session (10 minutes)**\\n- Address technical questions\\n- Discuss business concerns\\n- Handle security inquiries\\n- Provide next steps\\n\\n### **Presentation Tips**\\n1. **Start with the Big Picture**: Explain MCP and its business value\\n2. **Show Live Demos**: Demonstrate working endpoints\\n3. **Use Visual Aids**: Reference architecture diagrams\\n4. **Address Concerns**: Be prepared for security and cost questions\\n5. **End with Action Items**: Clear next steps and timeline\\n\\n---\\n\\n## \\ud83d\\udd27 **Technical Demo Script**\\n\\n### **Demo 1: Health Check**\\n```bash\\n# Show the audience the health endpoint\\ncurl -f http://3.109.155.48:8000/health\\n\\n# Expected response:\\n{\\n  \\\"status\\\": \\\"healthy\\\",\\n  \\\"service\\\": \\\"mcp-server\\\",\\n  \\\"postgresql\\\": \\\"connected\\\",\\n  \\\"redis\\\": \\\"connected\\\",\\n  \\\"timestamp\\\": \\\"2025-08-02T13:55:00Z\\\"\\n}\\n```\\n\\n### **Demo 2: Main API**\\n```bash\\n# Show the main API endpoint\\ncurl http://3.109.155.48:8000/\\n\\n# Expected response:\\n{\\n  \\\"endpoints\\\": {\\n    \\\"health\\\": \\\"/health\\\",\\n    \\\"home\\\": \\\"/\\\"\\n  },\\n  \\\"message\\\": \\\"MCP Server is running!\\\",\\n  \\\"version\\\": \\\"1.0.0\\\"\\n}\\n```\\n\\n### **Demo 3: Container Status**\\n```bash\\n# Show Docker container status\\ndocker ps\\n\\n# Expected output:\\n# CONTAINER ID   IMAGE                   COMMAND                  STATUS\\n# 73be2f914793   mcp-server-mcp-server   \\\"python server.py\\\"       Up 5 minutes (healthy)\\n# 1cd356f3b970   redis:7-alpine        ...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"requirements.txt\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\requirements.txt\",\n    \"content\": \"fastapi\\nuvicorn\\nstreamlit\\nlangchain>=0.1.47\\nlangchain-openai\\nopenai\\nrequests\\nbeautifu...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"streamlit_app.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\",\n    \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\nProfessional MCP Tools Suite\\nEnterprise-grade tool execution and management platform\\n\\\"\\\"\\\"\\n\\nimport streamlit as st\\nimport json\\nimport os\\nimport sys\\nimport importlib\\nimport traceback\\nfrom datetime import datetime, timedelta\\nfrom typing import List, Dict, Any\\nimport uuid\\nimport hashlib\\n\\n# Add tools directory to Python path\\nsys.path.append('tools')\\nsys.path.append(os.path.join(os.path.dirname(__file__), 'tools'))\\n\\n# Try to import chatbot components with graceful fallback\\ntry:\\n    from chatbot import Chatbot, question_answering\\n    CHATBOT_AVAILABLE = True\\nexcept ImportError as e:\\n    CHATBOT_AVAILABLE = False\\n    IMPORT_ERROR = str(e)\\n\\n# Try to import bot.py for chat functionality\\ntry:\\n    from bot import chat_with_bot\\n    BOT_AVAILABLE = True\\nexcept ImportError as e:\\n    BOT_AVAILABLE = False\\n    BOT_IMPORT_ERROR = str(e)\\n    \\n    # Fallback function\\n    def chat_with_bot(user_input):\\n        return \\\"Bot is not available. Please ensure bot.py is properly configured with OpenAI API key and FAISS index.\\\"\\n    \\n    # Fallback classes for demo mode\\n    class Chatbot:\\n        def __init__(self, **kwargs):\\n            pass\\n        def chat(self, message):\\n            return \\\"System in demo mode. Install dependencies for full functionality: pip install langchain-openai langchain\\\"\\n    \\n    def question_answering(query):\\n        return \\\"System in demo mode. Install dependencies for full functionality.\\\"\\n\\n# Configure Streamlit with professional settings\\nst.set_page_config(\\n    page_title=\\\"MCP AI Assistant Suite\\\",\\n    page_icon=\\\"\\ud83e\\udd16\\\",\\n    layout=\\\"wide\\\",\\n    initial_sidebar_state=\\\"collapsed\\\"\\n)\\n\\n# Professional CSS styling with business-standard design\\nst.markdown(\\\"\\\"\\\"\\n<style>\\n    /* Professional color scheme */\\n    :root {\\n        --primary-navy: #1a365d;\\n        --secondary-blue: #2b77d9;\\n        --accent-teal: #319795;\\n        --success-green: #38a169;\\n        --warning-amber: #d69e2e;\\n        --danger-red: #e53e3e;\\n        --neutral-50: #f7fafc;\\n        --neutral-100: #edf2f7;\\n        --neutral-200: #e2e8f0;\\n        --neutral-300: #cbd5e0;\\n        --neutral-700: #4a5568;\\n        --neutral-800: #2d3748;\\n        --neutral-900: #1a202c;\\n    }\\n    \\n    /* Hide Streamlit branding for professional appearance */\\n    #MainMenu {visibility: hidden;}\\n    footer {visibility: hidden;}\\n    header {visibility: hidden;}\\n    .css-1rs6os {visibility: hidden;}\\n    .css-17ziqus {visibility: hidden;}\\n    \\n    /* Main application header */\\n    .main-header {\\n        background: linear-gradient(135deg, var(--primary-navy) 0%, var(--secondary-blue) 100%);\\n        padding: 2rem 3rem 1.5rem 3rem;\\n        margin: -1rem -1rem 2rem -1rem;\\n        color: white;\\n        border-radius: 0 0 16px 16px;\\n        box-shadow: 0 8px 32px rgba(26, 54, 93, 0.15);\\n    }\\n    \\n    .header-content {\\n        display: flex;\\n        align-items: center;\\n        justify-content: space-between;\\n        max-width: 1200px;\\n        margin: 0 auto;\\n    }\\n    \\n    .brand-section {\\n        display: flex;\\n        align-items: center;\\n        gap: 1.5rem;\\n    }\\n    \\n    .brand-icon {\\n        width: 48px;\\n        height: 48px;\\n        background: rgba(255, 255, 255, 0.15);\\n        border-radius: 12px;\\n        display: flex;\\n        align-items: center;\\n        justify-content: center;\\n        font-size: 1.5rem;\\n        backdrop-filter: blur(10px);\\n        border: 1px solid rgba(255, 255, 255, 0.2);\\n    }\\n    \\n    .brand-text h1 {\\n        font-size: 2rem;\\n        font-weight: 700;\\n        margin: 0 0 0.25rem 0;\\n        letter-spacing: -0.025em;\\n    }\\n    \\n    .brand-text .tagline {\\n        font-size: 0.95rem;\\n        opacity: 0.85;\\n        font-weight: 400;\\n        margin: 0;\\n    }\\n    \\n    .system-status {\\n        display: flex;\\n        align-items: center;\\n        background: rgba(56, 161, 105, 0.2);\\n        color: white;\\n        padding: 0.5rem 1rem;\\n        border-radius: 8px;\\n        font-size: 0.875rem;\\n        font-weight: 600;\\n        border: 1px solid rgba(255, 255, 255, 0.2);\\n    }\\n    \\n    .status-indicator {\\n        width: 8px;\\n        height: 8px;\\n        background: #38a169;\\n        border-radius: 50%;\\n        margin-right: 0.5rem;\\n        animation: pulse 2s infinite;\\n    }\\n    \\n    @keyframes pulse {\\n        0% { opacity: 1; transform: scale(1); }\\n        50% { opacity: 0.7; transform: scale(1.1); }\\n        100% { opacity: 1; transform: scale(1); }\\n    }\\n    \\n    /* Tool cards with professional styling */\\n    .tool-card {\\n        background: white;\\n        border: 1px solid var(--neutral-200);\\n        border-radius: 12px;\\n        padding: 2rem;\\n        margin: 1.5rem 0;\\n        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.05);\\n        transition: all 0.3s ease;\\n        border-left: 4px solid var(--accent-teal);\\n    }\\n    \\n    .tool-card:hover {\\n        transform: translateY(-4px);\\n        box-shadow: 0 12px 32px rgba(0, 0, 0, 0.12);\\n        border-left-color: var(--secondary-blue);\\n    }\\n    \\n    .tool-header {\\n        display: flex;\\n        align-items: center;\\n        justify-content: space-between;\\n        margin-bottom: 1rem;\\n    }\\n    \\n    .tool-title {\\n        font-size: 1.25rem;\\n        font-weight: 600;\\n        color: var(--neutral-800);\\n        margin: 0;\\n    }\\n    \\n    .tool-category {\\n        background: var(--neutral-100);\\n        color: var(--neutral-700);\\n        padding: 0.25rem 0.75rem;\\n        border-radius: 6px;\\n        font-size: 0.75rem;\\n        font-weight: 500;\\n        text-transform: uppercase;\\n        letter-spacing: 0.05em;\\n    }\\n    \\n    .tool-description {\\n        color: var(--neutral-700);\\n        line-height: 1.6;\\n        margin: 0 0 1.5rem 0;\\n    }\\n    \\n    .tool-status {\\n        display: inline-flex;\\n        align-items: center;\\n        padding: 0.375rem 0.875rem;\\n        border-radius: 8px;\\n        font-size: 0.875rem;\\n        font-weight: 500;\\n        margin-right: 0.5rem;\\n    }\\n    \\n    .status-available {\\n        background: rgba(56, 161, 105, 0.1);\\n        color: var(--success-green);\\n        border: 1px solid rgba(56, 161, 105, 0.2);\\n    }\\n    \\n    .status-error {\\n        background: rgba(229, 62, 62, 0.1);\\n        color: var(--danger-red);\\n        border: 1px solid rgba(229, 62, 62, 0.2);\\n    }\\n    \\n    .status-warning {\\n        background: rgba(214, 158, 46, 0.1);\\n        color: var(--warning-amber);\\n        border: 1px solid rgba(214, 158, 46, 0.2);\\n    }\\n    \\n    /* Execution interface styling */\\n    .execution-panel {\\n        background: var(--neutral-50);\\n        border: 1px solid var(--neutral-200);\\n        border-radius: 12px;\\n        padding: 2rem;\\n        margin: 1.5rem 0;\\n    }\\n    \\n    .execution-header {\\n        font-size: 1.125rem;\\n        font-weight: 600;\\n        color: var(--neutral-800);\\n        margin: 0 0 1.5rem 0;\\n        padding-bottom: 0.75rem;\\n        border-bottom: 2px solid var(--neutral-200);\\n    }\\n    \\n    .parameter-group {\\n        margin-bottom: 1.5rem;\\n    }\\n    \\n    .parameter-label {\\n        display: block;\\n        font-weight: 600;\\n        color: var(--neutral-700);\\n        margin-bottom: 0.5rem;\\n    }\\n    \\n    .required-indicator {\\n        color: var(--danger-red);\\n        margin-left: 0.25rem;\\n    }\\n    \\n    /* Results display */\\n    .result-container {\\n        background: white;\\n        border: 1px solid var(--neutral-200);\\n        border-radius: 12px;\\n        overflow: hidden;\\n        margin: 1.5rem 0;\\n        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\\n    }\\n    \\n    .result-header {\\n        background: var(--neutral-100);\\n        padding: 1rem 1.5rem;\\n        border-bottom: 1px solid var(--neutral-200);\\n        display: flex;\\n        align-items: center;\\n        justify-content: space-between;\\n    }\\n    \\n    .result-title {\\n        font-weight: 600;\\n        color: var(--neutral-800);\\n        margin: 0;\\n    }\\n    \\n    .execution-time {\\n        font-size: 0.875rem;\\n        color: var(--neutral-700);\\n        background: white;\\n        padding: 0.25rem 0.75rem;\\n        border-radius: 6px;\\n        border: 1px solid var(--neutral-300);\\n    }\\n    \\n    .result-content {\\n        padding: 1.5rem;\\n        max-height: 400px;\\n        overflow-y: auto;\\n    }\\n    \\n    /* Professional buttons */\\n    .stButton > button {\\n        background: linear-gradient(135deg, var(--primary-navy) 0%, var(--secondary-blue) 100%);\\n        color: white;\\n        border: none;\\n        border-radius: 8px;\\n        padding: 0.75rem 2rem;\\n        font-weight: 600;\\n        font-size: 0.875rem;\\n        letter-spacing: 0.025em;\\n        transition: all 0.3s ease;\\n        box-shadow: 0 2px 8px rgba(43, 119, 217, 0.2);\\n    }\\n    \\n    .stButton > button:hover {\\n        transform: translateY(-2px);\\n        box-shadow: 0 8px 24px rgba(43, 119, 217, 0.3);\\n    }\\n    \\n    /* Navigation tabs */\\n    .stTabs [data-baseweb=\\\"tab-list\\\"] {\\n        gap: 12px;\\n        background: var(--neutral-100);\\n        padding: 0.5rem;\\n        border-radius: 12px;\\n        margin-bottom: 2rem;\\n    }\\n    \\n    .stTabs [data-baseweb=\\\"tab\\\"] {\\n        height: 48px;\\n        background-color: transparent;\\n        border-radius: 8px;\\n        color: var(--neutral-700);\\n        font-weight: 500;\\n        border: none;\\n        padding: 0 1.5rem;\\n    }\\n    \\n    .stTabs [aria-selected=\\\"true\\\"] {\\n        background-color: white;\\n        color: var(--primary-navy);\\n        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);\\n    }\\n    \\n    /* Sidebar styling */\\n    .css-1d391kg {\\n        background-color: var(--neutral-50);\\n    }\\n    \\n    /* Metrics and statistics */\\n    .metric-card {\\n        background: white;\\n        padding: 1.5rem;\\n        border-radius: 10px;\\n        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\\n        text-align: center;\\n        border-top: 3px solid var(--accent-teal);\\n        margin: 0.75rem 0;\\n    }\\n    \\n    .metric-value {\\n        font-size: 1.75rem;\\n        font-weight: 700;\\n        color: var(--primary-navy);\\n        margin: 0;\\n    }\\n    \\n    .metric-label {\\n        color: var(--neutral-700);\\n        font-size: 0.875rem;\\n        margin: 0.5rem 0 0 0;\\n        font-weight: 500;\\n    }\\n    \\n    /* ChatGPT-like interface styling */\\n    .mode-info-card {\\n        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\\n        color: white;\\n        padding: 1.5rem;\\n        border-radius: 12px;\\n        margin: 1rem 0;\\n        box-shadow: 0 4px 16px rgba(102, 126, 234, 0.2);\\n    }\\n    \\n    .mode-header {\\n        display: flex;\\n        align-items: center;\\n        gap: 0.75rem;\\n        margin-bottom: 0.75rem;\\n    }\\n    \\n    .mode-icon {\\n        font-size: 1.5rem;\\n        filter: drop-shadow(0 2px 4px rgba(0,0,0,0.2));\\n    }\\n    \\n    .mode-title {\\n        font-size: 1.25rem;\\n        font-weight: 600;\\n        margin: 0;\\n    }\\n    \\n    .mode-description {\\n        font-size: 0.95rem;\\n        opacity: 0.9;\\n        margin-bottom: 0.5rem;\\n        line-height: 1.5;\\n    }\\n    \\n    .mode-tools {\\n        font-size: 0.85rem;\\n        opacity: 0.8;\\n        font-style: italic;\\n    }\\n    \\n    .welcome-message {\\n        background: linear-gradient(135deg, var(--neutral-50), var(--neutral-100));\\n        border: 1px solid var(--neutral-200);\\n        border-radius: 16px;\\n        padding: 2rem;\\n        margin: 2rem 0;\\n        text-align: center;\\n        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.05);\\n    }\\n    \\n    .welcome-content {\\n        font-size: 1.1rem;\\n        color: var(--neutral-700);\\n        line-height: 1.6;\\n        max-width: 600px;\\n        margin: 0 auto;\\n    }\\n    \\n    /* Enhanced chat messages */\\n    .chat-message {\\n        margin: 1.5rem 0;\\n        padding: 0;\\n        border-radius: 16px;\\n        max-width: 85%;\\n        display: flex;\\n        align-items: flex-start;\\n        gap: 0.75rem;\\n    }\\n    \\n    .user-message {\\n        background: linear-gradient(135deg, #007bff, #0056b3);\\n        color: white;\\n        margin-left: auto;\\n        border-radius: 16px 16px 4px 16px;\\n        padding: 1.25rem 1.5rem;\\n        box-shadow: 0 4px 12px rgba(0, 123, 255, 0.2);\\n        max-width: 70%;\\n    }\\n    \\n    .assistant-message {\\n        background: white;\\n        color: var(--neutral-800);\\n        border: 1px solid var(--neutral-200);\\n        border-radius: 16px 16px 16px 4px;\\n        padding: 1.25rem 1.5rem;\\n        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\\n        max-width: 80%;\\n        margin-right: auto;\\n    }\\n    \\n    .assistant-avatar {\\n        width: 32px;\\n        height: 32px;\\n        background: linear-gradient(135deg, var(--accent-teal), var(--success-green));\\n        border-radius: 50%;\\n        display: flex;\\n        align-items: center;\\n        justify-content: center;\\n        font-size: 1rem;\\n        flex-shrink: 0;\\n        margin-top: 0.25rem;\\n        box-shadow: 0 2px 8px rgba(49, 151, 149, 0.3);\\n    }\\n    \\n    .message-content {\\n        flex: 1;\\n        line-height: 1.6;\\n        word-wrap: break-word;\\n    }\\n    \\n    .user-message .message-content {\\n        margin: 0;\\n    }\\n    \\n    .assistant-message .message-content {\\n        margin-left: 0.5rem;\\n    }\\n    \\n    /* Quick actions styling */\\n    .stButton > button {\\n        background: linear-gradient(135deg, var(--primary-navy) 0%, var(--secondary-blue) 100%);\\n        color: white;\\n        border: none;\\n        border-radius: 10px;\\n        padding: 0.75rem 1.5rem;\\n        font-weight: 500;\\n        font-size: 0.875rem;\\n        transition: all 0.3s ease;\\n        box-shadow: 0 2px 8px rgba(43, 119, 217, 0.2);\\n        border-left: 4px solid var(--accent-teal);\\n    }\\n    \\n    .stButton > button:hover {\\n        transform: translateY(-2px);\\n        box-shadow: 0 6px 20px rgba(43, 119, 217, 0.3);\\n        border-left-color: var(--success-green);\\n    }\\n    \\n    .stButton > button:active {\\n        transform: translateY(0);\\n        box-shadow: 0 2px 8px rgba(43, 119, 217, 0.2);\\n    }\\n    \\n    /* Chat input enhancement */\\n    .stChatInput > div > div > div > div {\\n        border-radius: 24px;\\n        border: 2px solid var(--neutral-200);\\n        background: white;\\n        transition: all 0.3s ease;\\n        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\\n    }\\n    \\n    .stChatInput > div > div > div > div:focus-within {\\n        border-color: var(--secondary-blue);\\n        box-shadow: 0 4px 16px rgba(43, 119, 217, 0.15);\\n    }\\n    \\n    /* Selectbox styling */\\n    .stSelectbox > div > div > div {\\n        background: white;\\n        border: 2px solid var(--neutral-200);\\n        border-radius: 10px;\\n        transition: all 0.3s ease;\\n    }\\n    \\n    .stSelectbox > div > div > div:focus-within {\\n        border-color: var(--secondary-blue);\\n        box-shadow: 0 4px 16px rgba(43, 119, 217, 0.15);\\n    }\\n    \\n    /* Conversation history styling */\\n    .conversation-container {\\n        max-height: 600px;\\n        overflow-y: auto;\\n        padding: 1rem;\\n        background: var(--neutral-50);\\n        border-radius: 12px;\\n        margin: 1rem 0;\\n    }\\n    \\n    /* Typing indicator */\\n    .typing-indicator {\\n        display: flex;\\n        align-items: center;\\n        gap: 0.5rem;\\n        padding: 1rem;\\n        background: var(--neutral-100);\\n        border-radius: 12px;\\n        margin: 1rem 0;\\n        animation: pulse 1.5s infinite;\\n    }\\n    \\n    @keyframes pulse {\\n        0% { opacity: 0.6; }\\n        50% { opacity: 1; }\\n        100% { opacity: 0.6; }\\n    }\\n    \\n    /* Session information */\\n    .session-card {\\n        background: white;\\n        border: 1px solid var(--neutral-200);\\n        border-radius: 10px;\\n        padding: 1.25rem;\\n        margin: 1rem 0;\\n        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\\n    }\\n    \\n    .session-header {\\n        font-weight: 600;\\n        color: var(--neutral-800);\\n        margin: 0 0 0.75rem 0;\\n    }\\n    \\n    .session-detail {\\n        display: flex;\\n        justify-content: space-between;\\n        margin: 0.5rem 0;\\n        font-size: 0.875rem;\\n    }\\n    \\n    .session-label {\\n        color: var(--neutral-700);\\n        font-weight: 500;\\n    }\\n    \\n    .session-value {\\n        color: var(--neutral-800);\\n    }\\n    \\n    /* Alert messages */\\n    .custom-alert {\\n        padding: 1rem 1.5rem;\\n        border-radius: 10px;\\n        margin: 1.5rem 0;\\n        border-left: 4px solid;\\n        font-weight: 500;\\n    }\\n    \\n    .alert-info {\\n        background: rgba(43, 119, 217, 0.1);\\n        border-color: var(--secondary-blue);\\n        color: var(--secondary-blue);\\n    }\\n    \\n    .alert-warning {\\n        background: rgba(214, 158, 46, 0.1);\\n        border-color: var(--warning-amber);\\n        color: #9c4221;\\n    }\\n    \\n    .alert-success {\\n        background: rgba(56, 161, 105, 0.1);\\n        border-color: var(--success-green);\\n        color: var(--success-green);\\n    }\\n    \\n    /* Loading states */\\n    .loading-container {\\n        display: flex;\\n        align-items: center;\\n        justify-content: center;\\n        padding: 2rem;\\n        background: var(--neutral-50);\\n        border-radius: 12px;\\n        margin: 1rem 0;\\n    }\\n    \\n    /* Export functionality */\\n    .export-section {\\n        background: white;\\n        border: 1px solid var(--neutral-200);\\n        border-radius: 10px;\\n        padding: 1.25rem;\\n        margin: 1rem 0;\\n    }\\n    \\n    .export-header {\\n        font-weight: 600;\\n        color: var(--neutral-800);\\n        margin: 0 0 1rem 0;\\n    }\\n</style>\\n\\\"\\\"\\\", unsafe_allow_html=True)\\n\\n# Load tools configuration\\n@st.cache_data\\ndef load_tools_config():\\n    \\\"\\\"\\\"Load tools configuration from tools.json\\\"\\\"\\\"\\n    try:\\n        with open(\\\"tools.json\\\", \\\"r\\\", encoding=\\\"utf-8\\\") as f:\\n            return json.load(f)\\n    except Exception as e:\\n        st.error(f\\\"Error loading tools configuration: {e}\\\")\\n        return []\\n\\nclass ProfessionalToolManager:\\n    \\\"\\\"\\\"Enterprise-grade tool execution and management system\\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.tools_config = load_tools_config()\\n        self.loaded_tools = {}\\n        self.execution_log = []\\n        self.session_stats = {\\n            \\\"tools_executed\\\": 0,\\n            \\\"successful_executions\\\": 0,\\n            \\\"failed_executions\\\": 0,\\n            \\\"total_execution_time\\\": 0\\n        }\\n        self._initialize_tools()\\n    \\n    def _initialize_tools(self):\\n        \\\"\\\"\\\"Initialize and validate all available tools\\\"\\\"\\\"\\n        for tool_config in self.tools_config:\\n            try:\\n                module_path = tool_config[\\\"module\\\"]\\n                tool_name = tool_config[\\\"name\\\"]\\n                \\n                # Import the module\\n                module = importlib.import_module(module_path)\\n                \\n                # Get the function\\n                if hasattr(module, tool_name):\\n                    tool_func = getattr(module, tool_name)\\n                    self.loaded_tools[tool_name] = {\\n                        \\\"function\\\": tool_func,\\n                        \\\"config\\\": tool_config,\\n                        \\\"status\\\": \\\"available\\\",\\n                        \\\"executions\\\": 0,\\n                        \\\"last_executed\\\": None\\n                    }\\n                else:\\n                    self.loaded_tools[tool_na...\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"load_tools_config\",\n    \"doc\": \"Load tools configuration from tools.json\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"ProfessionalToolManager\",\n    \"doc\": \"Enterprise-grade tool execution and management system\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"init_session_state\",\n    \"doc\": \"Initialize all session state variables\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"load_conversation_history\",\n    \"doc\": \"Load conversation history from file\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"save_conversation_history\",\n    \"doc\": \"Save conversation history to file\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"render_professional_header\",\n    \"doc\": \"Render professional application header\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"render_chatgpt_interface\",\n    \"doc\": \"Render ChatGPT-like interface with intelligent conversation\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"load_conversation_history\",\n    \"doc\": \"Load conversation history from file\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"save_conversation_history\",\n    \"doc\": \"Save conversation history to file\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_mode_specific_response\",\n    \"doc\": \"Get mode-specific AI response\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"auto_execute_tool_if_applicable\",\n    \"doc\": \"Auto-execute relevant tools based on mode and message content\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"main\",\n    \"doc\": \"Main application entry point\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"__init__\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"_initialize_tools\",\n    \"doc\": \"Initialize and validate all available tools\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_available_tools\",\n    \"doc\": \"Get list of successfully loaded tools\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_all_tools\",\n    \"doc\": \"Get all tools with their status\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_tool_config\",\n    \"doc\": \"Get tool configuration\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"execute_tool\",\n    \"doc\": \"Execute a tool with comprehensive error handling and logging\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"_create_error_result\",\n    \"doc\": \"Create standardized error result\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_execution_statistics\",\n    \"doc\": \"Get comprehensive execution statistics\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"chat_with_bot\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"Chatbot\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"question_answering\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"__init__\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"chat\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\streamlit_app.py\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"test_mcp_server.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\test_mcp_server.py\",\n    \"content\": \"\\\"\\\"\\\"\\nMCP Server Testing and Verification Script\\nDemonstrates local access, monitoring, and tool call verification\\n\\\"\\\"\\\"\\nimport requests\\nimport json\\nimport time\\nimport asyncio\\nimport websockets\\nfrom typing import Dict, Any\\n\\nclass MCPServerTester:\\n    def __init__(self, base_url=\\\"http://localhost:8000\\\", api_key=\\\"dev-test-key\\\"):\\n        self.base_url = base_url\\n        self.api_key = api_key\\n        self.headers = {\\n            \\\"X-API-Key\\\": api_key,\\n            \\\"Content-Type\\\": \\\"application/json\\\"\\n        }\\n    \\n    def test_server_health(self):\\n        \\\"\\\"\\\"Test server health and connectivity\\\"\\\"\\\"\\n        print(\\\"Testing server health...\\\")\\n        try:\\n            response = requests.get(f\\\"{self.base_url}/\\\")\\n            print(f\\\"Server Status: {response.json()}\\\")\\n            \\n            # Detailed health check\\n            response = requests.get(f\\\"{self.base_url}/admin/health\\\")\\n            health_data = response.json()\\n            print(f\\\"Detailed Health: {json.dumps(health_data, indent=2)}\\\")\\n            \\n            return True\\n        except Exception as e:\\n            print(f\\\"Server connection failed: {e}\\\")\\n            return False\\n    \\n    def test_tool_listing(self):\\n        \\\"\\\"\\\"Test tool listing endpoint\\\"\\\"\\\"\\n        print(\\\"\\\\nTesting tool listing...\\\")\\n        try:\\n            response = requests.get(f\\\"{self.base_url}/tools\\\", headers=self.headers)\\n            tools = response.json()\\n            print(f\\\"Available tools: {json.dumps(tools, indent=2)}\\\")\\n            return tools.get(\\\"tools\\\", [])\\n        except Exception as e:\\n            print(f\\\"Tool listing failed: {e}\\\")\\n            return []\\n    \\n    def test_tool_execution(self, tool_name=\\\"scan_codebase\\\", arguments=None):\\n        \\\"\\\"\\\"Test tool execution with monitoring\\\"\\\"\\\"\\n        if arguments is None:\\n            arguments = {\\\"query\\\": \\\"python patterns\\\"}\\n        print(f\\\"\\\\nTesting tool execution: {tool_name}\\\")\\n        try:\\n            payload = {\\n                \\\"tool_name\\\": tool_name,\\n                \\\"arguments\\\": arguments\\n            }\\n            \\n            start_time = time.time()\\n            response = requests.post(\\n                f\\\"{self.base_url}/tools/execute\\\", \\n                headers=self.headers, \\n                json=payload\\n            )\\n            execution_time = time.time() - start_time\\n            \\n            if response.status_code == 200:\\n                result = response.json()\\n                print(f\\\"Tool executed successfully in {execution_time:.2f}s\\\")\\n                print(f\\\"Result preview: {str(result.get('result', ''))[:200]}...\\\")\\n                return result\\n            else:\\n                print(f\\\"Tool execution failed: {response.status_code} - {response.text}\\\")\\n                return None\\n        except Exception as e:\\n            print(f\\\"Tool execution error: {e}\\\")\\n            return None\\n    \\n    def test_verification_endpoint(self):\\n        \\\"\\\"\\\"Test tool call verification\\\"\\\"\\\"\\n        print(\\\"\\\\nTesting tool call verification...\\\")\\n        try:\\n            response = requests.get(f\\\"{self.base_url}/verify/tools\\\", headers=self.headers)\\n            verification = response.json()\\n            \\n            print(f\\\"Verification Status: {verification.get('verification_status')}\\\")\\n            print(f\\\"Total calls tracked: {verification.get('total_calls')}\\\")\\n            print(f\\\"IDE breakdown: {verification.get('ide_breakdown')}\\\")\\n            print(f\\\"Tool breakdown: {verification.get('tool_breakdown')}\\\")\\n            \\n            return verification\\n        except Exception as e:\\n            print(f\\\"Verification failed: {e}\\\")\\n            return None\\n    \\n    def test_analytics(self):\\n        \\\"\\\"\\\"Test analytics endpoints\\\"\\\"\\\"\\n        print(\\\"\\\\nTesting analytics...\\\")\\n        try:\\n            # Get usage stats\\n            response = requests.get(f\\\"{self.base_url}/admin/analytics/stats\\\", headers=self.headers)\\n            stats = response.json()\\n            print(f\\\"Usage Stats: {json.dumps(stats, indent=2)}\\\")\\n            \\n            # Get recent executions\\n            response = requests.get(f\\\"{self.base_url}/admin/analytics/executions?limit=...\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"MCPServerTester\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\test_mcp_server.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"__init__\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\test_mcp_server.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"test_server_health\",\n    \"doc\": \"Test server health and connectivity\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\test_mcp_server.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"test_tool_listing\",\n    \"doc\": \"Test tool listing endpoint\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\test_mcp_server.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"test_tool_execution\",\n    \"doc\": \"Test tool execution with monitoring\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\test_mcp_server.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"test_verification_endpoint\",\n    \"doc\": \"Test tool call verification\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\test_mcp_server.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"test_analytics\",\n    \"doc\": \"Test analytics endpoints\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\test_mcp_server.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"run_comprehensive_test\",\n    \"doc\": \"Run all tests to verify MCP server functionality\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\test_mcp_server.py\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"tools.json\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\tools.json\",\n    \"content\": \"[\\n  {\\n    \\\"name\\\": \\\"jira_ticket_summarizer\\\",\\n    \\\"module\\\": \\\"tools.development.jira_tools\\\",\\n    \\\"description\\\": \\\"Analyze JIRA ticket history for development patterns, requirements, and project insights.\\\",\\n    \\\"args_schema\\\": {\\n      \\\"type\\\": \\\"object\\\",\\n      \\\"properties\\\": {\\n        \\\"query\\\": { \\\"type\\\": \\\"string\\\", \\\"description\\\": \\\"Query about JIRA patterns, ticket analysis, or project requirements.\\\" }\\n      },\\n      \\\"required\\\": [\\\"query\\\"]\\n    },\\n    \\\"output_format\\\": \\\"json\\\"\\n  },\\n  {\\n    \\\"name\\\": \\\"fetch_remote_git_history\\\",\\n    \\\"module\\\": \\\"tools.development.git_tools\\\",\\n    \\\"description\\\": \\\"Fetch git commit history from a remote repository.\\\",\\n    \\\"args_schema\\\"...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"tools_modular.json\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\tools_modular.json\",\n    \"content\": \"[\\n  {\\n    \\\"name\\\": \\\"question_answering\\\",\\n    \\\"module\\\": \\\"chatbot\\\",\\n    \\\"description\\\": \\\"Answer questions by performing internet research and logical reasoning. Remembers context for follow-up questions.\\\",\\n    \\\"args_schema\\\": {\\n      \\\"type\\\": \\\"object\\\",\\n      \\\"properties\\\": {\\n        \\\"query\\\": { \\\"type\\\": \\\"string\\\", \\\"description\\\": \\\"The natural language question to answer.\\\" }\\n      },\\n      \\\"required\\\": [\\\"query\\\"]\\n    },\\n    \\\"output_format\\\": \\\"console\\\"\\n  },\\n  {\\n    \\\"name\\\": \\\"custom_api\\\",\\n    \\\"module\\\": \\\"tools.custom_api\\\",\\n    \\\"description\\\": \\\"Execute an internal project function exposed over HTTP.\\\",\\n    \\\"args_schema\\\": {\\n      \\\"type\\\": \\\"object\\\",\\n      \\\"properties\\\": {\\n        \\\"query\\\": { \\\"type\\\": \\\"string\\\", \\\"description\\\": \\\"The natural language prompt or query for the tool.\\\" }\\n      },\\n      \\\"required\\\": [\\\"query\\\"]\\n    },\\n    \\\"output_format\\\": \\\"console\\\"\\n  },\\n  {\\n    \\\"name\\\": \\\"scan_codebase\\\",\\n    \\\"module\\\": \\\"tools.development.codebase_tools\\\",\\n    \\\"description\\\": \\\"Scan and analyze codebase for patterns, conventions, folder structures, and naming patterns.\\\",\\n    \\\"args_schema\\\": {\\n      \\\"type\\\": \\\"object\\\",\\n      ...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"tool_registry.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\core\\\\tool_registry.py\",\n    \"content\": \"import json\\nimport importlib\\nfrom pathlib import Path\\nfrom langchain.tools import Tool\\n\\nTOOLS_PATH = Path(__file__).parent.parent / \\\"tools.json\\\"\\n\\nclass ToolRegistry:\\n    def __init__(self):\\n        with open(TOOLS_PATH, \\\"r\\\", encoding=\\\"utf-8\\\") as f:\\n            self.tools_config = json.load(f)\\n        self.tools = self._load_tools()\\n\\n    def _load_tools(self):\\n        tools = []\\n        for tool in self.tools_config:\\n            module_path = tool[\\\"module\\\"]\\n            func_name = tool[\\\"name\\\"]\\n            mod = importlib.import_module(...\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"ToolRegistry\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_tool_registry\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"__init__\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"_load_tools\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_tool_list\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"execute_tool\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"codebandits_private_history.json\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\data\\\\codebandits_private_history.json\",\n    \"content\": \"{\\n  \\\"repository\\\": {\\n    \\\"url\\\": \\\"https://github.com/Codebandits-tal/hackhathon-codebandits.git\\\",\\n    \\\"cloned_branch\\\": \\\"master\\\",\\n    \\\"requested_branch\\\": \\\"main\\\",\\n    \\\"remote_url\\\": \\\"https://github.com/Codebandits-tal/hackhathon-codebandits.git\\\"\\n  },\\n  \\\"metadata\\\": {\\n    \\\"total_commits_fetched\\\": 50,\\n    \\\"max_commits_requested\\\": 50,\\n    \\\"fetch_timestamp\\\": \\\"2025-08-02T14:54:43.328244\\\",\\n    \\\"clone_method\\\": \\\"temporary\\\"\\n  },\\n  \\\"commits\\\": [\\n    {\\n      \\\"sha\\\": \\\"40421a3a982ff30c31d3d27810b560804904f866\\\",\\n      \\\"short_sha\\\": \\\"40421a3\\\",\\n      \\\"message\\\": \\\"Updated diagram path in readme file\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Codebandits-tal\\\",\\n        \\\"email\\\": \\\"140823987+Codebandits-tal@users.noreply.github.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T10:37:00+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T10:37:00+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"README.md\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"1c2b351c0727515bb9c292d06232d9c790c29d80\\\",\\n      \\\"short_sha\\\": \\\"1c2b351\\\",\\n      \\\"message\\\": \\\"Update README.md for onion architecture diagram\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Codebandits-tal\\\",\\n        \\\"email\\\": \\\"140823987+Codebandits-tal@users.noreply.github.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T10:34:21+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T10:34:21+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"README.md\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"3a9fe6f1ecea825781a85440459d7c48583d402b\\\",\\n      \\\"short_sha\\\": \\\"3a9fe6f\\\",\\n      \\\"message\\\": \\\"added onion architecture diagram\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Giridhar Anand\\\",\\n        \\\"email\\\": \\\"giridhar.anand@talentica.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T10:33:27+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T10:33:40+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"Hachathon-architecture.drawio.png\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"60dac31bea290a0ae831b6fdce35485a3f473c1a\\\",\\n      \\\"short_sha\\\": \\\"60dac31\\\",\\n      \\\"message\\\": \\\"ai icon on app level\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Ashok Patel\\\",\\n        \\\"email\\\": \\\"ashok@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T10:23:59+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T10:23:59+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/app.component.css\\\",\\n        \\\"CB-UI/src/app/app.component.html\\\",\\n        \\\"CB-UI/src/app/app.component.ts\\\",\\n        \\\"CB-UI/src/app/landing-page/landing-page.component.html\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"8685b87ad62a177b9478e78ea159f236207b1415\\\",\\n      \\\"short_sha\\\": \\\"8685b87\\\",\\n      \\\"message\\\": \\\"fixed editor resume builder\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Rajesh Patra\\\",\\n        \\\"email\\\": \\\"rajesh@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T09:39:44+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T09:39:44+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/component/editor/editor.component.ts\\\",\\n        \\\"CB-UI/src/app/service/login.service.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"df974d836a88b7a085dd6260c18597b9f76ed92d\\\",\\n      \\\"short_sha\\\": \\\"df974d8\\\",\\n      \\\"message\\\": \\\"fixed import error in app module, routing fix, search fix\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Rajesh Patra\\\",\\n        \\\"email\\\": \\\"rajesh@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T09:24:28+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T09:24:28+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/app-routing.module.ts\\\",\\n        \\\"CB-UI/src/app/app.module.ts\\\",\\n        \\\"CB-UI/src/app/auth.guard.ts\\\",\\n        \\\"CB-UI/src/app/component/editor/editor.component.ts\\\",\\n        \\\"CB-UI/src/app/login/login.component.ts\\\",\\n        \\\"CB-UI/src/app/service/login.service.ts\\\",\\n        \\\"CB-UI/src/app/service/search.service.ts\\\",\\n        \\\"CB-UI/src/app/service/userinfo.service.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"4c4a057cd322d05d63c422decd4d0944bd8e9a74\\\",\\n      \\\"short_sha\\\": \\\"4c4a057\\\",\\n      \\\"message\\\": \\\"Added Pipe for Gender\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Vishal Raj\\\",\\n        \\\"email\\\": \\\"Vishal@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T07:34:20+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T07:34:20+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/app.module.ts\\\",\\n        \\\"CB-UI/src/app/gender.pipe.spec.ts\\\",\\n        \\\"CB-UI/src/app/gender.pipe.ts\\\",\\n        \\\"CB-UI/src/app/view-search-result/view-search-result.component.html\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"0335f51566f8f3440c3ea0c6f03875cf1486844b\\\",\\n      \\\"short_sha\\\": \\\"0335f51\\\",\\n      \\\"message\\\": \\\"App module and misc files\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Ashok Patel\\\",\\n        \\\"email\\\": \\\"ashok@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T04:25:00+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T04:42:36+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/.prettierignore\\\",\\n        \\\"CB-UI/.prettierrc.json\\\",\\n        \\\"CB-UI/angular.json\\\",\\n        \\\"CB-UI/package.json\\\",\\n        \\\"CB-UI/proxy-base.json\\\",\\n        \\\"CB-UI/proxy-config.js\\\",\\n        \\\"CB-UI/src/app/app.module.ts\\\",\\n        \\\"CB-UI/src/index.html\\\",\\n        \\\"CB-UI/src/styles.css\\\",\\n        \\\"CB-UI/src/web.config\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"b7afab9718abce478964eeb6c95b01bcb5b1c13d\\\",\\n      \\\"short_sha\\\": \\\"b7afab9\\\",\\n      \\\"message\\\": \\\"Landing page work\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Ashok Patel\\\",\\n        \\\"email\\\": \\\"ashok@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T04:23:37+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T04:41:36+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/landing-page/landing-page.component.css\\\",\\n        \\\"CB-UI/src/app/landing-page/landing-page.component.html\\\",\\n        \\\"CB-UI/src/app/landing-page/landing-page.component.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"222412f0c6e6c3daae121aa7dd734569b12058c8\\\",\\n      \\\"short_sha\\\": \\\"222412f\\\",\\n      \\\"message\\\": \\\"Shared module\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Ashok Patel\\\",\\n        \\\"email\\\": \\\"ashok@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T04:22:44+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T04:39:23+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/core/common.css\\\",\\n        \\\"CB-UI/src/app/core/shared/shared.module.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"87a86cf86e64e78c596252e1eea45bff5b31c5da\\\",\\n      \\\"short_sha\\\": \\\"87a86cf\\\",\\n      \\\"message\\\": \\\"AI Assistant module\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Ashok Patel\\\",\\n        \\\"email\\\": \\\"ashok@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T04:21:36+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T04:39:23+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/ai-assistant/ai-assistant.module.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/ask-anything/ask-anything.component.css\\\",\\n        \\\"CB-UI/src/app/ai-assistant/ask-anything/ask-anything.component.html\\\",\\n        \\\"CB-UI/src/app/ai-assistant/ask-anything/ask-anything.component.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/assistant.service.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/core/ai-styles.css\\\",\\n        \\\"CB-UI/src/app/ai-assistant/email-helper/email-helper.component.css\\\",\\n        \\\"CB-UI/src/app/ai-assistant/email-helper/email-helper.component.html\\\",\\n        \\\"CB-UI/src/app/ai-assistant/email-helper/email-helper.component.spec.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/email-helper/email-helper.component.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/grammar-helper/grammar-helper.component.css\\\",\\n        \\\"CB-UI/src/app/ai-assistant/grammar-helper/grammar-helper.component.html\\\",\\n        \\\"CB-UI/src/app/ai-assistant/grammar-helper/grammar-helper.component.spec.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/grammar-helper/grammar-helper.component.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/home/home.component.css\\\",\\n        \\\"CB-UI/src/app/ai-assistant/home/home.component.html\\\",\\n        \\\"CB-UI/src/app/ai-assistant/home/home.component.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/interview-helper/interview-helper.component.css\\\",\\n        \\\"CB-UI/src/app/ai-assistant/interview-helper/interview-helper.component.html\\\",\\n        \\\"CB-UI/src/app/ai-assistant/interview-helper/interview-helper.component.spec.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/interview-helper/interview-helper.component.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/resume-helper/resume-helper.component.css\\\",\\n        \\\"CB-UI/src/app/ai-assistant/resume-helper/resume-helper.component.html\\\",\\n        \\\"CB-UI/src/app/ai-assistant/resume-helper/resume-helper.component.spec.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/resume-helper/resume-helper.component.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/search-helper/search-helper.component.css\\\",\\n        \\\"CB-UI/src/app/ai-assistant/search-helper/search-helper.component.html\\\",\\n        \\\"CB-UI/src/app/ai-assistant/search-helper/search-helper.component.spec.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/search-helper/search-helper.component.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"06904bacfaa6c97a420f0c4b503b16486206de2f\\\",\\n      \\\"short_sha\\\": \\\"06904ba\\\",\\n      \\\"message\\\": \\\"Python code\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Ashok Patel\\\",\\n        \\\"email\\\": \\\"ashok@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T04:21:02+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T04:39:22+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-AI-Assistant/index.py\\\",\\n        \\\"CB-AI-Assistant/web.config\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"c2e3b3f7cddf29dec2e2c178ac8d5197cee425ea\\\",\\n      \\\"short_sha\\\": \\\"c2e3b3f\\\",\\n      \\\"message\\\": \\\"CB ai first work\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Ashok Patel\\\",\\n        \\\"email\\\": \\\"ashok@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-29T14:03:34+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T04:39:22+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\".gitignore\\\",\\n        \\\"CB-AI-Assistant/.gitignore\\\",\\n        \\\"CB-AI-Assistant/.vscode/launch.json\\\",\\n        \\\"CB-AI-Assistant/.vscode/settings.json\\\",\\n        \\\"CB-AI-Assistant/README.md\\\",\\n        \\\"CB-AI-Assistant/Setup.md\\\",\\n        \\\"CB-AI-Assistant/conf/config.ini\\\",\\n        \\\"CB-AI-Assistant/index.py\\\",\\n        \\\"CB-AI-Assistant/requirements.txt\\\",\\n        \\\"CB-AI-Assistant/templates/index.html\\\",\\n        \\\"CB-AI-Assistant/web.config\\\",\\n        \\\"CB-UI/src/app/ai-assistant/ai-assistant-routing.module.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/ai-assistant.module.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/ask-anything/ask-anything.component.css\\\",\\n        \\\"CB-UI/src/app/ai-assistant/ask-anything/ask-anything.component.html\\\",\\n        \\\"CB-UI/src/app/ai-assistant/ask-anything/ask-anything.component.spec.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/ask-anything/ask-anything.component.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/assistant.service.spec.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/assistant.service.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/core/ai-assistant-request.model.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/core/ai-assistant-response.model.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/core/ai-styles.css\\\",\\n        \\\"CB-UI/src/app/ai-assistant/core/toolbar-map.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/home/home.component.css\\\",\\n        \\\"CB-UI/src/app/ai-assistant/home/home.component.html\\\",\\n        \\\"CB-UI/src/app/ai-assistant/home/home.component.spec.ts\\\",\\n        \\\"CB-UI/src/app/ai-assistant/home/home.component.ts\\\",\\n        \\\"CB-UI/src/app/core/http.service.spec.ts\\\",\\n        \\\"CB-UI/src/app/core/http.service.ts\\\",\\n        \\\"CB-UI/src/app/landing-page/landing-page.component.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"a1b06e6e4bf456759ce78dd762edc830fdc49811\\\",\\n      \\\"short_sha\\\": \\\"a1b06e6\\\",\\n      \\\"message\\\": \\\"added Search integration -Vishal\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Vishal Raj\\\",\\n        \\\"email\\\": \\\"Vishal@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T03:39:06+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T03:39:06+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/component/search/search.component.html\\\",\\n        \\\"CB-UI/src/app/component/search/search.component.ts\\\",\\n        \\\"CB-UI/src/app/header/header.component.css\\\",\\n        \\\"CB-UI/src/app/header/header.component.html\\\",\\n        \\\"CB-UI/src/app/landing-page/landing-page.component.html\\\",\\n        \\\"CB-UI/src/app/profile/profile.component.html\\\",\\n        \\\"CB-UI/src/app/service/search.service.spec.ts\\\",\\n        \\\"CB-UI/src/app/service/search.service.ts\\\",\\n        \\\"CB-UI/src/app/service/userinfo.service.ts\\\",\\n        \\\"CB-UI/src/app/view-search-result/view-search-result.component.html\\\",\\n        \\\"CB-UI/src/app/view-search-result/view-search-result.component.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"00b7d9deca5ef67e4f0f901be555fbe4be8c92ba\\\",\\n      \\\"short_sha\\\": \\\"00b7d9d\\\",\\n      \\\"message\\\": \\\"implemented get resume and save resume api\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Giridhar Anand\\\",\\n        \\\"email\\\": \\\"giridhar.anand@talentica.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T03:01:47+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T03:01:47+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB.Api/Controllers/ResumeController.cs\\\",\\n        \\\"CB.Core/Models/Resume.cs\\\",\\n        \\\"CB.Core/Repositories/IResumeRepository.cs\\\",\\n        \\\"CB.Core/Services/IResumeService.cs\\\",\\n        \\\"CB.Core/ServicesImpl/ResumeService.cs\\\",\\n        \\\"CB.Extension/CBExtension.cs\\\",\\n        \\\"CB.Repository/ResumeRepository.cs\\\",\\n        \\\"CB.Repository/SQLDB/ReleaseScripts.sql/procs.sql\\\",\\n        \\\"CB.Repository/SQLDB/ReleaseScripts.sql/tables.sql\\\",\\n        \\\"CB.Repository/SQLDB/SProcs/get_resume.sql\\\",\\n        \\\"CB.Repository/SQLDB/SProcs/save_resume.sql\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"4abfa4fac765f913d9eb46adb89068a5de64ca8e\\\",\\n      \\\"short_sha\\\": \\\"4abfa4f\\\",\\n      \\\"message\\\": \\\"order by descending for search employee api\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Giridhar Anand\\\",\\n        \\\"email\\\": \\\"giridhar.anand@talentica.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T01:34:31+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T01:34:31+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB.Repository/SQLDB/ReleaseScripts.sql/procs.sql\\\",\\n        \\\"CB.Repository/SQLDB/SProcs/search_employees.sql\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"fcfd09f1871ee19fd848ca7b62a6d9b873c8829d\\\",\\n      \\\"short_sha\\\": \\\"fcfd09f\\\",\\n      \\\"message\\\": \\\"implemented search employee api\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Giridhar Anand\\\",\\n        \\\"email\\\": \\\"giridhar.anand@talentica.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T01:25:35+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T01:26:49+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB.Api/Controllers/EmployeeController.cs\\\",\\n        \\\"CB.Api/Controllers/LoginController.cs\\\",\\n        \\\"CB.Core/Commands/EmployeeSearchCommand.cs\\\",\\n        \\\"CB.Api/Commands/LoginCommand.cs\\\",\\n        \\\"CB.Core/Repositories/IEmployeeRepository.cs\\\",\\n        \\\"CB.Core/Services/IEmployeeService.cs\\\",\\n        \\\"CB.Core/ServicesImpl/EmployeeService.cs\\\",\\n        \\\"CB.Repository/EmployeeRepository.cs\\\",\\n        \\\"CB.Repository/SQLDB/ReleaseScripts.sql/procs.sql\\\",\\n        \\\"CB.Repository/SQLDB/SProcs/get_employee_by_id.sql\\\",\\n        \\\"CB.Repository/SQLDB/SProcs/search_employees.sql\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"eab38cac1c7071eef158df24c9f96dd53f53266f\\\",\\n      \\\"short_sha\\\": \\\"eab38ca\\\",\\n      \\\"message\\\": \\\"YearOfExperience Bug Fixed\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Vishal Raj\\\",\\n        \\\"email\\\": \\\"Vishal@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T00:46:03+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T00:46:03+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/profile/profile.component.html\\\",\\n        \\\"CB-UI/src/app/profile/profile.component.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"12d02fa43c3b9fb83add1be3c0767d9c8dd12f5d\\\",\\n      \\\"short_sha\\\": \\\"12d02fa\\\",\\n      \\\"message\\\": \\\"forms autofill-rajesh\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Rajesh Patra\\\",\\n        \\\"email\\\": \\\"rajesh@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-30T00:24:57+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-30T00:24:57+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/profile/profile.component.html\\\",\\n        \\\"CB-UI/src/app/profile/profile.component.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"8b30ba4a082ba50bafb37b8ee854110ead087453\\\",\\n      \\\"short_sha\\\": \\\"8b30ba4\\\",\\n      \\\"message\\\": \\\"cors fix, issue tracker url update\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Rajesh Patra\\\",\\n        \\\"email\\\": \\\"rajesh@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-29T23:17:01+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-29T23:17:01+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/app-routing.module.ts\\\",\\n        \\\"CB-UI/src/app/header/header.component.html\\\",\\n        \\\"CB-UI/src/app/issuetracker/issuetracker.component.ts\\\",\\n        \\\"CB-UI/src/environments/environment.ts\\\",\\n        \\\"CB.Api/Program.cs\\\",\\n        \\\"CB.Repository/UnitOfWork.cs\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"a1218c0ae44443ff8df24ea9c1e4d71c58c60611\\\",\\n      \\\"short_sha\\\": \\\"a1218c0\\\",\\n      \\\"message\\\": \\\"added cors policy, api in url\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Giridhar Anand\\\",\\n        \\\"email\\\": \\\"giridhar.anand@talentica.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-29T23:00:03+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-29T23:01:04+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB.Api/CB.Api.csproj\\\",\\n        \\\"CB.Api/Controllers/LoginController.cs\\\",\\n        \\\"CB.Api/Controllers/ProjectController.cs\\\",\\n        \\\"CB.Api/Program.cs\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"1670d81c42a2bd60f5eee83888d1620ac3bb7203\\\",\\n      \\\"short_sha\\\": \\\"1670d81\\\",\\n      \\\"message\\\": \\\"Added login html code -Vishal\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Vishal Raj\\\",\\n        \\\"email\\\": \\\"Vishal@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-29T21:12:58+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-29T21:12:58+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/login/login.component.html\\\",\\n        \\\"CB-UI/src/app/service/login.service.ts\\\",\\n        \\\"CB-UI/src/environments/environment.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"0a29e4e3b004caacbb53081eac2b73e415833b2f\\\",\\n      \\\"short_sha\\\": \\\"0a29e4e\\\",\\n      \\\"message\\\": \\\"Added component to display users depending upon the search filter\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Vishal Raj\\\",\\n        \\\"email\\\": \\\"Vishal@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-29T20:32:54+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-29T20:39:24+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/app-routing.module.ts\\\",\\n        \\\"CB-UI/src/app/app.module.ts\\\",\\n        \\\"CB-UI/src/app/profile/profile.component.css\\\",\\n        \\\"CB-UI/src/app/view-search-result/view-search-result.component.css\\\",\\n        \\\"CB-UI/src/app/view-search-result/view-search-result.component.html\\\",\\n        \\\"CB-UI/src/app/view-search-result/view-search-result.component.spec.ts\\\",\\n        \\\"CB-UI/src/app/view-search-result/view-search-result.component.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"76453991a9ae93a3a9df50c7f2391f7eb438bbc5\\\",\\n      \\\"short_sha\\\": \\\"7645399\\\",\\n      \\\"message\\\": \\\"implemented login service code\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Vishal Raj\\\",\\n        \\\"email\\\": \\\"Vishal@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-29T18:14:26+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-29T20:28:38+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/app-routing.module.ts\\\",\\n        \\\"CB-UI/src/app/login/login.component.ts\\\",\\n        \\\"CB-UI/src/app/service/login.service.ts\\\",\\n        \\\"CB-UI/src/app/service/userinfo.service.ts\\\",\\n        \\\"CB-UI/src/environments/environment.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"3a014138598f6821dbbd87a47af1d78e57e56895\\\",\\n      \\\"short_sha\\\": \\\"3a01413\\\",\\n      \\\"message\\\": \\\"UI for login and employee search\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Vishal Raj\\\",\\n        \\\"email\\\": \\\"Vishal@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-29T17:29:04+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-29T20:27:38+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/app-routing.module.ts\\\",\\n        \\\"CB-UI/src/app/component/search/search.component.css\\\",\\n        \\\"CB-UI/src/app/component/search/search.component.html\\\",\\n        \\\"CB-UI/src/app/component/search/search.component.ts\\\",\\n        \\\"CB-UI/src/app/header/header.component.css\\\",\\n        \\\"CB-UI/src/app/header/header.component.html\\\",\\n        \\\"CB-UI/src/app/landing-page/landing-page.component.css\\\",\\n        \\\"CB-UI/src/app/login/login.component.css\\\",\\n        \\\"CB-UI/src/app/login/login.component.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"95dde18ec0d8f28a67eea2ebe240d75a73d6afee\\\",\\n      \\\"short_sha\\\": \\\"95dde18\\\",\\n      \\\"message\\\": \\\"ai assist button added in resumebuilder\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Rajesh Patra\\\",\\n        \\\"email\\\": \\\"rajesh@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-29T18:21:28+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-29T20:27:02+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/app.component.html\\\",\\n        \\\"CB-UI/src/app/component/editor/editor.component.html\\\",\\n        \\\"CB-UI/src/app/component/editor/editor.component.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"3d2b5db90d69e0611977cb08a04c6d5f3df68af2\\\",\\n      \\\"short_sha\\\": \\\"3d2b5db\\\",\\n      \\\"message\\\": \\\"issuetracker update\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Rajesh Patra\\\",\\n        \\\"email\\\": \\\"rajesh@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-29T16:50:57+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-29T20:26:54+05:30\\\",\\n      \\\"changed_files\\\": [\\n        \\\"CB-UI/src/app/app.module.ts\\\",\\n        \\\"CB-UI/src/app/issuetracker/issuetracker.component.css\\\",\\n        \\\"CB-UI/src/app/issuetracker/issuetracker.component.html\\\",\\n        \\\"CB-UI/src/app/issuetracker/issuetracker.component.ts\\\",\\n        \\\"CB-UI/src/app/service/userinfo.service.ts\\\"\\n      ]\\n    },\\n    {\\n      \\\"sha\\\": \\\"79ded17afab556cbd0d52efdb96f89de2dbc7677\\\",\\n      \\\"short_sha\\\": \\\"79ded17\\\",\\n      \\\"message\\\": \\\"issue tracker started\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"Rajesh Patra\\\",\\n        \\\"email\\\": \\\"rajesh@tailoredmail.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2023-07-29T15:24:40+05:30\\\",\\n      \\\"committed_date\\\": \\\"2023-07-29T20:26:0...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"hello_world_remote.json\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\data\\\\hello_world_remote.json\",\n    \"content\": \"{\\n  \\\"repository\\\": {\\n    \\\"url\\\": \\\"https://github.com/octocat/Hello-World.git\\\",\\n    \\\"cloned_branch\\\": \\\"master\\\",\\n    \\\"requested_branch\\\": \\\"main\\\",\\n    \\\"remote_url\\\": \\\"https://github.com/octocat/Hello-World.git\\\"\\n  },\\n  \\\"metadata\\\": {\\n    \\\"total_commits_fetched\\\": 3,\\n    \\\"max_commits_requested\\\": 5,\\n    \\\"fetch_timestamp\\\": \\\"2025-08-02T14:06:39.078365\\\",\\n    \\\"clone_method\\\": \\\"temporary\\\"\\n  },\\n  \\\"commits\\\": [\\n    {\\n      \\\"sha\\\": \\\"7fd1a60b01f91b314f59955a4e4d4e80d8edf11d\\\",\\n      \\\"short_sha\\\": \\\"7fd1a60\\\",\\n      \\\"message\\\": \\\"Merge pull request #6 from Spaceghost/patch-1\\\\n\\\\nNew line at end of file.\\\",\\n      \\\"author\\\": {\\n        \\\"name\\\": \\\"The Octocat\\\",\\n        \\\"email\\\": \\\"octocat@nowhere.com\\\"\\n      },\\n      \\\"authored_date\\\": \\\"2012-03-06T15:06:50-08:00\\\",\\n      \\\"committed_date\\\": \\\"2012-03-06T15:06:50-08:00\\\",\\n      \\\"changed_files\\\": [\\n        \\\"README\\\"\\n ...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"mcp-server.log\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\logs\\\\mcp-server.log\",\n    \"content\": \"2025-08-02 11:36:36,420 - mcp_server - ERROR - Error: {\\\"timestamp\\\": \\\"2025-08-02T06:06:36.419864\\\", \\\"event\\\": \\\"error\\\", \\\"error_type\\\": \\\"tool_execution_error\\\", \\\"error_message\\\": \\\"BaseTool.__call__() got an unexpected keyword argument 'query'\\\", \\\"user_id\\\": \\\"127.0.0.1\\\", \\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"ide_type\\\": \\\"unknown\\\", \\\"additional_data\\\": \\\"{\\\\\\\"tool_name\\\\\\\": \\\\\\\"scan_codebase\\\\\\\", \\\\\\\"execution_time\\\\\\\": 0.0019974708557128906}\\\"}\\n2025-08-02 11:36:36,420 - mcp_server - ERROR - Error: {\\\"timestamp\\\": \\\"2025-08-02T06:06:36.419864\\\", \\\"event\\\": \\\"error\\\", \\\"error_type\\\": \\\"tool_execution_error\\\", \\\"error_message\\\": \\\"BaseTool.__call__() got an unexpected keyword argument 'query'\\\", \\\"user_id\\\": \\\"127.0.0.1\\\", \\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"ide_type\\\": \\\"unknown\\\", \\\"additional_data\\\": \\\"{\\\\\\\"tool_name\\\\\\\": \\\\\\\"scan_codebase\\\\\\\", \\\\\\\"execution_time\\\\\\\": 0.0019974708557128906}\\\"}\\n2025-08-02 11:36:36,439 - mcp_server.server - ERROR - Tool 'scan_codebase' failed: BaseTool.__call__() got an unexpected keyword argument 'query'\\n2025-08-02 11:36:36,439 - mcp_server.server - ERROR - Tool 'scan_codebase' failed: BaseTool.__call__() got an unexpected keyword argument 'query'\\n2025-08-02 11:37:45,915 - mcp_server - INFO - Tool Executed: {\\\"timestamp\\\": \\\"2025-08-02T06:07:45.915899\\\", \\\"event\\\": \\\"tool_executed\\\", \\\"tool_name\\\": \\\"scan_codebase\\\", \\\"user_id\\\": \\\"127.0.0.1\\\", \\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"ide_type\\\": \\\"unknown\\\", \\\"execution_time_ms\\\": 22819.079160690308, \\\"request_size\\\": 73, \\\"response_size\\\": 175, \\\"success\\\": true, \\\"arguments\\\": \\\"{\\\\\\\"query\\\\\\\": \\\\\\\"python patterns\\\\\\\"}\\\", \\\"response_preview\\\": \\\"Codebase scan completed. Found 433 patterns. Common folders: ['site-packages', 'annotated_types']. Use specific queries like 'python naming conventions' for detailed analysis.\\\"}\\n2025-08-02 11:37:45,915 - mcp_server - INFO - Tool Executed: {\\\"timestamp\\\": \\\"2025-08-02T06:07:45.915899\\\", \\\"event\\\": \\\"tool_executed\\\", \\\"tool_name\\\": \\\"scan_codebase\\\", \\\"user_id\\\": \\\"127.0.0.1\\\", \\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"ide_type\\\": \\\"unknown\\\", \\\"execution_time_ms\\\": 22819.079160690308, \\\"request_size\\\": 73, \\\"response_size\\\": 175, \\\"success\\\": true, \\\"arguments\\\": \\\"{\\\\\\\"query\\\\\\\": \\\\\\\"python patterns\\\\\\\"}\\\", \\\"response_preview\\\": \\\"Codebase scan completed. Found 433 patterns. Common folders: ['site-packages', 'annotated_types']. Use specific queries like 'python naming conventions' for detailed analysis.\\\"}\\n2025-08-02 11:37:45,933 - mcp_server.server - INFO - Tool 'scan_codebase' executed successfully\\n2025-08-02 11:37:45,933 - mcp_server.server - INFO - Tool 'scan_codebase' executed successfully\\n2025-08-02 11:41:02,318 - mcp_server - INFO - Tool Executed: {\\\"timestamp\\\": \\\"2025-08-02T06:11:02.317179\\\", \\\"event\\\": \\\"tool_executed\\\", \\\"tool_name\\\": \\\"scan_codebase\\\", \\\"user_id\\\": \\\"127.0.0.1\\\", \\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"ide_type\\\": \\\"unknown\\\", \\\"execution_time_ms\\\": 21206.46858215332, \\\"request_size\\\": 73, \\\"response_size\\\": 175, \\\"success\\\": true, \\\"arguments\\\": \\\"{\\\\\\\"query\\\\\\\": \\\\\\\"python patterns\\\\\\\"}\\\", \\\"response_preview\\\": \\\"Codebase scan completed. Found 433 patterns. Common folders: ['site-packages', 'annotated_types']. Use specific queries like 'python naming conventions' for detailed analysis.\\\"}\\n2025-08-02 11:41:02,318 - mcp_server - INFO - Tool Executed: {\\\"timestamp\\\": \\\"2025-08-02T06:11:02.317179\\\", \\\"event\\\": \\\"tool_executed\\\", \\\"tool_name\\\": \\\"scan_codebase\\\", \\\"user_id\\\": \\\"127.0.0.1\\\", \\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"ide_type\\\": \\\"unknown\\\", \\\"execution_time_ms\\\": 21206.46858215332, \\\"request_size\\\": 73, \\\"response_size\\\": 175, \\\"success\\\": true, \\\"arguments\\\": \\\"{\\\\\\\"query\\\\\\\": \\\\\\\"python patterns\\\\\\\"}\\\", \\\"response_preview\\\": \\\"Codebase scan completed. Found 433 patterns. Common folders: ['site-packages', 'annotated_types']. Use specific queries like 'python naming conventions' for detailed analysis.\\\"}\\n2025-08-02 11:41:02,336 - mcp_server.server - INFO - Tool 'scan_codebase' executed successfully\\n2025-08-02 11:41:02,336 - mcp_server.server - INFO - Tool 'scan_codebase' executed successfully\\n2025-08-02 18:21:32,323 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:21:32,354 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:21:32,626 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:21:32,626 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:21:32,724 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:21:32,725 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:21:43,618 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:21:43,642 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:21:43,708 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:21:43,724 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:21:43,758 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:21:43,773 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:23:52,490 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:23:52,490 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:23:52,553 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:23:52,554 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:23:52,572 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:23:52,573 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:28:34,598 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:28:34,639 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:28:34,683 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:28:34,711 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:28:34,720 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:28:34,741 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:32:16,618 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:32:16,628 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:32:16,701 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:32:16,707 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:32:16,722 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:32:16,726 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:44:11,590 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:44:11,602 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:44:11,697 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:44:11,705 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:44:11,736 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:44:11,745 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:46:36,758 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:46:36,830 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:46:36,875 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:46:36,927 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:46:36,949 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:46:36,989 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:48:52,516 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:48:52,518 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:48:52,621 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:48:52,623 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:48:52,657 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:48:52,661 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:49:52,227 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:49:52,228 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:49:52,320 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:49:52,325 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:49:52,354 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:49:52,355 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:52:36,814 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:52:36,816 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:52:36,931 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:52:36,936 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:52:36,976 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:52:36,983 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:57:17,629 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:57:17,654 - faiss.loader - INFO - Loading faiss with AVX2 support.\\n2025-08-02 18:57:17,759 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:57:17,774 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\\n2025-08-02 18:57:17,810 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\\n2025-08-02 18:57:17,817 - faiss ...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \".env.example\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\.env.example\",\n    \"content\": \"# Development Assistant MCP Server - Environment Configuration\\n\\n# Server Configuration\\nSECRET_KEY=your-super-secret-key-change-this-in-production\\nHOST=0.0.0.0\\nPORT=8000\\nDEBUG=false\\n\\n# Database Configuration\\nREDIS_URL=redis://localhost:6379\\nPOSTGRES_URL=postgresql://user:password@localhost:5432/devassistant\\n\\n# External API Keys\\nOPENAI_API_KEY=your-openai-api-key-here\\nSTRIPE_SECRET_KEY=sk_test_your-stripe-secret-key\\nSTRIPE_WEBHOOK_SECRET=whsec_your-webhook-secret\\n\\n# Tool Configuration\\nT...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"docker-compose.yml\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\docker-compose.yml\",\n    \"content\": \"version: '3.8'\\n\\nservices:\\n  # MCP Server\\n  mcp-server:\\n    build: .\\n    ports:\\n      - \\\"8000:8000\\\"\\n    environment:\\n      - REDIS_URL=redis://redis:6379\\n      - POSTGRES_URL=postgresql://postgres:password@postgres:5432/devassistant\\n      - SECRET_KEY=your-production-secret-key-here\\n    depends_on:\\n      - redis\\n      - postgres\\n    volumes:\\n      - ./logs:/app/logs\\n      - ./data:/app/data\\n    restart: unless-stopped\\n\\n  # Redis for caching and session management\\n  redis:\\n    image: redis:7-alpine\\n    ports:\\n      - \\\"6379:6379\\\"\\n    volumes:\\n      - redis_data:/data\\n    restart: unless-stopped\\n    command: redis-server --appen...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"Dockerfile\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\Dockerfile\",\n    \"content\": \"FROM python:3.11-slim\\n\\n# Set working directory\\nWORKDIR /app\\n\\n# Install system dependencies\\nRUN apt-get update && apt-get install -y \\\\\\n    git \\\\\\n    curl \\\\\\n    && rm -rf /var/lib/apt/lists/*\\n\\n# Copy requirements first for better caching\\nCOPY requirements.txt .\\n\\n# Install Python dependencies\\nRUN pip install --no-cache-dir -r requirements.txt\\n\\n# C...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"langchain_mcp_server.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\langchain_mcp_server.py\",\n    \"content\": \"\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"mcp_sqlite_logger.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\mcp_sqlite_logger.py\",\n    \"content\": \"import logging\\nimport json\\nimport sqlite3\\nfrom datetime import datetime\\nfrom typing import Dict, Any, Optional\\n\\nclass MCPSQLiteLogger:\\n    def __init__(self, db_path='logs/mcp-server.db', log_level=logging.INFO):\\n        self.db_path = db_path\\n        self.logger = logging.getLogger(\\\"mcp_server\\\")\\n        self.setup_logging(log_level)\\n        self._init_db()\\n\\n    def setup_logging(self, log_level):\\n        formatter = logging.Formatter(\\n            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\\n        )\\n        console_handler = logging.StreamHandler()\\n        console_handler.setFormatter(formatter)\\n        file_handler = logging.FileHandler('logs/mcp-server.log')\\n        file_handler.setFormatter(formatter)\\n        self.logger.setLevel(log_level)\\n        self.logger.addHandler(console_handler)\\n        self.logger.addHandler(file_handler)\\n\\n    def _init_db(self):\\n        conn = sqlite3.connect(self.db_path)\\n        c = conn.cursor()\\n        c.execute('''CREATE TABLE IF NOT EXISTS tool_executions (\\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\\n            timestamp TEXT,\\n            event TEXT,\\n            tool_name TEXT,\\n            user_id TEXT,\\n            client_ip TEXT,\\n            ide_type TEXT,\\n            execution_time_ms REAL,\\n            request_size INTEGER,\\n            response_size INTEGER,\\n            success INTEGER,\\n            arguments TEXT,\\n            response_preview TEXT\\n        )''')\\n        c.execute('''CREATE TABLE IF NOT EXISTS errors (\\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\\n            timestamp TEXT,\\n            event TEXT,\\n            error_type TEXT,\\n            error_message TEXT,\\n            user_id TEXT,\\n            client_ip TEXT,\\n            ide_type TEXT,\\n            additional_data TEXT\\n        )''')\\n        conn.commit()\\n        conn.close()\\n\\n    def log_tool_execution(self, tool_name: str, user_id: str, request_data: Dict[str, Any], response_data: Any, execution_time: float, client_info: Dict[str, Any]):\\n        execution_data = {\\n            \\\"timestamp\\\": datetime.utcnow().isoformat(),\\n            \\\"event\\\": \\\"tool_executed\\\",\\n            \\\"tool_name\\\": tool_name,\\n            \\\"user_id\\\": user_id,\\n            \\\"client_ip\\\": client_info.get(\\\"client_ip\\\"),\\n            \\\"ide_type\\\": self.detect_ide(client_info.get(\\\"user_agent\\\", \\\"\\\")),\\n            \\\"execution_time_ms\\\": execution_time * 1000,\\n            \\\"request_size\\\": len(str(request_data)),\\n            \\\"response_size\\\": len(str(response_data)),\\n            \\\"success\\\": True,\\n            \\\"arguments\\\": json.dumps(request_data.get(\\\"arguments\\\", {})),\\n            \\\"response_preview\\\": str(response_data)[:200] + \\\"...\\\" if len(str(response_data)) > 200 else str(response_data)\\n        }\\n        ...\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"MCPSQLiteLogger\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\mcp_sqlite_logger.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"__init__\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\mcp_sqlite_logger.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"setup_logging\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\mcp_sqlite_logger.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"_init_db\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\mcp_sqlite_logger.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"log_tool_execution\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\mcp_sqlite_logger.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"log_error\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\mcp_sqlite_logger.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"detect_ide\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\mcp_sqlite_logger.py\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"mcp_tools.http\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\mcp_tools.http\",\n    \"content\": \"### List all tools\\nGET http://localhost:8000/tools\\n\\n### Execute a tool (example: scan_codebase)\\nPOST http://localhost:8000/tools...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"monitoring.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\",\n    \"content\": \"\\\"\\\"\\\"\\nEnhanced logging and monitoring for MCP server\\nProvides detailed insights into tool usage, client connections, and performance\\n\\\"\\\"\\\"\\nimport logging\\nimport json\\nimport time\\nfrom datetime import datetime\\nfrom typing import Dict, Any, Optional, List\\nfrom functools import wraps\\nimport redis\\nfrom fastapi import Request\\nimport asyncio\\n\\nclass MCPLogger:\\n    def __init__(self, redis_client, log_level=logging.INFO):\\n        self.redis_client = redis_client\\n        self.logger = logging.getLogger(\\\"mcp_server\\\")\\n        self.setup_logging(log_level)\\n        \\n    def setup_logging(self, log_level):\\n        \\\"\\\"\\\"Configure detailed logging\\\"\\\"\\\"\\n        formatter = logging.Formatter(\\n            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\\n        )\\n        \\n        # Console handler\\n        console_handler = logging.StreamHandler()\\n        console_handler.setFormatter(formatter)\\n        \\n        # File handler\\n        file_handler = logging.FileHandler('logs/mcp-server.log')\\n        file_handler.setFormatter(formatter)\\n        \\n        self.logger.setLevel(log_level)\\n        self.logger.addHandler(console_handler)\\n        self.logger.addHandler(file_handler)\\n    \\n    def log_connection(self, client_info: Dict[str, Any]):\\n        \\\"\\\"\\\"Log client connection details\\\"\\\"\\\"\\n        connection_data = {\\n            \\\"timestamp\\\": datetime.utcnow().isoformat(),\\n            \\\"event\\\": \\\"client_connected\\\",\\n            \\\"client_ip\\\": client_info.get(\\\"client_ip\\\"),\\n            \\\"user_agent\\\": client_info.get(\\\"user_agent\\\"),\\n            \\\"ide_type\\\": self.detect_ide(client_info.get(\\\"user_agent\\\", \\\"\\\")),\\n            \\\"user_id\\\": client_info.get(\\\"user_id\\\"),\\n            \\\"connection_type\\\": client_info.get(\\\"connection_type\\\")  # websocket/rest\\n        }\\n        \\n        # Log to file\\n        self.logger.info(f\\\"Client Connected: {json.dumps(connection_data)}\\\")\\n        \\n        # Store in Redis for analytics\\n        self.redis_client.lpush(\\\"mcp:connections\\\", json.dumps(connection_data))\\n        self.redis_client.ltrim(\\\"mcp:connections\\\", 0, 1000)  # Keep last 1000 connections\\n    \\n    def log_tool_execution(self, tool_name: str, user_id: str, \\n                          request_data: Dict[str, Any], \\n                          response_data: Any, execution_time: float,\\n                          client_info: Dict[str, Any]):\\n        \\\"\\\"\\\"Log detailed tool execution\\\"\\\"\\\"\\n        execution_data = {\\n            \\\"timestamp\\\": datetime.utcnow().isoformat(),\\n            \\\"event\\\": \\\"tool_executed\\\",\\n            \\\"tool_name\\\": tool_name,\\n            \\\"user_id\\\": user_id,\\n            \\\"client_ip\\\": client_info.get(\\\"client_ip\\\"),\\n            \\\"ide_type\\\": self.detect_ide(client_info.get(\\\"user_agent\\\", \\\"\\\")),\\n            \\\"execution_time_ms\\\": execution_time * 1000,\\n            \\\"request_size\\\": len(str(request_data)),\\n            \\\"response_size\\\": len(str(response_data)),\\n            \\\"success\\\": True,\\n            \\\"arguments\\\": request_data.get(\\\"arguments\\\", {}),\\n            \\\"response_preview\\\": str(response_data)[:200] + \\\"...\\\" if len(str(response_data)) > 200 else str(response_data)\\n        }\\n        \\n        # Log to file\\n        self.logger.info(f\\\"Tool Executed: {json.dumps(execution_data)}\\\")\\n        \\n        # Store in Redis for analytics\\n        self.redis_client.lpush(\\\"mcp:executions\\\", json.dumps(execution_data))\\n        self.redis_client.ltrim(\\\"mcp:executions\\\", 0, 10000)  # Keep last 10000 executions\\n        \\n        # Update tool usage statistics\\n        today = datetime.utcnow().strftime(\\\"%Y-%m-%d\\\")\\n        self.redis_client.hincrby(f\\\"mcp:stats:{today}\\\", f\\\"tool:{tool_name}\\\", 1)\\n        self.redis_client.hincrby(f\\\"mcp:stats:{today}\\\", f\\\"user:{user_id}\\\", 1)\\n        self.redis_client.hincrby(f\\\"mcp:stats:{today}\\\", \\\"total_executions\\\", 1)\\n    \\n    def log_error(self, error_type: str, error_message: str, \\n                 user_id: str, client_info: Dict[str, Any], \\n                 additional_data: Dict[str, Any] = None):\\n        \\\"\\\"\\\"Log errors with context\\\"\\\"\\\"\\n        error_data = {\\n            \\\"timestamp\\\": datetime.utcnow().isoformat(),\\n            \\\"event\\\": \\\"error\\\",\\n            \\\"error_type\\\": error_type,\\n            \\\"error_message\\\": error_message,\\n            \\\"user_id\\\": user_id,\\n            \\\"client_ip\\\": client_info.get(\\\"client_ip\\\"),\\n      ...\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"MCPLogger\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"MCPAnalytics\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"track_execution\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"__init__\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"setup_logging\",\n    \"doc\": \"Configure detailed logging\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"log_connection\",\n    \"doc\": \"Log client connection details\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"log_tool_execution\",\n    \"doc\": \"Log detailed tool execution\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"log_error\",\n    \"doc\": \"Log errors with context\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"detect_ide\",\n    \"doc\": \"Detect IDE type from user agent\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"__init__\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_usage_stats\",\n    \"doc\": \"Get usage statistics for a specific date\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_active_connections\",\n    \"doc\": \"Get recent active connections\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_recent_executions\",\n    \"doc\": \"Get recent tool executions\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_error_summary\",\n    \"doc\": \"Get recent errors\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"decorator\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\monitoring.py\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"README.md\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\README.md\",\n    \"content\": \"# MCP Development Assistant Server\\n\\nA Model Context Protocol (MCP) server that provides development assistance tools for teams, including codebase analysis, git conventions, JIRA patterns, and team collaboration features.\\n\\n## \\ud83d\\ude80 Features\\n\\n- **Codebase Analysis**: Pattern recognition, naming conventions, folder structure analysis\\n- **Git Integration**: Commit convention analysis, contributor patterns\\n- **JIRA Integration**: Ticket pattern analysis, development insights\\n- **Team Collaboration**: Centralized development intelligence\\n- **Subscription Management**: Tiered access control with usage tracking\\n- **MCP Protocol**: Native VS Code Copilot integration\\n\\n## \\ud83d\\udcc1 Architecture\\n\\n```\\nmcp-server/\\n\\u251c\\u2500\\u2500 server.py              # FastAPI MCP server\\n\\u251c\\u2500\\u2500 auth/                  # Authentication & subscription management\\n\\u2502   \\u2514\\u2500\\u2500 manager.py\\n\\u251c\\u2500\\u2500 core/                  # Tool registry and routing\\n\\u2502   \\u2514\\u2500\\u2500 tool_registry.py\\n\\u251c\\u2500\\u2500 config/                # Configuration management\\n\\u2502   \\u2514\\u2500\\u2500 settings.py\\n\\u251c\\u2500\\u2500 docker/                # Containerization files\\n\\u251c\\u2500\\u2500 deploy/                # Cloud deployment scripts\\n\\u2502   \\u2514\\u2500\\u2500 deploy-aws.sh\\n\\u2514\\u2500\\u2500 .env.example          # Environment configuration template\\n```\\n\\n## \\ud83d\\udd27 Local Development Setup\\n\\n### Prerequisites\\n\\n- Python 3.11+\\n- Redis server\\n- PostgreSQL (optional, SQLite used by default)\\n- Git\\n\\n### Step 1: Clone and Setup\\n\\n```bash\\ncd mcp-server\\ncp .env.example .env\\n```\\n\\n### Step 2: Configure Environment\\n\\nEdit `.env` file with your settings:\\n\\n```bash\\n# Required\\nSECRET_KEY=your-secret-key-here\\nOPENAI_API_KEY=your-openai-api-key\\n\\n# Optional (uses defaults)\\nREDIS_URL=redis://localhost:6379\\nHOST=0.0.0.0\\nPORT=8000\\n```\\n\\n### Step 3: Install Dependencies\\n\\n```bash\\npip install -r requirements.txt\\n```\\n\\n### Step 4: Start Redis (Required)\\n\\n```bash\\n# Using Docker\\ndocker run -d -p 6379:6379 redis:alpine\\n\\n# Or install locally\\n# Windows: Download from Redis website\\n# macOS: brew install redis && brew services start redis\\n# Linux: sudo apt install redis-server && sudo systemctl start redis\\n```\\n\\n### Step 5: Run the Server\\n\\n```bash\\npython server.py\\n```\\n\\nServer will be available at:\\n\\n- **REST API**: <http://localhost:8000>\\n- **MCP WebSocket**: ws://localhost:8000/mcp\\n- **Health Check**: <http://localhost:8000/>\\n\\n## \\ud83d\\udc33 Docker Local Deployment\\n\\n### Single Container\\n\\n```bash\\n# Build and run\\ndocker build -t mcp-dev-assistant .\\ndocker run -p 8000:8000 -e OPENAI_API_KEY=your-key mcp-dev-assistant\\n```\\n\\n### Full Stack with Docker Compose\\n\\n```bash\\n# Start all services (Redis, PostgreSQL, MCP Server)\\ndocker-compose up -d\\n\\n# View logs\\ndocker-compose logs -f mcp-server\\n\\n# Stop all services\\ndocker-compose down\\n```\\n\\nServices available:\\n\\n- **MCP Server**: <http://localhost:8000>\\n- **Redis**: localhost:6379\\n- **PostgreSQL**: localhost:5432\\n\\n## \\u2601\\ufe0f Cloud Deployment\\n\\n### AWS ECS/Fargate Deployment\\n\\n#### Prerequisites\\n\\n- AWS CLI configured\\n- Docker installed\\n- ECR repository access\\n\\n#### Automated Deployment\\n\\n```bash\\n# Make script executable\\nchmod +x deploy/deploy-aws.sh\\n\\n# Deploy to AWS\\n./deploy/deploy-aws.sh\\n```\\n\\n#### Manual AWS Setup\\n\\n1. **Create ECR Repository**:\\n\\n```bash\\naws ecr create-repository --repository-name mcp-dev-assistant --region us-east-1\\n```\\n\\n2. **Create ECS Cluster**:\\n\\n```bash\\naws ecs create-cluster --cluster-name mcp-dev-assistant\\n```\\n\\n3. **Deploy Infrastructure** (recommended: use CloudFormation):\\n\\n```bash\\n# Create VPC, subnets, load balancer, RDS, ElastiCache\\n# See deploy/cloudformation-template.yaml (create if needed)\\n```\\n\\n4. **Deploy Application**:\\n\\n```bash\\n./deploy/deploy-aws.sh\\n```\\n\\n### Google Cloud Run Deployment\\n\\n```bash\\n# Build and deploy\\ngcloud run deploy mcp-dev-assistant \\\\\\n  --image gcr.io/PROJECT-ID/mcp-dev-assistant \\\\\\n  --platform managed \\\\\\n  --region us-central1 \\\\\\n  --allow-unauthenticated \\\\\\n  --port 8000 \\\\\\n  --set-env-vars OPENAI_API_KEY=your-key\\n```\\n\\n### Azure Container Instances\\n\\n```bash\\n# Create resource group\\naz group create --name mcp-dev-assistant --location eastus\\n\\n# Deploy container\\naz container create \\\\\\n  --resource-group mcp-dev-assistant \\\\\\n  --name mcp-server \\\\\\n  --image your-registry/mcp-dev-assistant \\\\\\n  --ports 8000 \\\\\\n  --environment-variables OPENAI_API_KEY=your-key\\n```\\n\\n## \\ud83d\\udd0c VS Code Integration\\n\\n### Method 1: MC...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"requirements.txt\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\requirements.txt\",\n    \"content\": \"fastapi>=0.104.1\\nuvicorn>=0.24.0\\nwebsockets>=12.0\\npydantic>=2.5.0\\nasyncio-mqtt>=0.16.1\\npython-jose[cryptography]>=3.3.0\\npasslib[bcrypt]>=1.7.4\\nredis>=5.0.0\\npsycopg2-binary>=2.9.9\\n...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"server.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\server.py\",\n    \"content\": \"\\\"\\\"\\\"\\nMain MCP Server implementation with Enhanced Monitoring\\nHandles MCP protocol communication and routes requests to tools\\nIncludes detailed logging, analytics, and verification features\\n\\\"\\\"\\\"\\nimport asyncio\\nimport json\\nimport logging\\nimport time\\nfrom datetime import datetime\\nfrom typing import Dict, Any, List, Optional\\nfrom fastapi import FastAPI, WebSocket, HTTPException, Depends, Header, Request\\nfrom fastapi.middleware.cors import CORSMiddleware\\nfrom pydantic import BaseModel\\nimport uvicorn\\n# import redis\\n\\nfrom core.tool_registry import get_tool_registry\\nfrom mcp_server.mcp_sqlite_logger import MCPSQLiteLogger\\n# from monitoring import MCPLogger, MCPAnalytics, track_execution\\n\\n# Configure enhanced logging\\nlogging.basicConfig(\\n    level=logging.INFO,\\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\\n    handlers=[\\n        logging.FileHandler('logs/mcp-server.log'),\\n        logging.StreamHandler()\\n    ]\\n)\\nlogger = logging.getLogger(__name__)\\n\\n# Initialize FastAPI app\\napp = FastAPI(title=\\\"Development Assistant MCP Server\\\", version=\\\"1.0.0\\\")\\n\\n# Add CORS middleware\\napp.add_middleware(\\n    CORSMiddleware,\\n    allow_origins=[\\\"*\\\"],\\n    allow_credentials=True,\\n    allow_methods=[\\\"*\\\"],\\n    allow_headers=[\\\"*\\\"],\\n)\\n\\n# Initialize managers with monitoring\\n# redis_client = redis.from_url(\\\"redis://localhost:6379\\\")\\ntool_registry = get_tool_registry()\\n\\n# Initialize monitoring\\nmcp_logger = MCPSQLiteLogger()\\n# mcp_analytics = MCPAnalytics(redis_client)\\n\\n# Pydantic models\\nclass MCPRequest(BaseModel):\\n    method: str\\n    params: Dict[str, Any]\\n    id: Optional[str] = None\\n\\nclass MCPResponse(BaseModel):\\n    result: Optional[Dict[str, Any]] = None\\n    error: Optional[Dict[str, Any]] = None\\n    id: Optional[str] = None\\n\\nclass ToolExecutionRequest(BaseModel):\\n    tool_name: str\\n    arguments: Dict[str, Any]\\n\\n# MCP Protocol handlers\\nclass MCPHandler:\\n    def __init__(self):\\n        self.handlers = {\\n            \\\"tools/list\\\": self.list_tools,\\n            \\\"tools/call\\\": self.call_tool,\\n            \\\"resources/list\\\": self.list_resources,\\n            \\\"prompts/list\\\": self.list_prompts,\\n        }\\n    \\n    async def handle_request(self, request: MCPRequest) -> MCPResponse:\\n        \\\"\\\"\\\"Handle MCP request\\\"\\\"\\\"\\n        try:\\n            if request.method in self.handlers:\\n                result = await self.handlers[request.method](request.params)\\n                return MCPResponse(result=result, id=request.id)\\n            else:\\n                error = {\\\"code\\\": -32601, \\\"message\\\": f\\\"Method not found: {request.method}\\\"}\\n                return MCPResponse(error=error, id=request.id)\\n        \\n        except Exception as e:\\n            logger.error(f\\\"Error handling request: {e}\\\")\\n            error = {\\\"code\\\": -32603, \\\"message\\\": f\\\"Internal error: {str(e)}\\\"}\\n            return MCPResponse(error=error, id=request.id)\\n    \\n    async def list_tools(self, params: Dict[str, Any]) -> Dict[str, Any]:\\n        \\\"\\\"\\\"List available tools\\\"\\\"\\\"\\n        tools = tool_registry.get_tool_list()\\n        \\n        return {\\\"tools\\\": tools}\\n    \\n    async def call_tool(self, params: Dict[str, Any]) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Execute a tool\\\"\\\"\\\"\\n        tool_name = params.get(\\\"name\\\")\\n        arguments = params.get(\\\"arguments\\\", {})\\n        \\n        if not tool_name:\\n            raise ValueError(\\\"Tool name is required\\\")\\n        \\n        try:\\n            result = tool_registry.execute_tool(tool_name, arguments)\\n            \\n            return {\\n                \\\"content\\\": [\\n                    {\\n                        \\\"type\\\": \\\"text\\\",\\n                        \\\"text\\\": str(result)\\n                    }\\n                ]\\n            }\\n        \\n        except Exception as e:\\n            logger.error(f\\\"Tool execution error: {e}\\\")\\n            raise ValueError(f\\\"Tool execution failed: {str(e)}\\\")\\n    \\n    async def list_resources(self, params: Dict[str, Any]) -> Dict[str, Any]:\\n        \\\"\\\"\\\"List available resources\\\"\\\"\\\"\\n        return {\\\"resources\\\": []}\\n    \\n    async def list_prompts(self, params: Dict[str, Any]) -> Dict[str, Any]:\\n        \\\"\\\"\\\"List available prompts\\\"\\\"\\\"\\n        return {\\\"prompts\\\": []}\\n\\n# Initialize MCP handler\\nmcp_handler = MCPHandler()\\n\\n# REST API endpoints\\n@app.get(\\\"/\\\")\\nasync def root():\\n    \\\"\\\"\\\"Health check endpoint\\\"\\\"\\\"\\n    return {\\\"status\\\": \\\"healthy\\\", \\\"service\\\": \\\"Development Assistant MCP Server\\\"}\\n\\n@app.get(\\\"/tools\\\")\\nasync def list_tools_rest():\\n    \\\"\\\"\\\"REST endpoint to list tools\\\"\\\"\\\"\\n    tools = tool_registry.g...\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"MCPRequest\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\server.py\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"MCPResponse\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\server.py\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"ToolExecutionRequest\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\server.py\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"MCPHandler\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\server.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"__init__\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\server.py\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"start-server.bat\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\start-server.bat\",\n    \"content\": \"@echo off\\nREM Start MCP Server with Enhanced Monitoring (Windows version)\\nREM This script starts the server and provides instructions for testing\\n\\necho \\ud83d\\ude80 Starting MCP Development Assistant Server with Enhanced Monitoring\\necho ==============================================================\\n\\nREM Create necessary directories\\nif not exist \\\"logs\\\" mkdir logs\\nif not exist \\\"data\\\" mkdir data\\n\\nREM Check if Redis is running\\ntasklist /FI \\\"IMAGENAME eq redis-server.exe\\\" 2>NUL | find /I /N \\\"redis-server.exe\\\">NUL\\nif \\\"%ERRORLEVEL%\\\"==\\\"1\\\" (\\n    echo \\u26a0\\ufe0f  Redis not detected. Please start Redis manually:\\n    echo    - Install Redis for Windows\\n    echo    - Or use Docker: docker run -d -p 6379:6379 redis:alpine\\n    echo    - Or use WSL with Redis\\n    pause\\n    exit /b 1\\n)\\n\\necho \\u2705 Redis is running\\n\\nREM Activate virtual environment if it exists\\nif exist \\\"venv\\\\Scripts\\\\activate.bat\\\" (\\n    call venv\\\\Scripts\\\\activate.bat\\n) else (\\n    echo \\ud83d\\udce6 Setting up virtual environment...\\n    python -m venv venv\\n    call venv\\\\Scripts\\\\activate.bat\\n    pip install -r requirements.txt\\n)\\n\\necho \\ud83d\\udcca Starting MCP Server with monitoring...\\necho    - REST API: http://localhost:8000...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"start-server.sh\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\start-server.sh\",\n    \"content\": \"#!/bin/bash\\n# Start MCP Server with Enhanced Monitoring\\n# This script starts the server and provides instructions for testing\\n\\necho \\\"\\ud83d\\ude80 Starting MCP Development Assistant Server with Enhanced Monitoring\\\"\\necho \\\"==============================================================\\\"\\n\\n# Create necessary directories\\nmkdir -p logs\\nmkdir -p data\\n\\n# Check if Redis is running\\nif ! pgrep -x \\\"redis-server\\\" > /dev/null; then\\n    echo \\\"\\u26a0\\ufe0f  Redis not detected. Starting Redis...\\\"\\n    # For Windows with Redis installed\\n    if command -v redis-server &> /dev/null; then\\n        redis-server &\\n    else\\n        echo \\\"\\u274c Redis not found. Please install and start Redis first:\\\"\\n        echo \\\"   - Windows: Download from https://redis.io/download\\\"\\n        echo \\\"   - Or use Docker: docker run -d -p 6379:6379 redis:alpine\\\"\\n        exit 1\\n    fi\\nfi\\n\\necho \\\"\\u2705 Redis is running\\\"\\n\\n# Install dependencies if needed\\nif [ ! -d \\\"venv\\\" ]; then\\n    echo \\\"\\ud83d\\udce6 Setting up virtual environment...\\\"\\n    python -m venv venv\\n    source venv/bin/activate  # For Windows: venv\\\\Scripts\\\\activate\\n    pip install -r requirements.txt\\nelse\\n    source venv/bin/activate  # For Windows: venv\\\\Scripts\\\\activate\\nfi\\n\\necho \\\"\\ud83d\\udcca Starting MCP Server with monitoring...\\\"\\necho \\\"   - REST API: http://localhost:8000\\\"\\necho \\\"   - WebSocket: ws://localhost:8000/...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"test_verification.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\test_verification.py\",\n    \"content\": \"\\\"\\\"\\\"\\nQuick verification that MCP server tools can be accessed locally\\n\\\"\\\"\\\"\\nimport requests\\nimport json\\n\\ndef test_local_access():\\n    base_url = \\\"http://localhost:8000\\\"\\n    api_key = \\\"dev-test-key\\\"\\n    headers = {\\\"X-API-Key\\\": api_key}\\n    \\n    print(\\\"\\ud83d\\udd0d Testing local MCP server access...\\\")\\n    \\n    # Test 1: Basic connectivity\\n    try:\\n        response = requests.get(f\\\"{base_url}/\\\")\\n        print(f\\\"\\u2705 Server reachable: {response.json()}\\\")\\n    except Exception as e:\\n        print(f\\\"\\u274c Server not running. Start with: python server.py\\\")\\n        return False\\n    \\n    # Test 2: List tools\\n    try:\\n        response = requests.get(f\\\"{base_url}/tools\\\", headers=headers)\\n        tools_json = response...\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"test_local_access\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\test_verification.py\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"__init__.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\__init__.py\",\n    \"content\": \"# Makes mcp_server...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"tool_registry.py\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\core\\\\tool_registry.py\",\n    \"content\": \"\\\"\\\"\\\"\\nTool registry and routing for MCP server\\nMaps tool names to implementations and handles tool discovery\\n\\\"\\\"\\\"\\nimport importlib\\nimport json\\nfrom typing import Dict, List, Any, Optional, Callable\\nfrom pathlib import Path\\n\\n# Refactored ToolRegistry to dynamically load tools.json and transform its structure\\nclass ToolRegistry:\\n    def __init__(self, tools_config_path: str = None):\\n        self.tools = {}\\n        self.tool_functions = {}\\n\\n        if tools_config_path:\\n            self.load_tools_from_config(tools_config_path)\\n        else:\\n            raise ValueError(\\\"tools.json configuration file is required\\\")\\n\\n    def load_tools_from_config(self, config_path: str):\\n        \\\"\\\"\\\"Load tools from JSON configuration file\\\"\\\"\\\"\\n        with open(config_path, 'r') as f:\\n            tools_config = json.load(f)\\n\\n        for tool_config in tools_config:\\n            self.register_tool_from_config(tool_config)\\n\\n    def register_tool_from_config(self, tool_config: Dict[str, Any]):\\n        \\\"\\\"\\\"Register a tool from configuration\\\"\\\"\\\"\\n        tool_name = tool_config[\\\"name\\\"]\\n        module_path = tool_config[\\\"module\\\"]\\n        description = tool_config.get(\\\"description\\\", \\\"\\\")\\n        args_schema = tool_config.get(\\\"args_schema\\\", {})\\n\\n        # Import the module and get the function\\n        try:\\n            # Add parent directory to Python path for imports\\n            import sys\\n            parent_dir = str(Path(__file__).parent.parent.parent)\\n            if parent_dir not in sys.path:\\n                sys.path.insert(0, parent_dir)\\n            \\n            module = importlib.import_module(module_path)\\n            tool_function = getattr(module, tool_name)\\n            self.register_tool(tool...\"\n  },\n  {\n    \"type\": \"class\",\n    \"name\": \"ToolRegistry\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_tool_registry\",\n    \"doc\": \"Get global tool registry instance\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"__init__\",\n    \"doc\": null,\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"load_tools_from_config\",\n    \"doc\": \"Load tools from JSON configuration file\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"register_tool_from_config\",\n    \"doc\": \"Register a tool from configuration\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"register_tool\",\n    \"doc\": \"Register a tool with the registry\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_tool_list\",\n    \"doc\": \"Get list of available tools\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"get_tool\",\n    \"doc\": \"Get tool definition by name\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"function\",\n    \"name\": \"execute_tool\",\n    \"doc\": \"Execute a tool with given arguments\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\core\\\\tool_registry.py\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"deploy-aws.sh\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\deploy\\\\deploy-aws.sh\",\n    \"content\": \"#!/bin/bash\\n\\n# AWS ECS Deployment Script for MCP Development Assistant Server\\n\\nset -e\\n\\n# Configuration\\nAWS_REGION=\\\"us-east-1\\\"\\nCLUSTER_NAME=\\\"mcp-dev-assistant\\\"\\nSERVICE_NAME=\\\"mcp-server\\\"\\nTASK_FAMILY=\\\"mcp-dev-assistant-task\\\"\\nECR_REPOSITORY=\\\"mcp-dev-assistant\\\"\\nIMAGE_TAG=\\\"latest\\\"\\n\\necho \\\"Starting deployment of MCP Development Assistant Server...\\\"\\n\\n# Step 1: Build and push Docker image to ECR\\necho \\\"Building Docker image...\\\"\\ndocker build -t $ECR_REPOSITORY:$IMAGE_TAG .\\n\\n# Get ECR login token\\necho \\\"Logging into ECR...\\\"\\naws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $(aws sts get-caller-identity --query Account --output text).dkr.ecr.$AWS_REGION.amazonaws.com\\n\\n# Create ECR repository if it doesn't exist\\naws ecr describe-repositories --repository-names $ECR_REPOSITORY --region $AWS_REGION 2>/dev/null || \\\\\\naws ecr create-repository --repository-name $ECR_REPOSITORY --region $AWS_REGION\\n\\n# Tag and push image\\nECR_URI=$(aws sts get-caller-identity --query Account --output text).dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPOSITORY:$IMAGE_TAG\\ndocker tag $ECR_REPOSITORY:$IMAGE_TAG $ECR_URI\\ndocker push $ECR_URI\\n\\n# Step 2: Update ECS task definition\\necho \\\"Updating ECS task definition...\\\"\\ncat > task-definition.json << EOF\\n{\\n  \\\"family\\\": \\\"$TASK_FAMILY\\\",\\n  \\\"networkMode\\\": \\\"awsvpc\\\",\\n  \\\"requiresCompatibilities\\\": [\\\"FARGATE\\\"],\\n  \\\"cpu\\\": \\\"1024\\\",\\n  \\\"memory\\\": \\\"2048\\\",\\n  \\\"executionRoleArn\\\": \\\"arn:aws:iam::$(aws sts get-caller-identity --query Account --output text):role/ecsTaskExecutionRole\\\",\\n  \\\"taskRoleArn\\\": \\\"arn:aws:iam::$(aws sts get-caller-identity --query Account --output text):role/ecsTaskRole\\\",\\n  \\\"containerDefinitions\\\": [\\n    {\\n      \\\"name\\\": \\\"mcp-server\\\",\\n      \\\"image\\\": \\\"$ECR_URI\\\",\\n      \\\"portMappings\\\": [\\n        {\\n          \\\"containerPort\\\": 8000,\\n          \\\"protocol\\\": \\\"tcp\\\"\\n        }\\n      ],\\n      \\\"environment\\\": [\\n        {\\n          \\\"name\\\": \\\"REDIS_URL\\\",\\n          \\\"value\\\": \\\"redis://mcp-redis.cache.amazonaws.com:6379\\\"\\n        },\\n        {\\n          \\\"name\\\": \\\"POSTGRES_URL\\\",\\n          \\\"value\\\": \\\"po...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"mcp-server.log\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\mcp_server\\\\logs\\\\mcp-server.log\",\n    \"content\": \"2025-08-02 01:01:02,739 - mcp_server - ERROR - Error: {\\\"timestamp\\\": \\\"2025-08-01T19:31:02.739187\\\", \\\"event\\\": \\\"error\\\", \\\"error_type\\\": \\\"tool_execution_error\\\", \\\"error_message\\\": \\\"Tool 'scan_codebase' not found\\\", \\\"user_id\\\": {\\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"user_agent\\\": \\\"python-requests/2.32.3\\\", \\\"connection_type\\\": \\\"rest\\\"}, \\\"client_ip\\\": null, \\\"ide_type\\\": \\\"unknown\\\", \\\"additional_data\\\": {}}\\n2025-08-02 01:01:02,739 - mcp_server - ERROR - Error: {\\\"timestamp\\\": \\\"2025-08-01T19:31:02.739187\\\", \\\"event\\\": \\\"error\\\", \\\"error_type\\\": \\\"tool_execution_error\\\", \\\"error_message\\\": \\\"Tool 'scan_codebase' not found\\\", \\\"user_id\\\": {\\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"user_agent\\\": \\\"python-requests/2.32.3\\\", \\\"connection_type\\\": \\\"rest\\\"}, \\\"client_ip\\\": null, \\\"ide_type\\\": \\\"unknown\\\", \\\"additional_data\\\": {}}\\n2025-08-02 01:01:02,739 - mcp_server - ERROR - Error: {\\\"timestamp\\\": \\\"2025-08-01T19:31:02.739187\\\", \\\"event\\\": \\\"error\\\", \\\"error_type\\\": \\\"tool_execution_error\\\", \\\"error_message\\\": \\\"Tool 'scan_codebase' not found\\\", \\\"user_id\\\": {\\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"user_agent\\\": \\\"python-requests/2.32.3\\\", \\\"connection_type\\\": \\\"rest\\\"}, \\\"client_ip\\\": null, \\\"ide_type\\\": \\\"unknown\\\", \\\"additional_data\\\": {}}\\n2025-08-02 01:09:20,818 - mcp_server - ERROR - Error: {\\\"timestamp\\\": \\\"2025-08-01T19:39:20.818130\\\", \\\"event\\\": \\\"error\\\", \\\"error_type\\\": \\\"tool_execution_error\\\", \\\"error_message\\\": \\\"Tool 'scan_codebase' not found\\\", \\\"user_id\\\": {\\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"user_agent\\\": \\\"python-requests/2.32.3\\\", \\\"connection_type\\\": \\\"rest\\\"}, \\\"client_ip\\\": null, \\\"ide_type\\\": \\\"unknown\\\", \\\"additional_data\\\": {}}\\n2025-08-02 01:09:20,818 - mcp_server - ERROR - Error: {\\\"timestamp\\\": \\\"2025-08-01T19:39:20.818130\\\", \\\"event\\\": \\\"error\\\", \\\"error_type\\\": \\\"tool_execution_error\\\", \\\"error_message\\\": \\\"Tool 'scan_codebase' not found\\\", \\\"user_id\\\": {\\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"user_agent\\\": \\\"python-requests/2.32.3\\\", \\\"connection_type\\\": \\\"rest\\\"}, \\\"client_ip\\\": null, \\\"ide_type\\\": \\\"unknown\\\", \\\"additional_data\\\": {}}\\n2025-08-02 01:09:20,818 - mcp_server - ERROR - Error: {\\\"timestamp\\\": \\\"2025-08-01T19:39:20.818130\\\", \\\"event\\\": \\\"error\\\", \\\"error_type\\\": \\\"tool_execution_error\\\", \\\"error_message\\\": \\\"Tool 'scan_codebase' not found\\\", \\\"user_id\\\": {\\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"user_agent\\\": \\\"python-requests/2.32.3\\\", \\\"connection_type\\\": \\\"rest\\\"}, \\\"client_ip\\\": null, \\\"ide_type\\\": \\\"unknown\\\", \\\"additional_data\\\": {}}\\n2025-08-02 01:24:32,819 - mcp_server - ERROR - Error: {\\\"timestamp\\\": \\\"2025-08-01T19:54:32.818256\\\", \\\"event\\\": \\\"error\\\", \\\"error_type\\\": \\\"tool_execution_error\\\", \\\"error_message\\\": \\\"MCPLogger.log_tool_execution() missing 1 required positional argument: 'user_id'\\\", \\\"user_id\\\": {\\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"user_agent\\\": \\\"python-requests/2.32.3\\\", \\\"connection_type\\\": \\\"rest\\\"}, \\\"client_ip\\\": null, \\\"ide_type\\\": \\\"unknown\\\", \\\"additional_data\\\": {}}\\n2025-08-02 01:24:32,819 - mcp_server - ERROR - Error: {\\\"timestamp\\\": \\\"2025-08-01T19:54:32.818256\\\", \\\"event\\\": \\\"error\\\", \\\"error_type\\\": \\\"tool_execution_error\\\", \\\"error_message\\\": \\\"MCPLogger.log_tool_execution() missing 1 required positional argument: 'user_id'\\\", \\\"user_id\\\": {\\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"user_agent\\\": \\\"python-requests/2.32.3\\\", \\\"connection_type\\\": \\\"rest\\\"}, \\\"client_ip\\\": null, \\\"ide_type\\\": \\\"unknown\\\", \\\"additional_data\\\": {}}\\n2025-08-02 01:24:32,819 - mcp_server - ERROR - Error: {\\\"timestamp\\\": \\\"2025-08-01T19:54:32.818256\\\", \\\"event\\\": \\\"error\\\", \\\"error_type\\\": \\\"tool_execution_error\\\", \\\"error_message\\\": \\\"MCPLogger.log_tool_execution() missing 1 required positional argument: 'user_id'\\\", \\\"user_id\\\": {\\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"user_agent\\\": \\\"python-requests/2.32.3\\\", \\\"connection_type\\\": \\\"rest\\\"}, \\\"client_ip\\\": null, \\\"ide_type\\\": \\\"unknown\\\", \\\"additional_data\\\": {}}\\n2025-08-02 01:38:27,964 - mcp_server - ERROR - Error: {\\\"timestamp\\\": \\\"2025-08-01T20:08:27.964511\\\", \\\"event\\\": \\\"error\\\", \\\"error_type\\\": \\\"tool_execution_error\\\", \\\"error_message\\\": \\\"MCPSQLiteLogger.log_tool_execution() missing 1 required positional argument: 'user_id'\\\", \\\"user_id\\\": {\\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"user_agent\\\": \\\"python-requests/2.32.3\\\", \\\"connection_type\\\": \\\"rest\\\"}, \\\"client_ip\\\": null, \\\"ide_type\\\": \\\"unknown\\\", \\\"additional_data\\\": \\\"{}\\\"}\\n2025-08-02 01:38:27,964 - mcp_server - ERROR - Error: {\\\"timestamp\\\": \\\"2025-08-01T20:08:27.964511\\\", \\\"event\\\": \\\"error\\\", \\\"error_type\\\": \\\"tool_execution_error\\\", \\\"error_message\\\": \\\"MCPSQLiteLogger.log_tool_execution() missing 1 required positional argument: 'user_id'\\\", \\\"user_id\\\": {\\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"user_agent\\\": \\\"python-requests/2.32.3\\\", \\\"connection_type\\\": \\\"rest\\\"}, \\\"client_ip\\\": null, \\\"ide_type\\\": \\\"unknown\\\", \\\"additional_data\\\": \\\"{}\\\"}\\n2025-08-02 01:38:27,964 - mcp_server - ERROR - Error: {\\\"timestamp\\\": \\\"2025-08-01T20:08:27.964511\\\", \\\"event\\\": \\\"error\\\", \\\"error_type\\\": \\\"tool_execution_error\\\", \\\"error_message\\\": \\\"MCPSQLiteLogger.log_tool_execution() missing 1 required positional argument: 'user_id'\\\", \\\"user_id\\\": {\\\"client_ip\\\": \\\"127.0.0.1\\\", \\\"user_agent\\\": \\\"python-requests/2.32.3\\\", \\\"connection_type\\\": \\\"rest\\\"}, \\\"client_ip\\\": null, \\\"ide_type\\\": \\\"unknown\\\", \\\"additional_data\\\": \\\"{}\\\"}\\n2025-08-02 01:49:41,960 - mcp_server - INFO - Tool Executed: {\\\"timestamp\\\": \\\"2025-08-01T20:19:41.959074\\\", \\\"event\\\": \\\"tool_executed\\\", \\\"tool_name\\\": \\\"scan_codebase\\\", \\\"user_id\\\": \\\"127.0.0.1\\\", \\\"client_ip\\\":...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"workflow_context.json\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\output\\\\workflow_context.json\",\n    \"content\": \"{\\n  \\\"execution_history\\\": [],\\n  \\\"data_context\\\": {\\n    \\\"https://github.com/atulpandey1695/MCP-hackathon.git\\\": \\\"https://github.com/atulpandey1695/MCP-hackathon.git\\\",\\n    \\\"hi\\\": \\\"hi\\\",\\n   ...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \".terraform.lock.hcl\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\terraform\\\\.terraform.lock.hcl\",\n    \"content\": \"# This file is maintained automatically by \\\"terraform init\\\".\\n# Manual edits may be lost in future updates.\\n\\nprovider \\\"registry.terraform.io/hashicorp/aws\\\" {\\n  version     = \\\"5.100.0\\\"\\n  constraints = \\\"~> 5.0\\\"\\n  hashes = [\\n    \\\"h1:edXOJWE4ORX8Fm+dpVpICzMZJat4AX0VRCAy/xkcOc0=\\\",\\n    \\\"zh:054b8dd49f0549c9a7cc27d159e45327b7b65cf404da5e5a20da154b90b8a644\\\",\\n    \\\"zh:0b97bf8d5e03d15d83cc40b0530a1f84b459354939ba6f135a0086c20ebbe6b2\\\",\\n    \\\"zh:1589a2266af699cbd5d80737a0fe02e54ec9cf2ca54e7e00ac51c7359056f274\\\",\\n    \\\"zh:6330766f1d85f01ae6ea90d1b214b8b74cc8c1badc4696b165b36ddd4cc15f7b\\\",\\n    \\\"zh:7c8c2e30d8e55291b86fcb64bdf6c25489d538688545eb48fd74ad622e5d3862\\\",\\n    \\\"zh:99b1003bd9bd32ee323544da897148f46a527f622dc3971af63ea3e251596342\\\",\\n    \\\"zh:9b12af85486a96aedd8d7984b0ff811a4b42e3d88dad1a3fb4c0b580d04fa425\\\",\\n    \\\"zh:9f8b909d3ec50ade83c8062290378b1ec553edef6a447c56dadc01a99f4eaa93\\\",\\n    \\\"zh:aaef921ff9aabaf8b1869a86d692ebd24fbd4e12c21205034bb679b9caf883a2\\\",\\n    \\\"zh:ac882313207aba00dd5a76dbd572a0ddc818bb9cbf5c9d61b28fe30efaec951e\\\",\\n    \\\"zh:bb64e8aff37becab373a1a0cc1080990785304141af42ed6aa3dd4913b000421\\\",\\n    \\\"zh:dfe495f6621df5540d9c92ad40b8067376350b005c637ea6efac5dc15028add4\\\",\\n    \\\"zh:f0ddf0eaf052766cfe09dea8200a946519f653c384ab4336e2a4a64fd...\"\n  },\n  {\n    \"type\": \"file\",\n    \"name\": \"deploy.sh\",\n    \"file\": \"C:\\\\Users\\\\AshokP.TALENTICA-ALL\\\\Documents\\\\GitHub\\\\MCP-hackathon/target\\\\terraform\\\\deploy.sh\",\n    \"content\": \"#!/bin/bash\\n\\n# MCP Server AWS Infrastructure Setup Guide\\n# Team: Minds-Constructing-Products\\n# Manual Terraform Deployment Guide\\n\\nset -e\\n\\necho \\\"\\ud83d\\ude80 MCP Server AWS Infrastructure Setup Guide\\\"\\necho \\\"Team: Minds-Constructing-Products\\\"\\necho \\\"Region: ap-south-1\\\"\\necho \\\"\\\"\\n\\n# Check prerequisites\\necho \\\"\\ud83d\\udccb Checking prerequisites...\\\"\\n\\nif ! command -v terraform &> /dev/null; then\\n    echo \\\"\\u274c Terraform is not installed. Please install Terraform first.\\\"\\n    echo \\\"Installation guide: https://developer.hashicorp.com/terraform/downloads\\\"\\n    exit 1\\nfi\\n\\nif ! command -v aws &> /dev/null; then\\n    echo \\\"\\u274c AWS CLI is not installed. Please install AWS CLI first.\\\"\\n    echo \\\"Installation guide: https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html\\\"\\n    exit 1\\nfi\\n\\n# Check AWS credentials\\nif ! aws sts get-caller-identity &> /dev/null; then\\n    echo \\\"\\u274c AWS credentials not configured. Please run 'aws configure' first.\\\"\\n    echo \\\"Configuration guide: https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html\\\"\\n    exit 1\\nfi\\n\\necho \\\"\\u2705 Prerequisites check passed!\\\"\\n\\n# Check for manually created key pair\\necho \\\"\\ud83d\\udd11 Checking for manually created key pair...\\\"\\nif [ -f \\\"Minds-Constructing-Products-key.pem\\\" ]; then\\n    echo \\\"\\u2705 Key pair file found: Minds-Constructing-Products-key.pem\\\"\\n    echo \\\"\\u2705 Key pair already created manually\\\"\\nelse\\n    echo \\\"\\u26a0\\ufe0f  Key pair file not found!\\\"\\n    echo \\\"Please create the key pair manually using:\\\"\\n    echo \\\"aws ec2 crea..."
  },
  {
    "type": "file",
    "name": "git_history_index.json",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\output\\git_history_index.json",
    "content": "{\n  \"repository\": {\n    \"url\": \"https://github.com/atulpandey1695/MCP-hackathon.git\",\n    \"cloned_branch\": \"main\",\n    \"requested_branch\": \"main\",\n    \"remote_url\": \"https://github.com/atulpandey1695/MCP-hackathon.git\"\n  },\n  \"metadata\": {\n    \"total_commits_fetched\": 26,\n    \"max_commits_requested\": 50,\n    \"fetch_timestamp\": \"2025-08-03T15:29:02.492330\",\n    \"clone_method\": \"temporary\"\n  },\n  \"commits\": [\n    {\n      \"sha\": \"668c0c69c6499cd38d9b14a1f12bd2dae5269bfc\",\n      \"short_sha\": \"668c0c6\",\n      \"message\": \"codebase tools access denied error fix\",\n      \"author\": {\n        \"name\": \"VishalRj-7\",\n        \"email\": \"Vishal.raj@talentica.com\"\n      },\n      \"authored_date\": \"2025-08-03T13:30:28+05:30\",\n      \"committed_date\": \"2025-08-03T13:30:28+05:30\",\n      \"changed_files\": [\n        \".gitignore\",\n        \"tools/development/codebase_tools.py\",\n        \"tools/output/codebase_faiss_index/index.faiss\",\n        \"tools/output/codebase_faiss_index/index.pkl\",\n        \"tools/output/codebase_index.json\",\n        \"tools/output/git_history_faiss_index/index.faiss\",\n        \"tools/output/git_history_faiss_index/index.pkl\",\n        \"tools/output/git_history_index.json\",\n        \"tools/output/jira_tickets_stories_faiss_index/index.faiss\",\n        \"tools/output/jira_tickets_stories_faiss_index/index.pkl\"\n      ]\n    },\n    {\n      \"sha\": \"53230e24dc8452b1771160943206b8849bb8b59f\",\n      \"short_sha\": \"53230e2\",\n      \"message\": \"vinay jira token\",\n      \"author\": {\n        \"name\": \"patelashok93\",\n        \"email\": \"ashok.patel@talentica.com\"\n      },\n      \"authored_date\": \"2025-08-03T12:38:35+05:30\",\n      \"committed_date\": \"2025-08-03T12:52:30+05:30\",\n      \"changed_files\": [\n        \".env\",\n        \"tools/development/jira_tools.py\"\n      ]\n    },\n    {\n      \"sha\": \"d1c395af17563272642b262eba2a6222b12dfad7\",\n      \"short_sha\": \"d1c395a\",\n      \"message\": \"Cleanup: ignore terraform-generated files and remove large tracked files\",\n      \"author\": {\n        \"name\": \"atul.pandey\",\n        \"email\": \"atul.pandey@digitalturbine.com\"\n      },\n      \"authored_date\": \"2025-08-03T01:49:39+05:30\",\n      \"committed_date\": \"2025-08-03T01:53:08+05:30\",\n      \"changed_files\": [\n        \"terraform/.gitignore\"\n      ]\n    },\n    {\n      \"sha\": \"22a604169dea019aeb4932fbc0b74c94f6950481\",\n      \"short_sha\": \"22a6041\",\n      \"message\": \"Cleanup: ignore Terraform-generated files and remove large tracked files\",\n      \"author\": {\n        \"name\": \"atul.pandey\",\n        \"email\": \"atul.pandey@digitalturbine.com\"\n      },\n      \"authored_date\": \"2025-08-03T01:44:06+05:30\",\n      \"committed_date\": \"2025-08-03T01:53:08+05:30\",\n      \"changed_files\": [\n        \"terraform/terraform.tfstate\",\n        \"terraform/terraform.tfstate.backup\"\n      ]\n    },\n    {\n      \"sha\": \"2cbecdafbdedddb81ef4b69403a34db69d809ff4\",\n      \"short_sha\": \"2cbecda\",\n      \"message\": \"updated the terraform code files\",\n      \"author\": {\n        \"name\": \"atul.pandey\",\n        \"email\": \"atul.pandey@digitalturbine.com\"\n      },\n      \"authored_date\": \"2025-08-03T01:36:33+05:30\",\n      \"committed_date\": \"2025-08-03T01:53:08+05:30\",\n      \"changed_files\": [\n        \".github/workflows/README.md\",\n        \".github/workflows/ci-cd.yml\",\n        \".github/workflows/notifications.yml\",\n        \".github/workflows/security-scan.yml\",\n        \".github/workflows/terraform-plan.yml\",\n        \"ARCHITECTURE_DIAGRAM.md\",\n        \"PRESENTATION_ARCHITECTURE.md\",\n        \"PRESENTATION_SLIDES.md\",\n        \"README_PRESENTATION.md\",\n        \"terraform/.gitignore\",\n        \"terraform/.terraform.lock.hcl\",\n        \"terraform/DEPLOYMENT_GUIDE.md\",\n        \"terraform/MANUAL_DEPLOYMENT.md\",\n        \"terraform/README.md\",\n        \"terraform/WORKFLOW_DIAGRAM.md\",\n        \"terraform/main.tf\",\n        \"terraform/outputs.tf\",\n        \"terraform/setup_script.sh\",\n        \"terraform/terraform.tfstate\",\n        \"terraform/terraform.tfstate.backup\",\n        \"terraform/user_data.sh\",\n        \"terraform/variables.tf\",\n        \"terraform/workflow.md\"\n      ]\n    },\n    {\n      \"sha\": \"690ee18f82844ea3a69a404cf97755817f683f13\",\n      \"short_sha\": \"690ee18\",\n      \"message\": \"jira tool update\",\n      \"author\": {\n        \"name\": \"patelashok93\",\n        \"email\": \"ashok.patel@talentica.com\"\n      },\n      \"authored_date\": \"2025-08-03T00:49:05+05:30\",\n      \"committed_date\": \"2025-08-03T00:50:15+05:30\",\n      \"changed_files\": [\n        \"bot.py\",\n        \"tools/development/jira_tools.py\",\n        \"tools/output/jira_faiss_index/index.faiss\",\n        \"tools/output/jira_faiss_index/index.pkl\",\n        \"tools/output/jira_tickets_stories_context.json\",\n        \"tools/output/jira_tickets_stories_faiss_index/index.faiss\",\n        \"tools/output/jira_tickets_stories_faiss_index/index.pkl\",\n        \"tools/output/prd_context.json\"\n      ]\n    },\n    {\n      \"sha\": \"4547fe4ded6445474a34946ee0b297cc899b212e\",\n      \"short_sha\": \"4547fe4\",\n      \"message\": \"Git ignore with Node_Modules\",\n      \"author\": {\n        \"name\": \"Ketan\",\n        \"email\": \"ketan@tailoredmail.com\"\n      },\n      \"authored_date\": \"2025-08-02T23:09:42+05:30\",\n      \"committed_date\": \"2025-08-02T23:09:54+05:30\",\n      \"changed_files\": [\n        \".gitignore\"\n      ]\n    },\n    {\n      \"sha\": \"a3f6eefb4fe5a351d83a1f389bf1204c0d8b6646\",\n      \"short_sha\": \"a3f6eef\",\n      \"message\": \"UI with Streamlit\",\n      \"author\": {\n        \"name\": \"VinayD-01\",\n        \"email\": \"vinay.dahat@talentica.com\"\n      },\n      \"authored_date\": \"2025-08-02T22:58:01+05:30\",\n      \"committed_date\": \"2025-08-02T22:58:01+05:30\",\n      \"changed_files\": [\n        \"requirements.txt\",\n        \"streamlit_app.py\"\n      ]\n    },\n    {\n      \"sha\": \"da919ed69fa7045249f4718ced6c84a6d22ea833\",\n      \"short_sha\": \"da919ed\",\n      \"message\": \"Integegrated git history tool in multi-agent\",\n      \"author\": {\n        \"name\": \"Codebandits-tal\",\n        \"email\": \"140823987+Codebandits-tal@users.noreply.github.com\"\n      },\n      \"authored_date\": \"2025-08-02T22:40:43+05:30\",\n      \"committed_date\": \"2025-08-02T22:40:43+05:30\",\n      \"changed_files\": [\n        \"bot.py\",\n        \"git_history_api.py\",\n        \"multi-agent.py\",\n        \"output/workflow_context.json\",\n        \"tools.json\",\n        \"tools/development/git_tools.py\",\n        \"tools/output/git_history_faiss_index/index.faiss\",\n        \"tools/output/git_history_faiss_index/index.pkl\",\n        \"tools/output/git_history_index.json\",\n        \"tools/output/jira_faiss_index/index.faiss\",\n        \"tools/output/jira_faiss_index/index.pkl\",\n        \"tools/output/remote_git_history.json\",\n        \"tools/utils/faiss_converter.py\"\n      ]\n    },\n    {\n      \"sha\": \"db9a7063a94d151ff91f74493fb66117889b5d26\",\n      \"short_sha\": \"db9a706\",\n      \"message\": \"Merge pull request #1 from atulpandey1695/gitwebhook-anand\\n\\nFetch git history\",\n      \"author\": {\n        \"name\": \"Codebandits-tal\",\n        \"email\": \"140823987+Codebandits-tal@users.noreply.github.com\"\n      },\n      \"authored_date\": \"2025-08-02T21:21:00+05:30\",\n      \"committed_date\": \"2025-08-02T21:21:00+05:30\",\n      \"changed_files\": [\n        \"data/codebandits_private_history.json\",\n        \"data/hello_world_remote.json\",\n        \"git_history_api.py\",\n        \"requirements.txt\"\n      ]\n    },\n    {\n      \"sha\": \"579588ea447af0188c1e084a243393db1709e40c\",\n      \"short_sha\": \"579588e\",\n      \"message\": \"codebase analysis tool  half done\",\n      \"author\": {\n        \"name\": \"VishalRj-7\",\n        \"email\": \"Vishal.raj@talentica.com\"\n      },\n      \"authored_date\": \"2025-08-02T21:16:57+05:30\",\n      \"committed_date\": \"2025-08-02T21:16:57+05:30\",\n      \"changed_files\": [\n        \"bot.py\",\n        \"logs/mcp-server.log\",\n        \"multi-agent.py\",\n        \"output/workflow_context.json\",\n        \"tools.json\",\n        \"tools/development/codebase_tools.py\",\n        \"tools/development/jira_tools.py\",\n        \"tools/output/codebase_faiss_index/index.faiss\",\n        \"tools/output/codebase_faiss_index/index.pkl\",\n        \"tools/output/codebase_index.json\",\n        \"tools/output/faiss_index/index.faiss\",\n        \"tools/output/jira_faiss_index/index.faiss\",\n        \"tools/output/faiss_index/index.pkl\",\n        \"tools/utils/faiss_converter.py\"\n      ]\n    },\n    {\n      \"sha\": \"4598c1468516ba0bb49d475e0a95fb7d26250735\",\n      \"short_sha\": \"4598c14\",\n      \"message\": \"Added bot py file\",\n      \"author\": {\n        \"name\": \"patelashok93\",\n        \"email\": \"ashok.patel@talentica.com\"\n      },\n      \"authored_date\": \"2025-08-02T18:08:55+05:30\",\n      \"committed_date\": \"2025-08-02T18:10:01+05:30\",\n      \"changed_files\": [\n        \".env\",\n        \".gitignore\",\n        \"__pycache__/enhanced_context_manager.cpython-311.pyc\",\n        \"__pycache__/llm_provider.cpython-311.pyc\",\n        \"bot.py\",\n        \"multi-agent.py\",\n        \"requirements.txt\",\n        \"tools.json\",\n        \"tools/__pycache__/__init__.cpython-311.pyc\",\n        \"tools/__pycache__/custom_api.cpython-311.pyc\",\n        \"tools/__pycache__/google_search.cpython-311.pyc\",\n        \"tools/__pycache__/question_answering_module.cpython-311.pyc\",\n        \"tools/development/__pycache__/codebase_tools.cpython-311.pyc\",\n        \"tools/development/__pycache__/git_tools.cpython-311.pyc\",\n        \"tools/development/__pycache__/jira_tools.cpython-311.pyc\",\n        \"tools/development/jira_tools.py\",\n        \"tools/output/faiss_index/index.faiss\",\n        \"tools/output/faiss_index/index.pkl\",\n        \"tools/output/prd_context.json\",\n        \"tools/utils/faiss_converter.py\"\n      ]\n    },\n    {\n      \"sha\": \"590de4726c3e1862708382819723b1c96e622428\",\n      \"short_sha\": \"590de47\",\n      \"message\": \"updated terraform files\",\n      \"author\": {\n        \"name\": \"atul.pandey\",\n        \"email\": \"atul.pandey@digitalturbine.com\"\n      },\n      \"authored_date\": \"2025-08-02T18:06:18+05:30\",\n      \"committed_date\": \"2025-08-02T18:06:18+05:30\",\n      \"changed_files\": [\n        \"terraform/main.tf\",\n        \"terraform/setup_script.sh\",\n        \"terraform/user_data.sh\"\n      ]\n    },\n    {\n      \"sha\": \"3abe4151434db0b7210ff62dd7bf73219163556e\",\n      \"short_sha\": \"3abe415\",\n      \"message\": \"updated main.tf file\",\n      \"author\": {\n        \"name\": \"atul.pandey\",\n        \"email\": \"atul.pandey@digitalturbine.com\"\n      },\n      \"authored_date\": \"2025-08-02T18:00:34+05:30\",\n      \"committed_date\": \"2025-08-02T18:00:34+05:30\",\n      \"changed_files\": [\n        \"terraform/main.tf\"\n      ]\n    },\n    {\n      \"sha\": \"41cfa49fe4f1afb217821fa671d1aaa942fdae42\",\n      \"short_sha\": \"41cfa49\",\n      \"message\": \":Merge branch 'main' of github.com:atulpandey1695/MCP-hackathon\",\n      \"author\": {\n        \"name\": \"atul.pandey\",\n        \"email\": \"atul.pandey@digitalturbine.com\"\n      },\n      \"authored_date\": \"2025-08-02T17:54:43+05:30\",\n      \"committed_date\": \"2025-08-02T17:54:43+05:30\",\n      \"changed_files\": [\n        \"multi-agent.py\",\n        \"tools.json\",\n        \"tools/development/codebase_tools.py\"\n      ]\n    },\n    {\n      \"sha\": \"81fbed0203736548665a9e05486f953356b0a26c\",\n      \"short_sha\": \"81fbed0\",\n      \"message\": \"feat: Add complete AWS infrastructure with Terraform\\n\\n- Add comprehensive..."
  },
  {
    "type": "file",
    "name": "jira_tickets_stories_context.json",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\output\\jira_tickets_stories_context.json",
    "content": "{\n  \"title\": \"Product Requirements Document\",\n  \"tickets\": [\n    {\n      \"id\": \"SCRUM-27\",\n      \"summary\": \"Integrate AI/ML food recognition service\",\n      \"description\": null\n    },\n    {\n      \"id\": \"SCRUM-26\",\n      \"summary\": \"Set up image upload infrastructure\",\n      \"description\": null\n    },\n    {\n      \"id\": \"SCRUM-25\",\n      \"summary\": \"Create statistics page\",\n      \"description\": null\n    },\n    {\n      \"id\": \"SCRUM-24\",\n      \"summary\": \"Build chart components\",\n      \"description\": null\n    },\n    {\n      \"id\": \"SCRUM-23\",\n      \"summary\": \"Implement daily calorie aggregation\",\n      \"description\": null\n    },\n    {\n      \"id\": \"SCRUM-22\",\n      \"summary\": \"Add pagination and filtering\",\n      \"description\": null\n    },\n    {\n      \"id\": \"SCRUM-21\",\n      \"summary\": \"Develop calorie entry UI components\",\n      \"description\": \"Design and implement reusable React components for adding, editing, and deleting calorie entries. Components should include input fields for meal name, calorie count, and date/time, along with validation and user feedback. Ensure consistent styling using CSS modules and theme variables. These components will be used across the stats page and test data features.\"\n    },\n    {\n      \"id\": \"SCRUM-20\",\n      \"summary\": \"Build Calorie API endpoints\",\n      \"description\": \"Implement full backend API support for calorie-related features. Endpoints should include:\\n\\n* {{POST /calories}}: Add a new entry.\\n* {{GET /calories}}: Retrieve all entries.\\n* {{GET /calories/by-day}}: Get daily grouped stats.\\n* {{PUT /calories/:id}}: Update an entry.\\n* {{DELETE /calories/:id}}: Remove an entry.\\n* {{POST /calories/test-data}}: Populate mock data for testing.\\n\\nThese endpoints should follow REST conventions and be covered with tests.\"\n    },\n    {\n      \"id\": \"SCRUM-19\",\n      \"summary\": \"Implement Calorie CRUD operations\",\n      \"description\": \"Develop backend logic and RESTful endpoints to create, retrieve, update, and delete calorie entries. Ensure all operations are scoped to the authenticated user and prevent unauthorized access to others\\u2019 data. Validate input data for each operation and respond with appropriate status codes and messages.\"\n    },\n    {\n      \"id\": \"SCRUM-18\",\n      \"summary\": \"Design Calorie database schema\",\n      \"description\": \"Create a robust schema using TypeORM for storing calorie entries. Each entry should include fields like {{id}}, {{userId}}, {{mealName}}, {{calories}}, and {{timestamp}}. Link entries to users and enforce referential integrity. Prepare migration scripts to initialize the database schema during deployment.\"\n    },\n    {\n      \"id\": \"SCRUM-17\",\n      \"summary\": \"Develop frontend authentication components\",\n      \"description\": \"Build reusable components to handle user login, logout, and session management in the frontend. Use React Context or global state management to persist authenticated user info. Display logged-in user's name and avatar in the UI. Secure routes using guards or conditional rendering based on auth status.\"\n    },\n    {\n      \"id\": \"SCRUM-16\",\n      \"summary\": \"Build authentication middleware\",\n      \"description\": \"Develop middleware in NestJS that intercepts HTTP requests to validate JWT tokens. Allow only authenticated users to access protected routes. Return appropriate error codes for invalid or expired tokens. Log token errors for debugging and monitoring purposes.\"\n    },\n    {\n      \"id\": \"SCRUM-15\",\n      \"summary\": \"Create User entity and repository\",\n      \"description\": \"Define a {{User}} entity using TypeORM with fields such as email, name, and profile picture. Create a repository to handle user creation, updates, and lookups. Upon successful OAuth login, either create a new user or update existing records with the latest data from Google. Ensure indexing on the email field for fast lookup.\"\n    },\n    {\n      \"id\": \"SCRUM-14\",\n      \"summary\": \"Implement JWT token management\",\n      \"description\": \"Use {{@nestjs/jwt}} to manage JWT tokens in the backend. Create services to sign, validate, and decode tokens securely. Embed user identification in the token payload and use expiration claims ({{exp}}) to enforce session expiry. Implement middleware to guard protected routes based on token validity.\"\n    },\n    {\n      \"id\": \"SCRUM-13\",\n      \"summary\": \"Set up Google OAuth configuration\",\n      \"description\": \"Set up and configure Google OAuth on both frontend and backend. In the frontend, use {{@react-oauth/google}} to initiate login flows. On the backend, use {{google-auth-library}} to verify tokens, extract user details, and issue JWTs. Ensure secure token exchange and proper error handling for authentication failures. Configure necessary credentials in {{.env}} or Docker environment files.\"\n    },\n    {\n      \"id\": \"SCRUM-12\",\n      \"summary\": \"Comprehensive Testing\",\n      \"description\": \"Containerize all application services (frontend, backend, and mock service) using Docker. Configure {{docker-compose}} to enable seamless multi-container orchestration. Set up the frontend to be served using Nginx, and backend and mock services to run on Node.js environments. Ensure all services are configurable through environment variables (e.g., JWT secrets, OAuth client IDs). Validate the setup with local builds and simulate production deployment.\"\n    },\n    {\n      \"id\": \"SCRUM-11\",\n      \"summary\": \"DevOps and Deployment\",\n      \"description\": \"Containerize all application services (frontend, backend, and mock service) using Docker. Configure {{docker-compose}} to enable seamless multi-container orchestration. Set up the frontend to be served using Nginx, and backend and mock services to run on Node.js environments. Ensure all services are configurable through environment variables (e.g., JWT secrets, OAuth client IDs). Validate the setup with local builds and simulate production deployment.\"\n    },\n    {\n      \"id\": \"SCRUM-10\",\n      \"summary\": \"Goal Setting and Tracking\",\n      \"description\": \"Introduce the ability for users to set daily calorie intake goals. Build backend support for saving and retrieving these goals. On the frontend, display progress indicators comparing consumed calories vs. the user-defined target. Provide feedback if users exceed or stay under their goals. This feature sets the foundation for future personalized health recommendations.\"\n    },\n    {\n      \"id\": \"SCRUM-9\",\n      \"summary\": \"Performance Optimization\",\n      \"description\": \"Identify and address performance bottlenecks in both frontend and backend. Implement lazy loading for components and optimize database queries to support high user concurrency. Ensure that the app handles up to 100 calorie entries per user without noticeable lag. P..."
  },
  {
    "type": "file",
    "name": "remote_git_history.json",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\output\\remote_git_history.json",
    "content": "{\n  \"repository\": {\n    \"url\": \"https://github.com/atulpandey1695/MCP-hackathon.git\",\n    \"cloned_branch\": \"main\",\n    \"requested_branch\": \"main\",\n    \"remote_url\": \"https://github.com/atulpandey1695/MCP-hackathon.git\"\n  },\n  \"metadata\": {\n    \"total_commits_fetched\": 17,\n    \"max_commits_requested\": 50,\n    \"fetch_timestamp\": \"2025-08-02T22:23:47.631297\",\n    \"clone_method\": \"temporary\"\n  },\n  \"commits\": [\n    {\n      \"sha\": \"db9a7063a94d151ff91f74493fb66117889b5d26\",\n      \"short_sha\": \"db9a706\",\n      \"message\": \"Merge pull request #1 from atulpandey1695/gitwebhook-anand\\n\\nFetch git history\",\n      \"author\": {\n        \"name\": \"Codebandits-tal\",\n        \"email\": \"140823987+Codebandits-tal@users.noreply.github.com\"\n      },\n      \"authored_date\": \"2025-08-02T21:21:00+05:30\",\n      \"committed_date\": \"2025-08-02T21:21:00+05:30\",\n      \"changed_files\": [\n        \"data/codebandits_private_history.json\",\n        \"data/hello_world_remote.json\",\n        \"git_history_api.py\",\n        \"requirements.txt\"\n      ]\n    },\n    {\n      \"sha\": \"579588ea447af0188c1e084a243393db1709e40c\",\n      \"short_sha\": \"579588e\",\n      \"message\": \"codebase analysis tool  half done\",\n      \"author\": {\n        \"name\": \"VishalRj-7\",\n        \"email\": \"Vishal.raj@talentica.com\"\n      },\n      \"authored_date\": \"2025-08-02T21:16:57+05:30\",\n      \"committed_date\": \"2025-08-02T21:16:57+05:30\",\n      \"changed_files\": [\n        \"bot.py\",\n        \"logs/mcp-server.log\",\n        \"multi-agent.py\",\n        \"output/workflow_context.json\",\n        \"tools.json\",\n        \"tools/development/codebase_tools.py\",\n        \"tools/development/jira_tools.py\",\n        \"tools/output/codebase_faiss_index/index.faiss\",\n        \"tools/output/codebase_faiss_index/index.pkl\",\n        \"tools/output/codebase_index.json\",\n        \"tools/output/faiss_index/index.faiss\",\n        \"tools/output/jira_faiss_index/index.faiss\",\n        \"tools/output/faiss_index/index.pkl\",\n        \"tools/utils/faiss_converter.py\"\n      ]\n    },\n    {\n      \"sha\": \"4598c1468516ba0bb49d475e0a95fb7d26250735\",\n      \"short_sha\": \"4598c14\",\n      \"message\": \"Added bot py file\",\n      \"author\": {\n        \"name\": \"patelashok93\",\n        \"email\": \"ashok.patel@talentica.com\"\n      },\n      \"authored_date\": \"2025-08-02T18:08:55+05:30\",\n      \"committed_date\": \"2025-08-02T18:10:01+05:30\",\n      \"changed_files\": [\n        \".env\",\n        \".gitignore\",\n        \"__pycache__/enhanced_context_manager.cpython-311.pyc\",\n        \"__pycache__/llm_provider.cpython-311.pyc\",\n        \"bot.py\",\n        \"multi-agent.py\",\n        \"requirements.txt\",\n        \"tools.json\",\n        \"tools/__pycache__/__init__.cpython-311.pyc\",\n        \"tools/__pycache__/custom_api.cpython-311.pyc\",\n        \"tools/__pycache__/google_search.cpython-311.pyc\",\n        \"tools/__pycache__/question_answering_module.cpython-311.pyc\",\n        \"tools/development/__pycache__/codebase_tools.cpython-311.pyc\",\n        \"tools/development/__pycache__/git_tools.cpython-311.pyc\",\n        \"tools/development/__pycache__/jira_tools.cpython-311.pyc\",\n        \"tools/development/jira_tools.py\",\n        \"tools/output/faiss_index/index.faiss\",\n        \"tools/output/faiss_index/index.pkl\",\n        \"tools/output/prd_context.json\",\n        \"tools/utils/faiss_converter.py\"\n      ]\n    },\n    {\n      \"sha\": \"590de4726c3e1862708382819723b1c96e622428\",\n      \"short_sha\": \"590de47\",\n      \"message\": \"updated terraform files\",\n      \"author\": {\n        \"name\": \"atul.pandey\",\n        \"email\": \"atul.pandey@digitalturbine.com\"\n      },\n      \"authored_date\": \"2025-08-02T18:06:18+05:30\",\n      \"committed_date\": \"2025-08-02T18:06:18+05:30\",\n      \"changed_files\": [\n        \"terraform/main.tf\",\n        \"terraform/setup_script.sh\",\n        \"terraform/user_data.sh\"\n      ]\n    },\n    {\n      \"sha\": \"3abe4151434db0b7210ff62dd7bf73219163556e\",\n      \"short_sha\": \"3abe415\",\n      \"message\": \"updated main.tf file\",\n      \"author\": {\n        \"name\": \"atul.pandey\",\n        \"email\": \"atul.pandey@digitalturbine.com\"\n      },\n      \"authored_date\": \"2025-08-02T18:00:34+05:30\",\n      \"committed_date\": \"2025-08-02T18:00:34+05:30\",\n      \"changed_files\": [\n        \"terraform/main.tf\"\n      ]\n    },\n    {\n      \"sha\": \"41cfa49fe4f1afb217821fa671d1aaa942fdae42\",\n      \"short_sha\": \"41cfa49\",\n      \"message\": \":Merge branch 'main' of github.com:atulpandey1695/MCP-hackathon\",\n      \"author\": {\n        \"name\": \"atul.pandey\",\n        \"email\": \"atul.pandey@digitalturbine.com\"\n      },\n      \"authored_date\": \"2025-08-02T17:54:43+05:30\",\n      \"committed_date\": \"2025-08-02T17:54:43+05:30\",\n      \"changed_files\": [\n        \"multi-agent.py\",\n        \"tools.json\",\n        \"tools/development/codebase_tools.py\"\n      ]\n    },\n    {\n      \"sha\": \"81fbed0203736548665a9e05486f953356b0a26c\",\n      \"short_sha\": \"81fbed0\",\n      \"message\": \"feat: Add complete AWS infrastructure with Terraform\\n\\n- Add comprehensive Terraform configuration for MCP Server\\n- Include EC2 instance with PostgreSQL and Redis\\n- Add S3 bucket and ECR repository\\n- Include enhanced user_data script with error handling\\n- Add comprehensive documentation and deployment guides\\n- Optimize for t2.micro instances with Amazon Linux 2\\n- Include security groups and monitoring\\n- Add troubleshooting and verification scripts\",\n      \"author\": {\n        \"name\": \"atul.pandey\",\n        \"email\": \"atul.pandey@digitalturbine.com\"\n      },\n      \"authored_date\": \"2025-08-02T17:36:38+05:30\",\n      \"committed_date\": \"2025-08-02T17:36:38+05:30\",\n      \"changed_files\": [\n        \"ARCHITECTURE_ANALYSIS.md\",\n        \"terraform/.gitignore\",\n        \"terraform/DEPLOYMENT_GUIDE.md\",\n        \"terraform/MANUAL_DEPLOYMENT.md\",\n        \"terraform/README.md\",\n        \"terraform/WORKFLOW_DIAGRAM.md\",\n        \"terraform/deploy.sh\",\n        \"terraform/main.tf\",\n        \"terraform/outputs.tf\",\n        \"terraform/user_data.sh\",\n        \"terraform/variables.tf\",\n        \"terraform/versions.tf\",\n        \"terraform/workflow.md\"\n      ]\n    },\n    {\n      \"sha\": \"825ea209fc8eb3257e30bb8d2bc83a78624783b4\",\n      \"short_sha\": \"825ea20\",\n      \"message\": \"Merge branch 'main' into gitwebhook-anand\",\n      \"author\": {\n        \"name\": \"Codebandits-tal\",\n        \"email\": \"140823987+Codebandits-tal@users.noreply.github.com\"\n      },\n      \"authored_date\": \"2025-08-02T15:31:57+05:30\",\n      \"committed_date\": \"2025-08-02T15:31:57+05:30\",\n      \"changed_files\": [\n        \".gitignore\",\n        \"README.md\",\n        \"chat_context_db.py\",\n        \"chatbot.py\",\n        \"chatbot_context.json\",\n        \"core/tool_registry.py\",\n        \"logs/mcp-server.log\",\n        \"mcp_server/.env.example\",\n        \"mcp_server/Dockerfile\",\n        \"mcp_server/README.md\",\n        \"mcp_server/__init__.py\",\n        \"mcp_server/core/tool_registry.py\",\n        \"mcp_server/deploy/deploy-aws.sh\",\n        \"mcp_server/docker-compose.yml\",\n        \"mcp_server/langchain_mcp_server.py\",\n        \"mcp_server/logs/mcp-server.log\",\n        \"mcp_server/mcp_sqlite_logger.py\",\n        \"mcp_server/mcp_tools.http\",\n        \"mcp_server/monitoring.py\",\n        \"mcp_server/requirements.txt\",\n        \"mcp_server/server.py\",\n        \"mcp_server/start-server.bat\",\n        \"mcp_server/start-server.sh\",\n        \"mcp_server/test_verification.py\",\n        \"multi-agent.py\",\n        \"output/workflow_context.json\",\n        \"requirements.txt\",\n        \"test_mcp_server.py\",\n        \"tools.json\",\n        \"tools/__pycache__/question_answering_module.cpython-311.pyc\",\n        \"tools/development/__pycache__/codebase_tools.cpython-311.pyc\",\n        \"tools/development/__pycache__/git_tools.cpython-311.pyc\",\n        \"tools/development/__pycache__/jira_tools.cpython-311.pyc\",\n        \"tools/development/codebase_tools.py\",\n        \"tools/development/git_tools.py\",\n        \"tools/development/jira_tools.py\",\n        \"tools/question_answering_module.py\"\n      ]\n    },\n    {\n      \"sha\": \"a30e504a00037e9c68e75ba1f18726e1b2383c41\",\n      \"short_sha\": \"a30e504\",\n      \"message\": \"deleted unwanted files\",..."
  },
  {
    "type": "file",
    "name": "index.faiss",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\output\\codebase_faiss_index\\index.faiss",
    "content": ""
  },
  {
    "type": "file",
    "name": "index.pkl",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\output\\codebase_faiss_index\\index.pkl",
    "content": ""
  },
  {
    "type": "file",
    "name": "index.faiss",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\output\\git_history_faiss_index\\index.faiss",
    "content": ""
  },
  {
    "type": "file",
    "name": "index.pkl",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\output\\git_history_faiss_index\\index.pkl",
    "content": ""
  },
  {
    "type": "file",
    "name": "index.faiss",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\output\\jira_tickets_stories_faiss_index\\index.faiss",
    "content": ""
  },
  {
    "type": "file",
    "name": "index.pkl",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\output\\jira_tickets_stories_faiss_index\\index.pkl",
    "content": ""
  },
  {
    "type": "file",
    "name": "faiss_converter.py",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\utils\\faiss_converter.py",
    "content": "import json\nimport faiss\nfrom langchain_openai.embeddings import OpenAIEmbeddings\nfrom langchain_community.vectorstores import FAISS\nfrom dotenv import load_dotenv\nimport os\nimport pathlib\nimport importlib\n\n# Load environment variables from .env file\nload_dotenv()\n\nopenai_api_key = os.getenv(\"OPENAI_API_KEY\")\nif not openai_api_key:\n    # Try to read from settings.json\n    settings_path = pathlib.Path(__file__).parent / \"settings.json\"\n    if settings_path.exists():\n        with open(settings_path, \"r\", encoding=\"utf-8\") as f:\n            try:\n                settings = json.load(f)\n                openai_api_key = settings.get(\"OPENAI_API_KEY\")\n            except Exception:\n                openai_api_key = None\n    if not openai_api_key:\n        openai_api_key = input(\"Enter your OpenAI API key: \").strip()\n\ndef json_to_faiss(json_file_path: str, faiss_index_path: str):\n    \"\"\"\n    Convert JSON data into FAISS chunks for querying with LLM.\n    \n    Args:\n        json_file_path (str): Path to the JSON file.\n        faiss_index_path (str): Path to save the FAISS index.\n    \n    Returns:\n        FAISS: The FAISS index object.\n    \"\"\"\n \n    #print(f\"Using OpenAI API key: {api_key}\")\n    # Step 1: Load JSON data\n    with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    \n    # Step 2: Extract text chunks from JSON and add metadata\n    from langchain_core.documents import Document\n    documents = []\n    for ticket in data.get(\"tickets\", []):\n        chunk = f\"ID: {ticket['id']}\\nSummary: {ticket['summary']}\\nDescription: {ticket['description']}\"\n        metadata = {\"id\": str(ticket[\"id\"])}\n        documents.append(Document(page_content=chunk, metadata=metadata))\n    \n    # Step 3: Generate embeddings using OpenAI embeddings\n    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)  # Ensure your OpenAI API key is set in the environment\n    \n    # Step 4: Create FAISS index with documents and metadata\n    faiss_index = FAISS.from_documents(documents, embeddings)\n    \n    # Step 5: Save the FAISS index\n    faiss_index.save_local(faiss_index_path)\n    print(f\"FAISS index saved to {faiss_index_path}\")\n    \n    return faiss_index\n\ndef codebase_json_to_faiss(json_file_path: str, faiss_index_path: str):\n    import json\n    from langchain_core.documents import Document\n    from langchain_openai.embeddings import OpenAIEmbeddings\n    from langchain_community.vectorstores import FAISS\n\n    # Load JSON data (list of dicts)\n    with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n\n    # Build documents from codebase_index.json\n    documents = []\n    for entry in data:\n        # Compose a chunk from av..."
  },
  {
    "type": "function",
    "name": "json_to_faiss",
    "doc": "Convert JSON data into FAISS chunks for querying with LLM.\n\nArgs:\n    json_file_path (str): Path to the JSON file.\n    faiss_index_path (str): Path to save the FAISS index.\n\nReturns:\n    FAISS: The FAISS index object.",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\utils\\faiss_converter.py"
  },
  {
    "type": "function",
    "name": "codebase_json_to_faiss",
    "doc": null,
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\utils\\faiss_converter.py"
  },
  {
    "type": "function",
    "name": "remote_git_history_to_faiss",
    "doc": "Convert remote_git_history.json git commit data into FAISS chunks for semantic search.\nArgs:\n    json_file_path (str): Path to the remote_git_history.json file.\n    faiss_index_path (str): Path to save the FAISS index.\nReturns:\n    FAISS: The FAISS index object.",
    "file": "C:\\Users\\VinayD\\Documents\\GitHub\\MCP-hackathon/target\\tools\\utils\\faiss_converter.py"
  }
]